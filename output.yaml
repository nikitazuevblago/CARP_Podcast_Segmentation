- end: '00:02.540'
  start: '00:00.000'
  text: The following is a conversation with Elon Musk.
- end: '00:06.960'
  start: '00:02.540'
  text: His third time on this, the Lex Friedman podcast.
- end: '00:08.400'
  start: '00:06.960'
  text: Yeah, make yourself comfortable.
- end: '00:09.240'
  start: '00:08.400'
  text: Boo.
- end: '00:11.040'
  start: '00:09.240'
  text: No, wow, okay.
- end: '00:12.760'
  start: '00:11.040'
  text: You don't do the headphones thing?
- end: '00:13.600'
  start: '00:12.760'
  text: No.
- end: '00:14.440'
  start: '00:13.600'
  text: Okay.
- end: '00:15.280'
  start: '00:14.440'
  text: I mean, how close do I get?
- end: '00:16.120'
  start: '00:15.280'
  text: I need to get to this thing.
- end: '00:17.560'
  start: '00:16.120'
  text: The closer you are, the sexier you sound.
- end: '00:18.400'
  start: '00:17.560'
  text: Hey, babe.
- end: '00:19.240'
  start: '00:18.400'
  text: Yep.
- end: '00:20.960'
  start: '00:19.240'
  text: Can't get enough of the all that, baby.
- end: '00:25.960'
  start: '00:20.960'
  text: I'm gonna clip that out anytime somebody messes with me.
- end: '00:26.840'
  start: '00:26.000'
  text: Messages me about you.
- end: '00:27.680'
  start: '00:26.840'
  text: I don't know.
- end: '00:28.520'
  start: '00:27.680'
  text: You want my body.
- end: '00:30.160'
  start: '00:28.520'
  text: And you think I'm sexy.
- end: '00:32.120'
  start: '00:30.160'
  text: Come right out and tell me so.
- end: '00:39.720'
  start: '00:38.880'
  text: So good.
- end: '00:40.560'
  start: '00:39.720'
  text: Okay.
- end: '00:41.920'
  start: '00:40.560'
  text: Serious mode activate.
- end: '00:43.240'
  start: '00:41.920'
  text: All right.
- end: '00:44.360'
  start: '00:43.240'
  text: Serious mode.
- end: '00:45.200'
  start: '00:44.360'
  text: Come on, you're Russian.
- end: '00:46.040'
  start: '00:45.200'
  text: You can be serious.
- end: '00:47.760'
  start: '00:46.040'
  text: Everyone's serious all the time in Russia.
- end: '00:48.600'
  start: '00:47.760'
  text: Yeah.
- end: '00:50.640'
  start: '00:48.600'
  text: Yeah, we'll get there.
- end: '00:52.480'
  start: '00:50.640'
  text: We'll get there.
- end: '00:53.400'
  start: '00:52.480'
  text: It's gotten soft.
- end: '00:57.720'
  start: '00:54.160'
  text: Allow me to say that the SpaceX launch
- end: '01:00.920'
  start: '00:57.720'
  text: of human beings to orbit on May 30th, 2020
- end: '01:03.880'
  start: '01:02.120'
  text: was seen by many as the first step
- end: '01:07.400'
  start: '01:03.880'
  text: in a new era of human space exploration.
- end: '01:10.600'
  start: '01:07.400'
  text: These human spaceflight missions were a beacon of hope
- end: '01:12.720'
  start: '01:10.600'
  text: to me and to millions over the past two years
- end: '01:14.640'
  start: '01:12.720'
  text: as our world has been going through
- end: '01:18.040'
  start: '01:14.640'
  text: one of the most difficult periods in recent human history.
- end: '01:21.720'
  start: '01:18.040'
  text: We saw, we see the rise of division, fear, cynicism
- end: '01:24.640'
  start: '01:21.720'
  text: and the loss of common humanity
- end: '01:26.400'
  start: '01:24.640'
  text: right when it is needed most.
- end: '01:29.080'
  start: '01:26.400'
  text: So first, Elon, let me say thank you
- end: '01:30.640'
  start: '01:29.080'
  text: for giving the world hope and reason
- end: '01:32.520'
  start: '01:30.640'
  text: to be excited about the future.
- end: '01:34.200'
  start: '01:32.520'
  text: Oh, it's kind of you to say.
- end: '01:35.480'
  start: '01:34.200'
  text: I do want to do that.
- end: '01:38.320'
  start: '01:35.480'
  text: Humanity has obviously a lot of issues
- end: '01:42.640'
  start: '01:38.320'
  text: and people at times do bad things,
- end: '01:47.240'
  start: '01:42.640'
  text: but despite all that, I love humanity
- end: '01:52.280'
  start: '01:47.280'
  text: and I think we should make sure we do everything
- end: '01:54.480'
  start: '01:52.280'
  text: we can to have a good future and an exciting future
- end: '01:58.360'
  start: '01:54.480'
  text: and one where that maximizes the happiness of the people.
- end: '02:00.960'
  start: '01:58.360'
  text: Let me ask about Crew Dragon demo two.
- end: '02:04.400'
  start: '02:00.960'
  text: So that first flight with humans on board,
- end: '02:06.200'
  start: '02:04.400'
  text: how did you feel leading up to that launch?
- end: '02:07.320'
  start: '02:06.200'
  text: Were you scared?
- end: '02:08.320'
  start: '02:07.320'
  text: Were you excited?
- end: '02:09.680'
  start: '02:08.320'
  text: Was going through your mind?
- end: '02:11.400'
  start: '02:09.680'
  text: So much was at stake.
- end: '02:16.400'
  start: '02:12.400'
  text: Yeah, no, that was extremely stressful, no question.
- end: '02:20.400'
  start: '02:16.400'
  text: We obviously could not let them down in any way.
- end: '02:26.400'
  start: '02:20.400'
  text: So extremely stressful, I'd say, to say the least.
- end: '02:29.400'
  start: '02:26.400'
  text: I was confident that at the time that we launched,
- end: '02:35.400'
  start: '02:29.400'
  text: that no one could think of anything at all to do
- end: '02:38.400'
  start: '02:35.400'
  text: that would improve the probability of success
- end: '02:42.400'
  start: '02:39.400'
  text: and we racked our brains to think of any possible way
- end: '02:44.400'
  start: '02:42.400'
  text: to improve the probability of success.
- end: '02:47.400'
  start: '02:44.400'
  text: We could not think of anything more and nor could NASA
- end: '02:51.400'
  start: '02:47.400'
  text: and so that's just the best that we could do.
- end: '02:55.400'
  start: '02:51.400'
  text: So then we went ahead and launched.
- end: '02:58.400'
  start: '02:55.400'
  text: Now, I'm not a religious person,
- end: '03:03.400'
  start: '02:58.400'
  text: but I nonetheless got on my knees and prayed for that mission.
- end: '03:05.400'
  start: '03:03.400'
  text: Were you able to sleep?
- end: '03:07.400'
  start: '03:05.400'
  text: No.
- end: '03:10.400'
  start: '03:07.400'
  text: How did it feel when it was a success?
- end: '03:12.400'
  start: '03:10.400'
  text: First, when the launch was a success
- end: '03:16.400'
  start: '03:12.400'
  text: and when they returned back home or back to Earth?
- end: '03:21.400'
  start: '03:16.400'
  text: It was a great relief, yeah.
- end: '03:23.400'
  start: '03:21.400'
  text: For high stress situations,
- end: '03:28.400'
  start: '03:23.400'
  text: I find it's not so much elation as relief.
- end: '03:33.400'
  start: '03:28.400'
  text: And I think once, as we got more comfortable
- end: '03:38.400'
  start: '03:33.400'
  text: and proved out the systems because we really
- end: '03:40.400'
  start: '03:38.400'
  text: are going to make sure everything works,
- end: '03:43.400'
  start: '03:40.400'
  text: it was definitely a lot more enjoyable
- end: '03:46.400'
  start: '03:43.400'
  text: with the subsequent astronaut missions
- end: '03:49.400'
  start: '03:46.400'
  text: and I thought the inspiration mission
- end: '03:53.400'
  start: '03:49.400'
  text: was actually very inspiring, the inspiration for mission.
- end: '03:56.400'
  start: '03:53.400'
  text: I'd encourage people to watch the inspiration documentary
- end: '03:59.400'
  start: '03:56.400'
  text: on Netflix, it's actually really good.
- end: '04:03.400'
  start: '04:00.400'
  text: I was actually inspired by that.
- end: '04:09.400'
  start: '04:03.400'
  text: So that when I felt I was able to enjoy the actual mission
- end: '04:11.400'
  start: '04:09.400'
  text: and not just be super stressed all the time.
- end: '04:13.400'
  start: '04:11.400'
  text: For people that somehow don't know,
- end: '04:16.400'
  start: '04:13.400'
  text: it's the all-civilian first time,
- end: '04:19.400'
  start: '04:16.400'
  text: all-civilian out to space, out to orbit.
- end: '04:22.400'
  start: '04:19.400'
  text: Yeah, and it was I think the highest orbit
- end: '04:26.400'
  start: '04:22.400'
  text: that in like 30 or 40 years or something.
- end: '04:29.400'
  start: '04:26.400'
  text: The one that was higher was the one shuttle,
- end: '04:32.400'
  start: '04:29.400'
  text: sorry, Hubble servicing mission.
- end: '04:37.400'
  start: '04:32.400'
  text: And then before that, it would have been Apollo in 72.
- end: '04:39.400'
  start: '04:37.400'
  text: It's pretty wild.
- end: '04:40.400'
  start: '04:39.400'
  text: So it's cool.
- end: '04:44.400'
  start: '04:40.400'
  text: I think as a species,
- end: '04:48.400'
  start: '04:44.400'
  text: we want to be continuing to do better
- end: '04:50.400'
  start: '04:48.400'
  text: and reach higher ground.
- end: '04:53.400'
  start: '04:50.400'
  text: I think it would be extremely tragic
- end: '04:56.400'
  start: '04:53.400'
  text: if Apollo was the high watermark for humanity
- end: '04:59.400'
  start: '04:56.400'
  text: and that's as far as we ever got.
- end: '05:04.400'
  start: '04:59.400'
  text: And it's concerning that here we are
- end: '05:08.400'
  start: '05:04.400'
  text: 49 years after the last mission to the moon
- end: '05:13.400'
  start: '05:08.400'
  text: and so almost half a century and we've not been back.
- end: '05:16.400'
  start: '05:13.400'
  text: And that's worrying.
- end: '05:20.400'
  start: '05:16.400'
  text: It's like, does that mean we've peaked as a civilization
- end: '05:21.400'
  start: '05:20.400'
  text: or what?
- end: '05:24.400'
  start: '05:22.400'
  text: We've got to get back to the moon
- end: '05:26.400'
  start: '05:24.400'
  text: and build a base there, a science base.
- end: '05:29.400'
  start: '05:26.400'
  text: I think we could learn a lot about the nature of the universe
- end: '05:32.400'
  start: '05:29.400'
  text: if we have a proper science base on the moon.
- end: '05:35.400'
  start: '05:32.400'
  text: We have a science base in Antarctica
- end: '05:38.400'
  start: '05:35.400'
  text: and many other parts of the world.
- end: '05:41.400'
  start: '05:38.400'
  text: So that's the next big thing.
- end: '05:45.400'
  start: '05:41.400'
  text: We've got to have a serious moon base
- end: '05:49.400'
  start: '05:45.400'
  text: and then get people to Mars and get out there
- end: '05:51.400'
  start: '05:49.400'
  text: and be a space-faring civilization.
- end: '05:53.400'
  start: '05:51.400'
  text: I'll ask you about some of those details,
- end: '05:57.400'
  start: '05:53.400'
  text: but since you're so busy with the hard engineering challenges
- end: '05:59.400'
  start: '05:57.400'
  text: of everything that's involved,
- end: '06:02.400'
  start: '05:59.400'
  text: are you still able to marvel at the magic of it all,
- end: '06:05.400'
  start: '06:02.400'
  text: of space travel, of every time the rocket goes up,
- end: '06:07.400'
  start: '06:05.400'
  text: especially when it's a crewed mission?
- end: '06:09.400'
  start: '06:07.400'
  text: Are you just so overwhelmed
- end: '06:12.400'
  start: '06:09.400'
  text: with all the challenges that you have to solve?
- end: '06:15.400'
  start: '06:12.400'
  text: And actually sort of to add to that,
- end: '06:18.400'
  start: '06:15.400'
  text: the reason I wanted to ask this question of May 30th,
- end: '06:21.400'
  start: '06:18.400'
  text: it's been some time, so you can look back
- end: '06:23.400'
  start: '06:21.400'
  text: and think about the impact already.
- end: '06:26.400'
  start: '06:23.400'
  text: It's already, at the time, it was an engineering problem, maybe.
- end: '06:28.400'
  start: '06:26.400'
  text: Now it's becoming a historic moment.
- end: '06:30.400'
  start: '06:28.400'
  text: Like, it's a moment that...
- end: '06:33.400'
  start: '06:30.400'
  text: How many moments would be remembered about the 21st century?
- end: '06:36.400'
  start: '06:33.400'
  text: To me, that or something like that,
- end: '06:38.400'
  start: '06:36.400'
  text: maybe inspiration for one of those
- end: '06:40.400'
  start: '06:38.400'
  text: would be remembered as the early steps
- end: '06:43.400'
  start: '06:40.400'
  text: of a new age of space exploration.
- end: '06:46.400'
  start: '06:43.400'
  text: Yeah, I mean, during the launches itself,
- end: '06:49.400'
  start: '06:46.400'
  text: so I think maybe some people will know,
- end: '06:51.400'
  start: '06:49.400'
  text: but a lot of people don't know,
- end: '06:54.400'
  start: '06:51.400'
  text: it's like I'm actually the chief engineer of SpaceX,
- end: '06:58.400'
  start: '06:54.400'
  text: so I've signed off on pretty much all the design decisions,
- end: '07:05.400'
  start: '06:58.400'
  text: and so if there's something that goes wrong with that vehicle,
- end: '07:07.400'
  start: '07:05.400'
  text: it's fundamentally my fault.
- end: '07:13.400'
  start: '07:09.400'
  text: So I'm really just thinking about all the things that...
- end: '07:16.400'
  start: '07:13.400'
  text: So when I see the rocket, I see all the things that could go wrong
- end: '07:18.400'
  start: '07:16.400'
  text: and the things that could be better,
- end: '07:21.400'
  start: '07:18.400'
  text: and the same with the Dragon spacecraft.
- end: '07:23.400'
  start: '07:21.400'
  text: Other people will say,
- end: '07:25.400'
  start: '07:23.400'
  text: oh, this is a spacecraft or a rocket,
- end: '07:27.400'
  start: '07:25.400'
  text: and this looks really cool.
- end: '07:30.400'
  start: '07:27.400'
  text: I have a readout of these are the risks,
- end: '07:33.400'
  start: '07:30.400'
  text: these are the problems, that's what I see.
- end: '07:40.400'
  start: '07:37.400'
  text: Not what other people see when they see the product.
- end: '07:44.400'
  start: '07:40.400'
  text: So let me ask you then to analyze Starship in that same way.
- end: '07:47.400'
  start: '07:44.400'
  text: I know you'll talk in more detail about Starship
- end: '07:49.400'
  start: '07:47.400'
  text: in the near future, perhaps.
- end: '07:51.400'
  start: '07:49.400'
  text: Yeah, we'll talk about it now if you want.
- end: '07:53.400'
  start: '07:51.400'
  text: But just in that same way,
- end: '07:57.400'
  start: '07:53.400'
  text: like you said you see when you see a rocket,
- end: '07:59.400'
  start: '07:57.400'
  text: you see a sort of a list of risks.
- end: '08:03.400'
  start: '07:59.400'
  text: In that same way, you said that Starship is a really hard problem.
- end: '08:05.400'
  start: '08:03.400'
  text: So there's many ways I can ask this,
- end: '08:09.400'
  start: '08:05.400'
  text: but if you magically could solve one problem perfectly,
- end: '08:11.400'
  start: '08:09.400'
  text: one engineering problem perfectly,
- end: '08:13.400'
  start: '08:11.400'
  text: which one would it be?
- end: '08:14.400'
  start: '08:13.400'
  text: On Starship?
- end: '08:16.400'
  start: '08:14.400'
  text: Sorry, on Starship.
- end: '08:19.400'
  start: '08:16.400'
  text: So is it maybe related to the efficiency of the engine,
- end: '08:21.400'
  start: '08:19.400'
  text: the weight of the different components,
- end: '08:23.400'
  start: '08:21.400'
  text: the complexity of various things,
- end: '08:26.400'
  start: '08:23.400'
  text: maybe the controls of the crazy thing as to do the land?
- end: '08:31.400'
  start: '08:26.400'
  text: Actually, by far the biggest thing absorbing my time
- end: '08:34.400'
  start: '08:31.400'
  text: is engine production.
- end: '08:36.400'
  start: '08:34.400'
  text: Not the design of the engine.
- end: '08:42.400'
  start: '08:37.400'
  text: I've often said prototypes are easy, production is hard.
- end: '08:48.400'
  start: '08:45.400'
  text: So we have the most advanced rocket engine
- end: '08:50.400'
  start: '08:48.400'
  text: that's ever been designed.
- end: '08:55.400'
  start: '08:52.400'
  text: Because I say currently the best rocket engine ever
- end: '08:58.400'
  start: '08:55.400'
  text: is probably the RD-180 or RD-170,
- end: '09:03.400'
  start: '09:00.400'
  text: that's the door washing engine basically.
- end: '09:06.400'
  start: '09:03.400'
  text: And still, I think an engine should only count
- end: '09:08.400'
  start: '09:06.400'
  text: if it's gotten something to orbit.
- end: '09:12.400'
  start: '09:08.400'
  text: So our engine has not gotten anything to orbit yet.
- end: '09:16.400'
  start: '09:12.400'
  text: But it is, it's the first engine that's actually better
- end: '09:22.400'
  start: '09:16.400'
  text: than the Russian RD engines, which are amazing design.
- end: '09:25.400'
  start: '09:22.400'
  text: So you're talking about Raptor engine, what makes it amazing?
- end: '09:28.400'
  start: '09:25.400'
  text: What are the different aspects of it that make it,
- end: '09:31.400'
  start: '09:28.400'
  text: like what do you get the most excited about
- end: '09:34.400'
  start: '09:31.400'
  text: if the whole thing works in terms of efficiency,
- end: '09:36.400'
  start: '09:34.400'
  text: all those kinds of things?
- end: '09:45.400'
  start: '09:36.400'
  text: Well, it's, but Raptor is a full flow staged combustion engine
- end: '09:50.400'
  start: '09:45.400'
  text: and it's operating at a very high chamber pressure.
- end: '09:52.400'
  start: '09:50.400'
  text: So one of the key figures of merit,
- end: '09:55.400'
  start: '09:52.400'
  text: perhaps the key figure of merit is
- end: '09:59.400'
  start: '09:56.400'
  text: what is the chamber pressure at which the rocket engine
- end: '10:02.400'
  start: '09:59.400'
  text: can operate, that's the combustion chamber pressure.
- end: '10:06.400'
  start: '10:02.400'
  text: So Raptor is designed to operate at 300 bar,
- end: '10:09.400'
  start: '10:06.400'
  text: possibly maybe higher, that's 300 atmospheres.
- end: '10:15.400'
  start: '10:09.400'
  text: So the record right now for operational engine
- end: '10:17.400'
  start: '10:15.400'
  text: is the RD engine that I mentioned, the Russian RD,
- end: '10:21.400'
  start: '10:17.400'
  text: which is I believe around 267 bar.
- end: '10:25.400'
  start: '10:22.400'
  text: And the difficulty of the chamber pressure
- end: '10:27.400'
  start: '10:25.400'
  text: increases on a non-linear basis.
- end: '10:33.400'
  start: '10:27.400'
  text: So 10% more, chamber pressure is more like 50%,
- end: '10:36.400'
  start: '10:33.400'
  text: more difficult.
- end: '10:38.400'
  start: '10:36.400'
  text: But that chamber pressure is,
- end: '10:43.400'
  start: '10:38.400'
  text: that is what allows you to get a very high power density
- end: '10:45.400'
  start: '10:43.400'
  text: for the engine.
- end: '10:52.400'
  start: '10:45.400'
  text: So enabling a very high thrust to weight ratio
- end: '10:56.400'
  start: '10:52.400'
  text: and a very high specific impulse.
- end: '10:59.400'
  start: '10:56.400'
  text: So specific impulse is like a measure of the efficiency
- end: '11:01.400'
  start: '10:59.400'
  text: of a rocket engine.
- end: '11:07.400'
  start: '11:01.400'
  text: It's really the effect of exhaust velocity
- end: '11:10.400'
  start: '11:07.400'
  text: of the gas coming out of the engine.
- end: '11:16.400'
  start: '11:11.400'
  text: So with a very high chamber pressure,
- end: '11:21.400'
  start: '11:16.400'
  text: you can have a compact engine that nonetheless
- end: '11:23.400'
  start: '11:21.400'
  text: has a high expansion ratio,
- end: '11:28.400'
  start: '11:23.400'
  text: which is the ratio between the exit nozzle
- end: '11:31.400'
  start: '11:28.400'
  text: and the throat.
- end: '11:33.400'
  start: '11:31.400'
  text: So you see a rocket engine has got
- end: '11:35.400'
  start: '11:33.400'
  text: sort of like an hourglass shape,
- end: '11:37.400'
  start: '11:35.400'
  text: it's like a chamber and then it necks down
- end: '11:39.400'
  start: '11:37.400'
  text: and there's a nozzle.
- end: '11:44.400'
  start: '11:39.400'
  text: And the ratio of the exit diameter to the throat
- end: '11:46.400'
  start: '11:44.400'
  text: is the expansion ratio.
- end: '11:51.400'
  start: '11:46.400'
  text: So why is it such a hard engine to manufacture at scale?
- end: '11:53.400'
  start: '11:51.400'
  text: It's very complex.
- end: '11:55.400'
  start: '11:53.400'
  text: So what is complexity mean here?
- end: '11:57.400'
  start: '11:55.400'
  text: There's a lot of components involved.
- end: '12:02.400'
  start: '11:57.400'
  text: There's a lot of components and a lot of unique materials.
- end: '12:07.400'
  start: '12:02.400'
  text: So we had to invent several alloys
- end: '12:11.400'
  start: '12:07.400'
  text: that exist in order to make this engine work.
- end: '12:14.400'
  start: '12:11.400'
  text: It's a materials problem too.
- end: '12:19.400'
  start: '12:14.400'
  text: It's a materials problem and in a stage combustion,
- end: '12:21.400'
  start: '12:19.400'
  text: a full flow stage combustion,
- end: '12:24.400'
  start: '12:21.400'
  text: there are many feedback loops in the system.
- end: '12:30.400'
  start: '12:24.400'
  text: So basically you've got propellants
- end: '12:36.400'
  start: '12:30.400'
  text: and hot gas flowing simultaneously
- end: '12:38.400'
  start: '12:36.400'
  text: for places on the engine
- end: '12:43.400'
  start: '12:38.400'
  text: and they all have a recursive effect on each other.
- end: '12:45.400'
  start: '12:43.400'
  text: So you change one thing here,
- end: '12:47.400'
  start: '12:45.400'
  text: it has a recursive effect here,
- end: '12:49.400'
  start: '12:47.400'
  text: it changes something over there
- end: '12:52.400'
  start: '12:49.400'
  text: and it's quite hard to control.
- end: '12:55.400'
  start: '12:52.400'
  text: Like there's a reason no one's made this before.
- end: '13:04.400'
  start: '12:55.400'
  text: But the reason we're doing a stage combustion full flow
- end: '13:12.400'
  start: '13:04.400'
  text: is because it has the highest theoretical possible efficiency.
- end: '13:19.400'
  start: '13:12.400'
  text: So in order to make a fully reusable rocket,
- end: '13:25.400'
  start: '13:19.400'
  text: that's really the holy grail of orbital rocketry.
- end: '13:28.400'
  start: '13:25.400'
  text: You have to have, everything's got to be the best.
- end: '13:30.400'
  start: '13:28.400'
  text: It's got to be the best engine,
- end: '13:33.400'
  start: '13:30.400'
  text: the best airframe, the best heat shield,
- end: '13:37.400'
  start: '13:33.400'
  text: extremely light avionics,
- end: '13:40.400'
  start: '13:37.400'
  text: very clever control mechanisms.
- end: '13:44.400'
  start: '13:40.400'
  text: You've got to shed mass in any possible way that you can.
- end: '13:48.400'
  start: '13:44.400'
  text: For example, instead of putting landing legs on the booster and ship,
- end: '13:50.400'
  start: '13:48.400'
  text: we are going to catch them with a tower
- end: '13:53.400'
  start: '13:50.400'
  text: to save the weight of the landing legs.
- end: '13:56.400'
  start: '13:53.400'
  text: So that's like, I mean,
- end: '14:01.400'
  start: '13:56.400'
  text: we're talking about catching the largest flying object ever made
- end: '14:06.400'
  start: '14:02.400'
  text: on a giant tower with chopstick arms.
- end: '14:09.400'
  start: '14:06.400'
  text: It's like a karate kid with the fly, but much bigger.
- end: '14:15.400'
  start: '14:12.400'
  text: This probably won't work the first time.
- end: '14:19.400'
  start: '14:17.400'
  text: Anyway, so this is bananas, this is banana stuff.
- end: '14:21.400'
  start: '14:19.400'
  text: So you mentioned that you doubt,
- end: '14:23.400'
  start: '14:21.400'
  text: well, not you doubt,
- end: '14:27.400'
  start: '14:23.400'
  text: but there's days or moments when you doubt that this is even possible.
- end: '14:29.400'
  start: '14:27.400'
  text: It's so difficult.
- end: '14:32.400'
  start: '14:29.400'
  text: The possible part is,
- end: '14:34.400'
  start: '14:32.400'
  text: well, at this point,
- end: '14:37.400'
  start: '14:34.400'
  text: I think we will get Starship to work.
- end: '14:42.400'
  start: '14:40.400'
  text: There's a question of timing.
- end: '14:44.400'
  start: '14:42.400'
  text: How long will it take us to do this?
- end: '14:49.400'
  start: '14:44.400'
  text: How long will it take us to actually achieve full and rapid reusability?
- end: '14:52.400'
  start: '14:49.400'
  text: Because it will take many launches
- end: '14:55.400'
  start: '14:52.400'
  text: before we are able to have full and rapid reusability.
- end: '15:01.400'
  start: '14:56.400'
  text: But I can say that the physics pencils out,
- end: '15:03.400'
  start: '15:01.400'
  text: like we're not,
- end: '15:08.400'
  start: '15:05.400'
  text: at this point, I'd say we're confident that,
- end: '15:13.400'
  start: '15:08.400'
  text: like let's say, I'm very confident that success is in the set of all possible
    outcomes.
- end: '15:21.400'
  start: '15:16.400'
  text: For a while there, I was not convinced that success was in the set of possible
    outcomes,
- end: '15:23.400'
  start: '15:21.400'
  text: which is very important actually.
- end: '15:25.400'
  start: '15:23.400'
  text: But so we were...
- end: '15:29.400'
  start: '15:27.400'
  text: You were saying there's a chance.
- end: '15:31.400'
  start: '15:29.400'
  text: I'm saying there's a chance, exactly.
- end: '15:37.400'
  start: '15:32.400'
  text: I'm just not sure how long it will take.
- end: '15:39.400'
  start: '15:37.400'
  text: We have a very talented team.
- end: '15:42.400'
  start: '15:39.400'
  text: They're working night and day to make it happen.
- end: '15:49.400'
  start: '15:45.400'
  text: And like I said, the critical thing to achieve for the revolution in spaceflight
- end: '15:54.400'
  start: '15:49.400'
  text: and for humanity to be a space-faring civilization is to have a fully and
    rapidly reusable rocket,
- end: '15:56.400'
  start: '15:54.400'
  text: orbital rocket.
- end: '16:00.400'
  start: '15:56.400'
  text: There's not even been any orbital rocket that's been fully reusable ever.
- end: '16:05.400'
  start: '16:00.400'
  text: And this has always been the holy grail of rocketry.
- end: '16:09.400'
  start: '16:05.400'
  text: And many smart people, very smart people,
- end: '16:13.400'
  start: '16:09.400'
  text: have tried to do this before and they've not succeeded.
- end: '16:16.400'
  start: '16:13.400'
  text: Because it's such a hard problem.
- end: '16:20.400'
  start: '16:16.400'
  text: What's your source of belief in situations like this?
- end: '16:24.400'
  start: '16:20.400'
  text: When the engineering problem is so difficult, there's a lot of experts,
- end: '16:28.400'
  start: '16:24.400'
  text: many of whom you admire who have failed in the past.
- end: '16:29.400'
  start: '16:28.400'
  text: Yes.
- end: '16:33.400'
  start: '16:29.400'
  text: And a lot of people,
- end: '16:38.400'
  start: '16:35.400'
  text: a lot of experts, maybe journalists, all the kind of...
- end: '16:42.400'
  start: '16:38.400'
  text: The public in general have a lot of doubt about whether it's possible.
- end: '16:49.400'
  start: '16:43.400'
  text: And you yourself know that even if it's a non-null set, non-empty set of success,
- end: '16:51.400'
  start: '16:49.400'
  text: it's still unlikely or very difficult.
- end: '16:53.400'
  start: '16:51.400'
  text: Like where do you go to?
- end: '16:58.400'
  start: '16:53.400'
  text: Both personally, intellectually as an engineer, as a team,
- end: '17:03.400'
  start: '16:58.400'
  text: like for source of strength needed to sort of persevere through this.
- end: '17:06.400'
  start: '17:03.400'
  text: And to keep going with the project, take it to completion.
- end: '17:18.400'
  start: '17:13.400'
  text: Source of strength.
- end: '17:21.400'
  start: '17:18.400'
  text: I just really know how I think about things.
- end: '17:26.400'
  start: '17:21.400'
  text: I mean, for me, it's simply this is something that is important to get done.
- end: '17:31.400'
  start: '17:26.400'
  text: And we should just keep doing it or die trying.
- end: '17:35.400'
  start: '17:31.400'
  text: And I don't need source of strength.
- end: '17:38.400'
  start: '17:35.400'
  text: So quitting is not even like...
- end: '17:40.400'
  start: '17:38.400'
  text: It's not in my nature.
- end: '17:45.400'
  start: '17:41.400'
  text: And I don't care about optimism or pessimism.
- end: '17:47.400'
  start: '17:45.400'
  text: Fuck that, we're gonna get it done.
- end: '17:49.400'
  start: '17:47.400'
  text: Gonna get it done.
- end: '17:55.400'
  start: '17:51.400'
  text: Can you then zoom back in to specific problems with starship
- end: '17:57.400'
  start: '17:55.400'
  text: or any engineering problems you work on?
- end: '18:01.400'
  start: '17:57.400'
  text: Can you try to introspect your particular biological neural network,
- end: '18:05.400'
  start: '18:01.400'
  text: your thinking process and describe how you think through problems,
- end: '18:07.400'
  start: '18:05.400'
  text: the different engineering and design problems?
- end: '18:09.400'
  start: '18:07.400'
  text: Is there like a systematic process?
- end: '18:11.400'
  start: '18:09.400'
  text: You've spoken about first principles, thinking,
- end: '18:13.400'
  start: '18:11.400'
  text: but is there a kind of process to it?
- end: '18:18.400'
  start: '18:13.400'
  text: Well, you know, like saying like physics is low
- end: '18:20.400'
  start: '18:18.400'
  text: and everything else is a recommendation.
- end: '18:22.400'
  start: '18:20.400'
  text: Like I've met a lot of people that can break the law,
- end: '18:25.400'
  start: '18:22.400'
  text: but I haven't met anyone who could break physics.
- end: '18:31.400'
  start: '18:25.400'
  text: So first, for any kind of technology problem,
- end: '18:37.400'
  start: '18:31.400'
  text: you have to sort of just make sure you're not violating physics.
- end: '18:44.400'
  start: '18:39.400'
  text: And, you know, first principles analysis,
- end: '18:48.400'
  start: '18:44.400'
  text: I think is something that could be applied to really any walk of life,
- end: '18:50.400'
  start: '18:48.400'
  text: anything really.
- end: '18:54.400'
  start: '18:50.400'
  text: It's really just saying, you know, let's boil something down
- end: '18:58.400'
  start: '18:54.400'
  text: to the most fundamental principles,
- end: '19:02.400'
  start: '18:58.400'
  text: the things that we are most confident are true at a foundational level.
- end: '19:06.400'
  start: '19:02.400'
  text: And that sets your axiomatic base and then you reason up from there
- end: '19:11.400'
  start: '19:06.400'
  text: and then you cross check your conclusion against the axiomatic truths.
- end: '19:17.400'
  start: '19:11.400'
  text: So, you know, some basics in physics would be like,
- end: '19:19.400'
  start: '19:17.400'
  text: are you violating conservation of energy or momentum
- end: '19:24.400'
  start: '19:19.400'
  text: or something like that, you know, then you're not going to work.
- end: '19:32.400'
  start: '19:24.400'
  text: So that's just to establish, is it possible?
- end: '19:36.400'
  start: '19:32.400'
  text: And another good physics tool is thinking about things in the limit.
- end: '19:41.400'
  start: '19:36.400'
  text: If you take a particular thing and you scale it to a very large number
- end: '19:45.400'
  start: '19:41.400'
  text: or to a very small number, how do things change?
- end: '19:49.400'
  start: '19:45.400'
  text: Both like in number of things you manufacture, something like that,
- end: '19:51.400'
  start: '19:49.400'
  text: and then in time?
- end: '19:55.400'
  start: '19:51.400'
  text: Yeah, like let's say, take an example of like manufacturing,
- end: '19:59.400'
  start: '19:55.400'
  text: which I think is just a very underrated problem.
- end: '20:09.400'
  start: '20:00.400'
  text: And like I said, it's much harder to take an advanced technology product
- end: '20:12.400'
  start: '20:09.400'
  text: and bring it into volume manufacturing than it is to design it in the first
    place,
- end: '20:14.400'
  start: '20:12.400'
  text: or as magnitude.
- end: '20:19.400'
  start: '20:14.400'
  text: So let's say you're trying to figure out is like,
- end: '20:23.400'
  start: '20:19.400'
  text: why is this part or product expensive?
- end: '20:27.400'
  start: '20:23.400'
  text: Is it because of something fundamentally foolish that we're doing
- end: '20:30.400'
  start: '20:27.400'
  text: or is it because our volume is too low?
- end: '20:33.400'
  start: '20:30.400'
  text: And so then you say, okay, well, what if our volume was a million units a
    year?
- end: '20:35.400'
  start: '20:33.400'
  text: Is it still expensive?
- end: '20:37.400'
  start: '20:35.400'
  text: That's what I mean by thinking about things in the limit.
- end: '20:39.400'
  start: '20:37.400'
  text: If it's still expensive at a million units a year,
- end: '20:42.400'
  start: '20:39.400'
  text: then volume is not the reason why your thing is expensive.
- end: '20:44.400'
  start: '20:42.400'
  text: There's something fundamental about design.
- end: '20:48.400'
  start: '20:44.400'
  text: And then you then can focus on reducing complexity or something like that.
- end: '20:55.400'
  start: '20:48.400'
  text: Change the design to change the part to be something that is not fundamentally
    expensive.
- end: '21:01.400'
  start: '20:56.400'
  text: But that's a common thing in rocketry because the unit volume is relatively
    low.
- end: '21:06.400'
  start: '21:01.400'
  text: And so a common excuse would be, well, it's expensive because our unit volume
    is low.
- end: '21:09.400'
  start: '21:06.400'
  text: And if we were in like automotive or something like that or consumer electronics,
- end: '21:11.400'
  start: '21:09.400'
  text: then our costs would be lower.
- end: '21:14.400'
  start: '21:11.400'
  text: I'm like, okay, so let's say now you're making a million units a year.
- end: '21:15.400'
  start: '21:14.400'
  text: Is it still expensive?
- end: '21:21.400'
  start: '21:15.400'
  text: If the answer is yes, then economies of scale are not the issue.
- end: '21:25.400'
  start: '21:21.400'
  text: Do you throw into manufacturing, do you throw like supply chain,
- end: '21:28.400'
  start: '21:25.400'
  text: talk about resources and materials and stuff like that?
- end: '21:31.400'
  start: '21:28.400'
  text: Do you throw that into the calculation of trying to reason from first principles
- end: '21:34.400'
  start: '21:31.400'
  text: like how we're going to make the supply chain work here?
- end: '21:35.400'
  start: '21:34.400'
  text: Yeah, yeah.
- end: '21:37.400'
  start: '21:35.400'
  text: And then the cost of materials, things like that?
- end: '21:38.400'
  start: '21:37.400'
  text: Or is that too much?
- end: '21:39.400'
  start: '21:38.400'
  text: Yeah, exactly.
- end: '21:45.400'
  start: '21:40.400'
  text: Another good example I think of thinking about things in the limit is,
- end: '21:53.400'
  start: '21:45.400'
  text: if you take any product, any machine or whatever,
- end: '21:58.400'
  start: '21:53.400'
  text: like take a rocket or whatever and say,
- end: '22:03.400'
  start: '21:58.400'
  text: if you look at the raw materials in the rocket,
- end: '22:07.400'
  start: '22:03.400'
  text: so you're going to have like an aluminum, steel, titanium,
- end: '22:13.400'
  start: '22:07.400'
  text: Inconel, specialty alloys, copper,
- end: '22:20.400'
  start: '22:13.400'
  text: and you say, what's the weight of the constituent elements of each of these
    elements
- end: '22:22.400'
  start: '22:20.400'
  text: and what is their raw material value?
- end: '22:29.400'
  start: '22:22.400'
  text: And that sets the asymptotic limit for how low the cost of the vehicle can
    be
- end: '22:31.400'
  start: '22:29.400'
  text: unless you change the materials.
- end: '22:33.400'
  start: '22:31.400'
  text: So, and then when you do that,
- end: '22:36.400'
  start: '22:33.400'
  text: I call it like maybe the magic wand number or something like that.
- end: '22:39.400'
  start: '22:36.400'
  text: So that would be like, if you had the, you know,
- end: '22:43.400'
  start: '22:39.400'
  text: like just a pile of these raw materials here and you could wave the magic
    wand
- end: '22:46.400'
  start: '22:43.400'
  text: and rearrange the atoms into the final shape,
- end: '22:50.400'
  start: '22:46.400'
  text: that would be the lowest possible cost that you could make this thing for
- end: '22:52.400'
  start: '22:50.400'
  text: unless you change the materials.
- end: '22:57.400'
  start: '22:52.400'
  text: So then, and that is always, almost always a very low number.
- end: '23:01.400'
  start: '22:57.400'
  text: So then what's actually causing things to be expensive
- end: '23:05.400'
  start: '23:01.400'
  text: is how you put the atoms into the desired shape.
- end: '23:09.400'
  start: '23:05.400'
  text: Yeah, actually, if you don't mind me taking a tiny tangent,
- end: '23:13.400'
  start: '23:09.400'
  text: I often talk to Jim Keller, who's somebody that worked with you as a friend.
- end: '23:17.400'
  start: '23:13.400'
  text: Oh, yeah, Jim was, yeah, did great work at Tesla.
- end: '23:22.400'
  start: '23:17.400'
  text: So, I suppose he carries the flame of the same kind of thinking
- end: '23:25.400'
  start: '23:22.400'
  text: that you're talking about now.
- end: '23:30.400'
  start: '23:25.400'
  text: And I guess I see that same thing at Tesla and SpaceX folks
- end: '23:33.400'
  start: '23:30.400'
  text: who worked there, they kind of learned this way of thinking
- end: '23:36.400'
  start: '23:33.400'
  text: and it kind of becomes obvious almost.
- end: '23:40.400'
  start: '23:36.400'
  text: But anyway, I had argument, not argument,
- end: '23:46.400'
  start: '23:40.400'
  text: he educated me about how cheap it might be to manufacture a Tesla bot.
- end: '23:48.400'
  start: '23:46.400'
  text: We just, we had an argument.
- end: '23:51.400'
  start: '23:48.400'
  text: How can you reduce the cost, the scale of producing a robot?
- end: '23:55.400'
  start: '23:51.400'
  text: Because I've gotten a chance to interact quite a bit,
- end: '23:59.400'
  start: '23:55.400'
  text: obviously in the academic circles with human robots
- end: '24:01.400'
  start: '23:59.400'
  text: and then my Boston Dynamics and stuff like that.
- end: '24:04.400'
  start: '24:01.400'
  text: And then they're very expensive to build.
- end: '24:07.400'
  start: '24:04.400'
  text: And then Jim kind of schooled me on saying like,
- end: '24:09.400'
  start: '24:07.400'
  text: okay, like this kind of first principles thinking
- end: '24:12.400'
  start: '24:09.400'
  text: of how can we get the cost of manufacturing down?
- end: '24:17.400'
  start: '24:12.400'
  text: I suppose you do that, you have done that kind of thinking for Tesla bot
- end: '24:21.400'
  start: '24:17.400'
  text: and for all kinds of complex systems
- end: '24:23.400'
  start: '24:21.400'
  text: that are traditionally seen as complex.
- end: '24:26.400'
  start: '24:23.400'
  text: And you say, okay, how can we simplify everything down?
- end: '24:28.400'
  start: '24:26.400'
  text: Yeah.
- end: '24:31.400'
  start: '24:28.400'
  text: I mean, I think if you are really good at manufacturing,
- end: '24:35.400'
  start: '24:31.400'
  text: you can basically make at high volume,
- end: '24:38.400'
  start: '24:35.400'
  text: you can basically make anything for a cost
- end: '24:42.400'
  start: '24:38.400'
  text: that asymptotically approaches the raw material value of the constituents
- end: '24:46.400'
  start: '24:42.400'
  text: plus any intellectual property that you need to do license.
- end: '24:49.400'
  start: '24:46.400'
  text: Anything.
- end: '24:50.400'
  start: '24:49.400'
  text: But it's hard.
- end: '24:52.400'
  start: '24:50.400'
  text: It's not like that's a very hard thing to do,
- end: '24:54.400'
  start: '24:52.400'
  text: but it is possible for anything.
- end: '24:57.400'
  start: '24:54.400'
  text: Anything in volume can be made of, like I said,
- end: '25:00.400'
  start: '24:57.400'
  text: for a cost that asymptotically approaches
- end: '25:02.400'
  start: '25:00.400'
  text: the raw material constituents
- end: '25:05.400'
  start: '25:02.400'
  text: plus intellectual property license rights.
- end: '25:08.400'
  start: '25:05.400'
  text: So what will often happen in trying to design a product
- end: '25:12.400'
  start: '25:08.400'
  text: is people will start with the tools and parts and methods
- end: '25:14.400'
  start: '25:12.400'
  text: that they are familiar with
- end: '25:20.400'
  start: '25:14.400'
  text: and then try to create a product using their existing tools and methods.
- end: '25:25.400'
  start: '25:20.400'
  text: The other way to think about it is actually try to imagine
- end: '25:28.400'
  start: '25:25.400'
  text: the platonic ideal of the perfect product
- end: '25:31.400'
  start: '25:28.400'
  text: or technology, whatever it might be.
- end: '25:35.400'
  start: '25:31.400'
  text: And so what is the perfect arrangement of atoms
- end: '25:38.400'
  start: '25:35.400'
  text: that would be the best possible product?
- end: '25:43.400'
  start: '25:38.400'
  text: And now let us try to figure out how to get the atoms in that shape.
- end: '25:50.400'
  start: '25:43.400'
  text: I mean, it sounds almost like Rick and Morty absurd
- end: '25:52.400'
  start: '25:50.400'
  text: until you start to really think about it
- end: '25:56.400'
  start: '25:52.400'
  text: and you really should think about it in this way
- end: '25:58.400'
  start: '25:56.400'
  text: because everything else is kind of...
- end: '26:00.400'
  start: '25:58.400'
  text: If you think...
- end: '26:04.400'
  start: '26:00.400'
  text: You might fall victim to the momentum of the way things were done in the past
- end: '26:06.400'
  start: '26:04.400'
  text: unless you think in this way.
- end: '26:08.400'
  start: '26:06.400'
  text: Well, just as a function of inertia,
- end: '26:12.400'
  start: '26:08.400'
  text: people want to use the same tools and methods that they are familiar with.
- end: '26:15.400'
  start: '26:13.400'
  text: That is what they will do by default.
- end: '26:18.400'
  start: '26:15.400'
  text: And then that will lead to an outcome of things
- end: '26:20.400'
  start: '26:18.400'
  text: that can be made with those tools and methods
- end: '26:25.400'
  start: '26:20.400'
  text: but it is unlikely to be the platonic ideal of the perfect product.
- end: '26:30.400'
  start: '26:25.400'
  text: So that is why it is good to think of things in both directions.
- end: '26:32.400'
  start: '26:30.400'
  text: What can we build with the tools that we have?
- end: '26:37.400'
  start: '26:32.400'
  text: But also what is the theoretical perfect product look like?
- end: '26:40.400'
  start: '26:37.400'
  text: And that theoretical perfect product is going to be a moving target
- end: '26:42.400'
  start: '26:40.400'
  text: because as you learn more,
- end: '26:46.400'
  start: '26:42.400'
  text: the definition for that perfect product will change
- end: '26:48.400'
  start: '26:46.400'
  text: because you don't actually know what the perfect product is
- end: '26:53.400'
  start: '26:48.400'
  text: but you can successfully approximate a more perfect product.
- end: '26:56.400'
  start: '26:53.400'
  text: So think about it like that and then saying,
- end: '27:02.400'
  start: '26:56.400'
  text: okay, now what tools, methods, materials, whatever do we need to create
- end: '27:05.400'
  start: '27:02.400'
  text: in order to get the atoms in that shape?
- end: '27:09.400'
  start: '27:05.400'
  text: But people rarely think about it that way.
- end: '27:12.400'
  start: '27:09.400'
  text: But it's a powerful tool.
- end: '27:18.400'
  start: '27:12.400'
  text: I should mention that the brilliant Siobhan Zillis is hanging out with us
- end: '27:25.400'
  start: '27:18.400'
  text: in case you hear a voice of wisdom from outside, from up above.
- end: '27:28.400'
  start: '27:25.400'
  text: Okay, so let me ask you about Mars.
- end: '27:33.400'
  start: '27:28.400'
  text: You mentioned it would be great for science to put a base on the moon
- end: '27:38.400'
  start: '27:33.400'
  text: to do some research but the truly big leap,
- end: '27:40.400'
  start: '27:38.400'
  text: again in this category of seemingly impossible,
- end: '27:43.400'
  start: '27:40.400'
  text: is to put a human being on Mars.
- end: '27:48.400'
  start: '27:43.400'
  text: When do you think SpaceX will land a human being on Mars?
- end: '28:16.400'
  start: '28:08.400'
  text: Best case is about five years, worst case ten years.
- end: '28:19.400'
  start: '28:16.400'
  text: What are the determining factors, would you say,
- end: '28:23.400'
  start: '28:19.400'
  text: from an engineering perspective or is that not the bottlenecks?
- end: '28:32.400'
  start: '28:23.400'
  text: You know, it's fundamentally engineering the vehicle.
- end: '28:36.400'
  start: '28:32.400'
  text: I mean, Starship is the most complex and advanced rocket
- end: '28:39.400'
  start: '28:36.400'
  text: that's ever been made by, I don't know,
- end: '28:42.400'
  start: '28:39.400'
  text: whatever magnitude or something like that, it's a lot.
- end: '28:46.400'
  start: '28:42.400'
  text: It's really next level.
- end: '28:49.400'
  start: '28:46.400'
  text: And the fundamental optimization of Starship
- end: '28:51.400'
  start: '28:49.400'
  text: is minimizing cost per ton to orbit
- end: '28:54.400'
  start: '28:51.400'
  text: and ultimately cost per ton to the surface of Mars.
- end: '28:56.400'
  start: '28:54.400'
  text: This may seem like a mercantile objective
- end: '29:00.400'
  start: '28:56.400'
  text: but it is actually the thing that needs to be optimized.
- end: '29:04.400'
  start: '29:00.400'
  text: Like there is a certain cost per ton to the surface of Mars
- end: '29:08.400'
  start: '29:04.400'
  text: that we can afford to establish a self-sustaining city
- end: '29:12.400'
  start: '29:08.400'
  text: and then above that we cannot afford to do it.
- end: '29:16.400'
  start: '29:12.400'
  text: So right now, you couldn't fly to Mars for a trillion dollars.
- end: '29:19.400'
  start: '29:16.400'
  text: No amount of money could get you a ticket to Mars.
- end: '29:22.400'
  start: '29:19.400'
  text: So we need to get that above, you know,
- end: '29:27.400'
  start: '29:22.400'
  text: to get that like something that is actually possible at all.
- end: '29:32.400'
  start: '29:27.400'
  text: But then, we don't just want to have, you know,
- end: '29:34.400'
  start: '29:32.400'
  text: Mars flags and footprints and then not come back
- end: '29:37.400'
  start: '29:34.400'
  text: for a half century like we did with the moon.
- end: '29:43.400'
  start: '29:37.400'
  text: In order to pass a very important, great filter,
- end: '29:48.400'
  start: '29:43.400'
  text: I think we need to be a multi-planet species.
- end: '29:51.400'
  start: '29:48.400'
  text: That sounds somewhat esoteric to a lot of people
- end: '29:56.400'
  start: '29:51.400'
  text: but eventually, given enough time,
- end: '30:01.400'
  start: '29:56.400'
  text: there's something, Earth is likely to experience some calamity.
- end: '30:06.400'
  start: '30:01.400'
  text: There could be something that humans do to themselves
- end: '30:10.400'
  start: '30:06.400'
  text: or an external event like happen to the dinosaurs.
- end: '30:17.400'
  start: '30:10.400'
  text: And eventually, if none of that happens
- end: '30:20.400'
  start: '30:17.400'
  text: and somehow magically we keep going,
- end: '30:24.400'
  start: '30:20.400'
  text: then the sun is gradually expanding
- end: '30:26.400'
  start: '30:24.400'
  text: and we'll engulf the Earth
- end: '30:34.400'
  start: '30:26.400'
  text: and probably Earth gets too hot for life in about 500 million years.
- end: '30:38.400'
  start: '30:34.400'
  text: It's a long time but that's only 10% longer than Earth has been around.
- end: '30:42.400'
  start: '30:38.400'
  text: And so if you think about like the current situation,
- end: '30:45.400'
  start: '30:42.400'
  text: it's really remarkable and kind of hard to believe
- end: '30:49.400'
  start: '30:45.400'
  text: but Earth's been around four and a half billion years
- end: '30:52.400'
  start: '30:49.400'
  text: and this is the first time in four and a half billion years
- end: '30:55.400'
  start: '30:52.400'
  text: that it's been possible to extend life beyond Earth.
- end: '30:58.400'
  start: '30:55.400'
  text: And that window of charity may be open for a long time
- end: '31:01.400'
  start: '30:58.400'
  text: and I hope it is but it also may be open for a short time
- end: '31:10.400'
  start: '31:01.400'
  text: and I think it was wise for us to act quickly while the window is open,
- end: '31:13.400'
  start: '31:10.400'
  text: just in case it closes.
- end: '31:17.400'
  start: '31:13.400'
  text: Yeah, the existence of nuclear weapons, pandemics,
- end: '31:24.400'
  start: '31:17.400'
  text: all kinds of threats should kind of give us some motivation.
- end: '31:30.400'
  start: '31:24.400'
  text: I mean civilization could die with a bang or a whimper.
- end: '31:37.400'
  start: '31:30.400'
  text: If it dies, the demographic collapse, then it's more of a whimper, obviously.
- end: '31:40.400'
  start: '31:37.400'
  text: But if it's World War III, it's more of a bang.
- end: '31:42.400'
  start: '31:40.400'
  text: But these are all risks.
- end: '31:44.400'
  start: '31:42.400'
  text: I mean it's important to think of these things
- end: '31:48.400'
  start: '31:44.400'
  text: and just think of things as like probabilities, not certainties.
- end: '31:52.400'
  start: '31:48.400'
  text: There's a probability that something bad will happen on Earth.
- end: '31:56.400'
  start: '31:52.400'
  text: I think most likely the future will be good.
- end: '31:59.400'
  start: '31:56.400'
  text: But there's like, let's say for argument's sake,
- end: '32:03.400'
  start: '31:59.400'
  text: a 1% chance per century of a civilization ending event.
- end: '32:07.400'
  start: '32:03.400'
  text: Like that was Stephen Hawking's estimate.
- end: '32:10.400'
  start: '32:07.400'
  text: I think he might be right about that.
- end: '32:18.400'
  start: '32:10.400'
  text: So then we should basically think of this like
- end: '32:21.400'
  start: '32:18.400'
  text: being a multi-planet species is like taking out insurance for life itself.
- end: '32:26.400'
  start: '32:21.400'
  text: Like life insurance for life.
- end: '32:29.400'
  start: '32:26.400'
  text: It's turned into an infomercial real quick.
- end: '32:31.400'
  start: '32:29.400'
  text: Life insurance for life, yes.
- end: '32:37.400'
  start: '32:31.400'
  text: And we can bring the creatures from plants and animals from Earth
- end: '32:41.400'
  start: '32:37.400'
  text: to Mars and breathe life into the planet
- end: '32:44.400'
  start: '32:41.400'
  text: and have a second planet with life.
- end: '32:45.400'
  start: '32:44.400'
  text: That would be great.
- end: '32:47.400'
  start: '32:45.400'
  text: They can't bring themselves there.
- end: '32:49.400'
  start: '32:47.400'
  text: So if we don't bring them to Mars,
- end: '32:54.400'
  start: '32:49.400'
  text: then they will just for sure all die when the sun expands anyway.
- end: '32:55.400'
  start: '32:54.400'
  text: And then that'll be it.
- end: '33:00.400'
  start: '32:55.400'
  text: What do you think is the most difficult aspect of building a civilization
    on Mars?
- end: '33:03.400'
  start: '33:00.400'
  text: Terraforming Mars, like from an engineering perspective,
- end: '33:06.400'
  start: '33:03.400'
  text: from a financial perspective, human perspective,
- end: '33:15.400'
  start: '33:06.400'
  text: to get a large number of folks there who will never return back to Earth?
- end: '33:16.400'
  start: '33:15.400'
  text: No, they could certainly return.
- end: '33:18.400'
  start: '33:16.400'
  text: Some will return back to Earth.
- end: '33:21.400'
  start: '33:18.400'
  text: They will choose to stay there for the rest of their lives.
- end: '33:23.400'
  start: '33:21.400'
  text: Many will.
- end: '33:29.400'
  start: '33:23.400'
  text: But we need the spaceships back, like the ones that go to Mars.
- end: '33:30.400'
  start: '33:29.400'
  text: We need them back.
- end: '33:32.400'
  start: '33:30.400'
  text: So you can hop on if you want.
- end: '33:34.400'
  start: '33:32.400'
  text: But we can't just not have the spaceships come back.
- end: '33:35.400'
  start: '33:34.400'
  text: Those things are expensive.
- end: '33:36.400'
  start: '33:35.400'
  text: We need them back.
- end: '33:38.400'
  start: '33:36.400'
  text: I'd like to come back during the trip.
- end: '33:40.400'
  start: '33:38.400'
  text: I mean, do you think about the terraforming aspect,
- end: '33:44.400'
  start: '33:40.400'
  text: like actually building, are you so focused right now on the spaceships part
- end: '33:45.400'
  start: '33:44.400'
  text: that's so critical to get to Mars?
- end: '33:47.400'
  start: '33:46.400'
  text: Absolutely.
- end: '33:49.400'
  start: '33:47.400'
  text: If you can't get there, nothing else matters.
- end: '33:54.400'
  start: '33:49.400'
  text: And like I said, we can't get there at some extraordinarily high cost.
- end: '33:59.400'
  start: '33:54.400'
  text: I mean, the current cost of, let's say, one ton to the surface of Mars
- end: '34:02.400'
  start: '33:59.400'
  text: is on the order of a billion dollars.
- end: '34:05.400'
  start: '34:02.400'
  text: Because you don't just need the rocket and the launch and everything.
- end: '34:06.400'
  start: '34:05.400'
  text: You need heat shield.
- end: '34:09.400'
  start: '34:06.400'
  text: You need guidance system.
- end: '34:11.400'
  start: '34:09.400'
  text: You need deep space communications.
- end: '34:14.400'
  start: '34:11.400'
  text: You need some kind of landing system.
- end: '34:19.400'
  start: '34:14.400'
  text: So like rough approximation would be a billion dollars per ton
- end: '34:21.400'
  start: '34:19.400'
  text: to the surface of Mars right now.
- end: '34:26.400'
  start: '34:21.400'
  text: This is obviously way too expensive
- end: '34:30.400'
  start: '34:26.400'
  text: to create a self-sustaining civilization.
- end: '34:36.400'
  start: '34:30.400'
  text: So we need to improve that by at least a factor of a thousand.
- end: '34:38.400'
  start: '34:36.400'
  text: A million per ton?
- end: '34:40.400'
  start: '34:38.400'
  text: Yes, ideally much less than a million ton.
- end: '34:44.400'
  start: '34:40.400'
  text: But if it's not, like it's got to be, you have to say like,
- end: '34:47.400'
  start: '34:44.400'
  text: well, how much can society afford to spend
- end: '34:51.400'
  start: '34:47.400'
  text: or just want to spend on a self-sustaining city on Mars?
- end: '34:53.400'
  start: '34:51.400'
  text: The self-sustaining part is important.
- end: '35:00.400'
  start: '34:53.400'
  text: Like it's just the key threshold, the great filter will have been passed
- end: '35:06.400'
  start: '35:00.400'
  text: when the city on Mars can survive even if the spaceships from Earth
- end: '35:08.400'
  start: '35:06.400'
  text: stop coming for any reason.
- end: '35:11.400'
  start: '35:08.400'
  text: It doesn't matter what the reason is, but if they stop coming for any reason,
- end: '35:13.400'
  start: '35:11.400'
  text: will it die out or will it not?
- end: '35:16.400'
  start: '35:13.400'
  text: And if there's even one critical ingredient missing,
- end: '35:18.400'
  start: '35:16.400'
  text: then it still doesn't count.
- end: '35:20.400'
  start: '35:18.400'
  text: It's like, you know, if you're on a long sea voyage
- end: '35:22.400'
  start: '35:20.400'
  text: and you've got everything except vitamin C,
- end: '35:25.400'
  start: '35:22.400'
  text: and it's only a matter of time, you know, you're going to die.
- end: '35:30.400'
  start: '35:25.400'
  text: So we're going to get a Mars city to the point where it's self-sustaining.
- end: '35:33.400'
  start: '35:30.400'
  text: I'm not sure this will really happen in my lifetime,
- end: '35:36.400'
  start: '35:33.400'
  text: but I hope to see it at least have a lot of momentum.
- end: '35:39.400'
  start: '35:36.400'
  text: And then you could say, okay, what is the minimum tonnage
- end: '35:44.400'
  start: '35:39.400'
  text: necessary to have a self-sustaining city?
- end: '35:46.400'
  start: '35:44.400'
  text: And there's a lot of uncertainty about this.
- end: '35:51.400'
  start: '35:46.400'
  text: You could say like, I don't know, it's probably at least a million tons
- end: '35:54.400'
  start: '35:51.400'
  text: because you have to set up a lot of infrastructure on Mars.
- end: '35:59.400'
  start: '35:54.400'
  text: Like I said, you can't be missing anything that,
- end: '36:01.400'
  start: '35:59.400'
  text: in order to be self-sustaining, you can't be missing.
- end: '36:04.400'
  start: '36:01.400'
  text: Like you need, you know, a semi-conductor fabs,
- end: '36:09.400'
  start: '36:04.400'
  text: you need iron ore refineries, like you need lots of things, you know.
- end: '36:13.400'
  start: '36:09.400'
  text: So, and Mars is not super-hospitable.
- end: '36:15.400'
  start: '36:13.400'
  text: It's the least inhospitable planet,
- end: '36:17.400'
  start: '36:15.400'
  text: but it's definitely a fixer-offer of a planet.
- end: '36:19.400'
  start: '36:17.400'
  text: Outside of Earth.
- end: '36:20.400'
  start: '36:19.400'
  text: Yes.
- end: '36:21.400'
  start: '36:20.400'
  text: Earth is pretty good.
- end: '36:22.400'
  start: '36:21.400'
  text: Earth is like easy.
- end: '36:25.400'
  start: '36:22.400'
  text: And also, we should clarify in the solar system.
- end: '36:26.400'
  start: '36:25.400'
  text: Yes, in the solar system.
- end: '36:29.400'
  start: '36:26.400'
  text: There might be nice, like, vacation spots.
- end: '36:32.400'
  start: '36:29.400'
  text: There might be some great planets out there, but it's hopeless.
- end: '36:33.400'
  start: '36:32.400'
  text: Too hard to get there?
- end: '36:37.400'
  start: '36:33.400'
  text: Yeah, way, way, way, way too hard, to say the least.
- end: '36:38.400'
  start: '36:37.400'
  text: Let me push back on that.
- end: '36:41.400'
  start: '36:38.400'
  text: Not really a pushback, but a quick curveball of a question.
- end: '36:44.400'
  start: '36:41.400'
  text: So, you did mention physics as the first starting point.
- end: '36:50.400'
  start: '36:44.400'
  text: So, general relativity allows for warm holes.
- end: '36:52.400'
  start: '36:50.400'
  text: They technically can exist.
- end: '36:58.400'
  start: '36:52.400'
  text: Do you think those can ever be leveraged by humus to travel fast in the speed
    of light?
- end: '37:05.400'
  start: '36:59.400'
  text: Well, the one whole thing is debatable.
- end: '37:11.400'
  start: '37:05.400'
  text: We currently do not know of any means of going faster than the speed of light.
- end: '37:21.400'
  start: '37:11.400'
  text: There is, like, there are some ideas about having space.
- end: '37:29.400'
  start: '37:21.400'
  text: Like, so, you can only move at the speed of light through space, but if you
    can make
- end: '37:36.400'
  start: '37:29.400'
  text: space itself move, that's what we're warming space.
- end: '37:39.400'
  start: '37:36.400'
  text: Space is capable of moving faster than the speed of light.
- end: '37:40.400'
  start: '37:39.400'
  text: Right.
- end: '37:45.400'
  start: '37:40.400'
  text: Like, the universe, in the Big Bang, the universe expanded much more than
    the speed of light
- end: '37:48.400'
  start: '37:45.400'
  text: by a lot.
- end: '38:01.400'
  start: '37:48.400'
  text: So, but the, if this is possible, the amount of energy required to walk space
    is so gigantic,
- end: '38:03.400'
  start: '38:01.400'
  text: it boggles the mind.
- end: '38:07.400'
  start: '38:03.400'
  text: So, all the work you've done with propulsion, how much innovation is possible
    with rocket
- end: '38:08.400'
  start: '38:07.400'
  text: propulsion?
- end: '38:14.400'
  start: '38:08.400'
  text: Is this, I mean, you've seen it all, and you're constantly innovating in every
    aspect.
- end: '38:15.400'
  start: '38:14.400'
  text: How much is possible?
- end: '38:17.400'
  start: '38:15.400'
  text: Like, how much can you get 10x somehow?
- end: '38:21.400'
  start: '38:17.400'
  text: Is there something in there in physics that you can get significant improvement
    in terms
- end: '38:24.400'
  start: '38:21.400'
  text: of efficiency of engines and all those kinds of things?
- end: '38:31.400'
  start: '38:24.400'
  text: Well, as I was saying, like, really, the Holy Grail is a fully and rapidly
    reusable orbital
- end: '38:32.400'
  start: '38:31.400'
  text: system.
- end: '38:43.800'
  start: '38:32.400'
  text: So, right now, the Falcon 9 is the only reusable rocket out there, but the
    booster comes back
- end: '38:47.800'
  start: '38:43.800'
  text: and lands, and you've seen the videos, and we get the nose cone fairing back,
    but we
- end: '38:50.800'
  start: '38:47.800'
  text: do not get the upper stage back.
- end: '38:57.680'
  start: '38:50.800'
  text: So, that means that we have a minimum cost of building an upper stage.
- end: '39:01.400'
  start: '38:57.680'
  text: You can think of like a two-stage rocket of sort of like two airplanes, like
    a big airplane
- end: '39:06.000'
  start: '39:01.400'
  text: and a small airplane, and we get big airplane back, but not the small airplane.
- end: '39:11.200'
  start: '39:06.000'
  text: And so, it still costs a lot, you know, so that upper stage is, you know,
    at least $10
- end: '39:19.000'
  start: '39:11.200'
  text: million, and then the degree of the booster is not as rapidly and completely
    reusable
- end: '39:25.120'
  start: '39:19.000'
  text: as we'd like in order of the fairings, so, you know, our kind of minimum marginal
    cost
- end: '39:33.480'
  start: '39:25.120'
  text: not counting overhead for per flight is on the order of $15 to $20 million,
    maybe.
- end: '39:40.680'
  start: '39:33.480'
  text: So, that's extremely good for, it's by far better than any rocket ever in
    history.
- end: '39:51.160'
  start: '39:41.600'
  text: But with full and rapid reusability, we can reduce the cost per ton to orbit
    by a factor
- end: '39:53.160'
  start: '39:51.160'
  text: of 100.
- end: '40:00.280'
  start: '39:53.160'
  text: But just think of it like, imagine if you had an aircraft or something or
    a car, and
- end: '40:06.880'
  start: '40:00.280'
  text: if you had to buy in your car every time you went for a drive, it would be
    very expensive,
- end: '40:13.720'
  start: '40:06.880'
  text: very silly, frankly, but you, in fact, you just refuel the car or recharge
    the car, and
- end: '40:20.480'
  start: '40:13.720'
  text: that makes your trip, like, I don't know, a thousand times cheaper.
- end: '40:23.920'
  start: '40:20.480'
  text: So, it's the same for rockets.
- end: '40:28.920'
  start: '40:23.920'
  text: If you, it's very difficult to make this complex machine that can go to orbit.
- end: '40:34.160'
  start: '40:28.920'
  text: And so, if you cannot reuse it and have to throw even any significant part
    of it away,
- end: '40:36.800'
  start: '40:34.160'
  text: that massively increases the cost.
- end: '40:44.560'
  start: '40:36.800'
  text: So, you know, Starship in theory could do a cost per launch of like a million,
    maybe
- end: '40:53.680'
  start: '40:44.560'
  text: $2 million or something like that, and put over 100 tons in orbit, which is
    crazy.
- end: '40:54.680'
  start: '40:53.680'
  text: Yeah.
- end: '40:55.680'
  start: '40:54.680'
  text: So.
- end: '40:56.680'
  start: '40:55.680'
  text: That's incredible.
- end: '41:00.720'
  start: '40:56.680'
  text: So, you're saying like it's by far the biggest bang for the buck is to make
    it fully reusable
- end: '41:05.320'
  start: '41:00.720'
  text: versus like some kind of brilliant breakthrough in theoretical physics?
- end: '41:06.320'
  start: '41:05.320'
  text: Yeah.
- end: '41:10.400'
  start: '41:06.360'
  text: There's no, there's no brilliant breakthrough, no, it just, you've got to
    make the rock
- end: '41:11.400'
  start: '41:10.400'
  text: reusable.
- end: '41:13.400'
  start: '41:11.400'
  text: This is an extremely difficult ensuring problem.
- end: '41:14.400'
  start: '41:13.400'
  text: Got it.
- end: '41:18.160'
  start: '41:14.400'
  text: But no new physics is required.
- end: '41:19.480'
  start: '41:18.160'
  text: Just brilliant engineering.
- end: '41:22.320'
  start: '41:19.480'
  text: Let me ask a slightly philosophical, fun question.
- end: '41:23.320'
  start: '41:22.320'
  text: Gotta ask.
- end: '41:27.400'
  start: '41:23.320'
  text: I know you're focused on getting to Mars, but once we're there on Mars, what
    do you, what
- end: '41:34.120'
  start: '41:27.400'
  text: form of government, economic system, political system, do you think would
    work best for an
- end: '41:36.720'
  start: '41:34.120'
  text: early civilization of humans?
- end: '41:43.480'
  start: '41:36.720'
  text: Is, I mean, the interesting reason to talk about this stuff, it also helps
    people dream
- end: '41:44.480'
  start: '41:43.480'
  text: about the future.
- end: '41:49.280'
  start: '41:44.480'
  text: I know you're really focused about the short term engineering dream, but it's
    like, I don't
- end: '41:53.400'
  start: '41:49.280'
  text: know, there's something about imagining an actual civilization on Mars that
    gives people,
- end: '41:55.240'
  start: '41:53.400'
  text: it really gives people hope.
- end: '41:59.800'
  start: '41:55.240'
  text: Well, it would be a new frontier and an opportunity to rethink the whole nature
    of government.
- end: '42:02.840'
  start: '41:59.800'
  text: Just as was done in the creation of the United States.
- end: '42:16.600'
  start: '42:02.840'
  text: So I mean, I would suggest having direct democracy, like people vote directly
    on things as opposed
- end: '42:18.600'
  start: '42:16.600'
  text: to representative democracy.
- end: '42:27.760'
  start: '42:18.600'
  text: So representative democracy, I think is too subject to a special interest
    and a coercion
- end: '42:31.440'
  start: '42:27.760'
  text: of the politicians and that kind of thing.
- end: '42:39.560'
  start: '42:31.440'
  text: So I'd recommend that there's just direct democracy.
- end: '42:43.640'
  start: '42:39.560'
  text: People vote on laws, the population votes on laws themselves, and then the
    laws must
- end: '42:46.200'
  start: '42:43.640'
  text: be short enough that people can understand them.
- end: '42:47.200'
  start: '42:46.200'
  text: Yeah.
- end: '42:51.560'
  start: '42:47.200'
  text: And then like keeping a well-informed populace, like really being transparent
    about all the
- end: '42:53.360'
  start: '42:51.560'
  text: information about what they're voting for.
- end: '42:54.960'
  start: '42:53.360'
  text: Yeah, absolute transparency.
- end: '42:55.960'
  start: '42:54.960'
  text: Yeah.
- end: '42:58.960'
  start: '42:55.960'
  text: And not make it as annoying as those cookies, we have to accept the cookies.
- end: '42:59.960'
  start: '42:58.960'
  text: Accept cookies.
- end: '43:05.520'
  start: '42:59.960'
  text: There's always like a slight amount of trepidation when you click accept cookies.
- end: '43:09.600'
  start: '43:05.520'
  text: Like I feel as though there's like perhaps like a very tiny chance that it'll
    open a
- end: '43:11.880'
  start: '43:09.600'
  text: portal to hell or something like that.
- end: '43:14.440'
  start: '43:11.880'
  text: That's exactly how I feel.
- end: '43:16.720'
  start: '43:14.440'
  text: Why do they want you to accept it?
- end: '43:19.320'
  start: '43:16.720'
  text: What do they want with this cookie?
- end: '43:22.440'
  start: '43:19.320'
  text: Somebody got upset with accepting cookies or something somewhere.
- end: '43:23.440'
  start: '43:22.440'
  text: Who cares?
- end: '43:26.640'
  start: '43:23.440'
  text: It's so annoying to keep accepting all these cookies.
- end: '43:29.240'
  start: '43:26.640'
  text: To me, it's just a great experience.
- end: '43:30.760'
  start: '43:29.680'
  text: Yes, you can have my damn cookie.
- end: '43:31.760'
  start: '43:30.760'
  text: I don't care.
- end: '43:32.760'
  start: '43:31.760'
  text: Whatever.
- end: '43:33.880'
  start: '43:32.760'
  text: He heard it from me on first.
- end: '43:36.000'
  start: '43:33.880'
  text: He accepts all of your damn cookies.
- end: '43:37.000'
  start: '43:36.000'
  text: Yeah.
- end: '43:39.000'
  start: '43:37.000'
  text: It's not asking me.
- end: '43:41.000'
  start: '43:39.000'
  text: It's annoying.
- end: '43:42.000'
  start: '43:41.000'
  text: Yeah.
- end: '43:49.960'
  start: '43:42.000'
  text: It's one example of implementation of a good idea done really horribly.
- end: '43:50.960'
  start: '43:49.960'
  text: Yeah.
- end: '43:55.720'
  start: '43:50.960'
  text: It's somebody who has some good intentions of like privacy or whatever, but
    now everyone's
- end: '43:59.480'
  start: '43:55.760'
  text: just has to accept cookies and it's not, you know, you have billions of people
    who have
- end: '44:00.800'
  start: '43:59.480'
  text: to keep clicking except cookie.
- end: '44:01.800'
  start: '44:00.800'
  text: It's super annoying.
- end: '44:04.120'
  start: '44:01.800'
  text: Then we just accept the damn cookie.
- end: '44:05.120'
  start: '44:04.120'
  text: It's fine.
- end: '44:10.440'
  start: '44:05.120'
  text: There is like, I think a fundamental problem that we're, because we've not
    really had a
- end: '44:15.560'
  start: '44:10.440'
  text: major like a world war or something like that in a while, and obviously we
    would like to
- end: '44:22.840'
  start: '44:15.560'
  text: not have world wars, there's not been a cleansing function for rules and regulations.
- end: '44:29.040'
  start: '44:22.840'
  text: So wars did have, you know, some sort of lining in that there would be a reset
    on rules and
- end: '44:31.200'
  start: '44:29.040'
  text: regulations after a war.
- end: '44:35.800'
  start: '44:31.200'
  text: So world wars one and two, there were huge resets on rules and regulations.
- end: '44:41.280'
  start: '44:35.800'
  text: Now as if the society does not have a war and there's no cleansing function
    or garbage
- end: '44:44.560'
  start: '44:41.280'
  text: collection for rules and regulations, then rules and regulations will accumulate
    every
- end: '44:46.560'
  start: '44:44.560'
  text: year because they're immortal.
- end: '44:50.440'
  start: '44:46.560'
  text: There's no actual humans die, but the laws don't.
- end: '44:54.640'
  start: '44:50.440'
  text: So we need a garbage collection function for rules and regulations.
- end: '44:59.360'
  start: '44:54.640'
  text: They should not just be immortal because some of the rules and regulations
    that are put
- end: '45:04.040'
  start: '44:59.360'
  text: in place will be counterproductive, done with good intentions, but counterproductive,
    sometimes
- end: '45:05.720'
  start: '45:04.040'
  text: not done with good intentions.
- end: '45:12.560'
  start: '45:05.720'
  text: So if rules and regulations just accumulate every year and you get more and
    more of them,
- end: '45:14.920'
  start: '45:12.560'
  text: then eventually you won't be able to do anything.
- end: '45:19.760'
  start: '45:14.920'
  text: You're just like Gulliver with, you know, tied down by thousands of little
    strings.
- end: '45:29.240'
  start: '45:19.760'
  text: And we see that in, you know, U.S. and like basically all economies that have
    been around
- end: '45:36.640'
  start: '45:29.240'
  text: for a while and regulators and legislators create new rules and regulations
    every year,
- end: '45:38.800'
  start: '45:36.640'
  text: but they don't put effort into removing them.
- end: '45:42.800'
  start: '45:38.800'
  text: And I think that's very important that we put effort into removing rules and
    regulations.
- end: '45:47.440'
  start: '45:42.800'
  text: But it gets tough because you get special interests that then are dependent
    on like
- end: '45:54.560'
  start: '45:47.440'
  text: they have a vested interest in that whatever rule and regulation and that
    they fight to
- end: '45:55.960'
  start: '45:54.560'
  text: not get it removed.
- end: '45:56.960'
  start: '45:55.960'
  text: Yeah.
- end: '46:04.320'
  start: '45:56.960'
  text: So I mean, I guess the problem with the Constitution is it's kind of like
    C versus Java because
- end: '46:06.680'
  start: '46:04.320'
  text: it doesn't have any garbage collection built in.
- end: '46:11.000'
  start: '46:06.680'
  text: I think there should be, when you first said the metaphor of garbage collection,
    I love
- end: '46:12.000'
  start: '46:11.000'
  text: that.
- end: '46:13.000'
  start: '46:12.000'
  text: Yeah, it's from a coding standpoint.
- end: '46:14.000'
  start: '46:13.000'
  text: From a coding standpoint.
- end: '46:15.000'
  start: '46:14.000'
  text: Yeah.
- end: '46:16.040'
  start: '46:15.040'
  text: Interesting.
- end: '46:20.600'
  start: '46:16.040'
  text: It's the laws themselves kind of had a built in thing where they kind of die
    after a while
- end: '46:23.360'
  start: '46:20.600'
  text: unless somebody explicitly publicly defends them.
- end: '46:24.360'
  start: '46:23.360'
  text: Yeah.
- end: '46:28.160'
  start: '46:24.360'
  text: So that's sort of, it's not like somebody has to kill them, they kind of die
    themselves.
- end: '46:29.160'
  start: '46:28.160'
  text: They disappear.
- end: '46:30.160'
  start: '46:29.160'
  text: Yeah.
- end: '46:37.800'
  start: '46:30.160'
  text: Not to defend Java or anything, but you know, C++, you know, you could also
    have a great
- end: '46:40.040'
  start: '46:37.800'
  text: garbage collection in Python and so on.
- end: '46:41.040'
  start: '46:40.040'
  text: Yeah.
- end: '46:49.720'
  start: '46:42.040'
  text: Something needs to happen or just the civilization's arteries just harden
    over time and you can
- end: '46:54.960'
  start: '46:49.720'
  text: just get less and less done because there's just a rule against everything.
- end: '47:00.320'
  start: '46:54.960'
  text: So I think like, I don't know, for Mars or whatever I say, I would say for
    Earth as well,
- end: '47:05.400'
  start: '47:00.320'
  text: like I think there should be an active process for removing rules and regulations
    and questioning
- end: '47:07.320'
  start: '47:05.400'
  text: their existence.
- end: '47:12.360'
  start: '47:08.320'
  text: Like, if we've got a function for creating rules and regulations, because
    rules and regulations
- end: '47:19.000'
  start: '47:12.360'
  text: can also think of as like, they're like software or lines of code for operating
    civilization.
- end: '47:20.080'
  start: '47:19.000'
  text: That's rules and regulations.
- end: '47:25.000'
  start: '47:20.080'
  text: So it's not like we shouldn't have rules and regulations, but you have code
    accumulation,
- end: '47:27.560'
  start: '47:25.000'
  text: but no code removal.
- end: '47:33.800'
  start: '47:27.560'
  text: And so it just gets to become basically archaic bloatware after a while.
- end: '47:38.040'
  start: '47:33.800'
  text: And it's just, it makes it hard for things to progress.
- end: '47:44.000'
  start: '47:38.040'
  text: So I don't know, maybe Mars, you'd have like, you know, any given law must
    have a sunset,
- end: '47:52.760'
  start: '47:44.000'
  text: you know, and require active voting to keep, to keep it up there, you know,
    and I should
- end: '47:58.880'
  start: '47:52.760'
  text: also say like, and these are just, I don't know, recommendations or thoughts
    and ultimately
- end: '48:06.280'
  start: '47:58.880'
  text: we'll be up to the people on Mars to decide, but I think it should be easier
    to remove
- end: '48:10.840'
  start: '48:06.280'
  text: a law than to add one because of the, just to overcome the inertia of laws.
- end: '48:18.800'
  start: '48:10.840'
  text: So maybe it's like, for argument's sake, you need like say 60% vote to have
    a law take
- end: '48:23.520'
  start: '48:18.800'
  text: effect, but only a 40% vote to remove it.
- end: '48:28.800'
  start: '48:23.520'
  text: So let me be the guy, you posted a meme on Twitter recently where there's
    like a row
- end: '48:34.880'
  start: '48:28.800'
  text: of urinals and a guy just walks all the way across and he tells you about
    crypto.
- end: '48:38.360'
  start: '48:34.880'
  text: I mean, that's how to be so many times.
- end: '48:44.320'
  start: '48:38.360'
  text: I think maybe even literally, do you think, technologically speaking, there's
    any room
- end: '48:49.440'
  start: '48:44.320'
  text: for ideas of smart contracts or so on, because you mentioned laws.
- end: '48:54.800'
  start: '48:49.440'
  text: That's an interesting use of things like smart contracts to implement the
    laws by which
- end: '49:02.960'
  start: '48:54.800'
  text: governments function, like something built on Ethereum or maybe a dog coin
    that enables
- end: '49:04.760'
  start: '49:02.960'
  text: smart contracts somehow.
- end: '49:12.800'
  start: '49:04.760'
  text: I don't quite understand this whole smart contract thing, you know, I mean,
    I'm too
- end: '49:14.960'
  start: '49:12.800'
  text: down to understand smart contracts.
- end: '49:17.840'
  start: '49:14.960'
  text: That's a good line.
- end: '49:22.400'
  start: '49:17.840'
  text: I mean, my general approach to any kind of like deal or whatever is just make
    sure there's
- end: '49:23.920'
  start: '49:22.400'
  text: clarity of understanding.
- end: '49:26.520'
  start: '49:23.920'
  text: That's the most important thing.
- end: '49:31.600'
  start: '49:26.520'
  text: And just keep any kind of deal very, very short and simple, plain language.
- end: '49:38.920'
  start: '49:31.600'
  text: And just make sure everyone understands, this is the deal, is it clear?
- end: '49:42.720'
  start: '49:38.920'
  text: And what are the consequences if various things don't happen?
- end: '49:50.880'
  start: '49:43.160'
  text: Usually deals are business deals or whatever are way too long and complex
    and overly lawyered
- end: '49:52.840'
  start: '49:50.880'
  text: and pointlessly.
- end: '49:59.600'
  start: '49:52.840'
  text: You mentioned that Doge is the people's coin and you said that you were literally
    going
- end: '50:07.880'
  start: '49:59.600'
  text: SpaceX may consider literally putting a Doge coin on the moon.
- end: '50:12.000'
  start: '50:07.880'
  text: Is this something you're still considering, Mars perhaps?
- end: '50:16.800'
  start: '50:12.000'
  text: Do you think there's some chance we've talked about political systems on Mars
    that Doge
- end: '50:22.720'
  start: '50:16.800'
  text: coin is the official currency of Mars that's happening in the future?
- end: '50:29.000'
  start: '50:22.720'
  text: Well, I think Mars itself will need to have a different currency because you
    can't synchronize
- end: '50:32.760'
  start: '50:29.000'
  text: due to speed of light or not easily.
- end: '50:35.480'
  start: '50:32.760'
  text: So it must be completely standalone from Earth?
- end: '50:43.520'
  start: '50:36.440'
  text: Well, yeah, because Mars, at closest approach, it's four light minutes away
    roughly and then
- end: '50:50.200'
  start: '50:43.520'
  text: at furthest approach, it's roughly 20 light minutes away, maybe a little more.
- end: '50:55.160'
  start: '50:50.200'
  text: So you can't really have something synchronizing if you've got a 20 minutes
    speed of light
- end: '51:01.280'
  start: '50:55.160'
  text: issue, if it's got a one minute blockchain, it's not going to synchronize
    probably.
- end: '51:06.240'
  start: '51:01.280'
  text: So Mars, I don't know if Mars will have a cryptocurrency as a thing, but probably
    seems
- end: '51:12.440'
  start: '51:06.240'
  text: likely, but it would be some kind of localized thing on Mars.
- end: '51:14.440'
  start: '51:12.440'
  text: And you let the people decide?
- end: '51:18.040'
  start: '51:14.440'
  text: Yeah, absolutely.
- end: '51:21.160'
  start: '51:18.040'
  text: The future of Mars should be up to the Martians.
- end: '51:34.040'
  start: '51:21.160'
  text: So I think the cryptocurrency thing is an interesting approach to reducing
    the error
- end: '51:41.400'
  start: '51:34.040'
  text: in the database that is called money.
- end: '51:46.080'
  start: '51:41.400'
  text: I think I have a pretty deep understanding of what money actually is on a
    practical day-to-day
- end: '51:50.480'
  start: '51:46.080'
  text: basis because of PayPal.
- end: '51:55.440'
  start: '51:50.480'
  text: We really got in deep there.
- end: '52:03.320'
  start: '51:55.440'
  text: And right now, the money system, actually for practical purposes, is really
    a bunch of heterogeneous
- end: '52:07.600'
  start: '52:03.320'
  text: mainframes running old cobalt.
- end: '52:08.600'
  start: '52:07.600'
  text: Okay, you mean literally?
- end: '52:09.600'
  start: '52:08.600'
  text: Literally.
- end: '52:10.880'
  start: '52:09.600'
  text: That is literally what's happening.
- end: '52:12.880'
  start: '52:10.880'
  text: In batch mode.
- end: '52:13.880'
  start: '52:12.880'
  text: Okay.
- end: '52:14.880'
  start: '52:13.880'
  text: In batch mode.
- end: '52:18.840'
  start: '52:15.080'
  text: Pretty the poor bastards who have to maintain that code.
- end: '52:22.360'
  start: '52:18.840'
  text: Okay, that's a pain.
- end: '52:23.960'
  start: '52:22.360'
  text: Not even Fortran, it's cobalt.
- end: '52:24.960'
  start: '52:23.960'
  text: Yep.
- end: '52:26.200'
  start: '52:24.960'
  text: It's cobalt.
- end: '52:33.280'
  start: '52:26.200'
  text: And the banks are still buying mainframes in 2021 and running ancient cobalt
    code.
- end: '52:39.200'
  start: '52:33.280'
  text: And the Federal Reserve is probably even older than what the banks have, and
    they have
- end: '52:42.040'
  start: '52:39.200'
  text: an old cobalt mainframe.
- end: '52:49.960'
  start: '52:42.040'
  text: And so the government effectively has editing privileges on the money database.
- end: '52:56.600'
  start: '52:49.960'
  text: And they use those editing privileges to make more money whenever they want.
- end: '53:00.120'
  start: '52:56.600'
  text: And this increases the error in the database that is money.
- end: '53:05.640'
  start: '53:00.120'
  text: So I think money should really be viewed through the lens of information theory.
- end: '53:09.360'
  start: '53:05.640'
  text: And so it's kind of like an internet connection.
- end: '53:13.760'
  start: '53:09.360'
  text: Like what's the bandwidth, you know, total bit rate?
- end: '53:21.120'
  start: '53:13.760'
  text: What is the latency, jitter, packet drop, you know, errors in network communication?
- end: '53:25.440'
  start: '53:21.120'
  text: Just think of money like that, basically.
- end: '53:27.880'
  start: '53:25.440'
  text: I think that's probably why I really think of it.
- end: '53:34.400'
  start: '53:27.880'
  text: And then say what system, from an information theory standpoint, allows an
    economy to function
- end: '53:48.760'
  start: '53:34.400'
  text: the best and, you know, crypto is an attempt to reduce the error in money
    that is contributed
- end: '53:59.000'
  start: '53:48.760'
  text: by governments diluting the money supply as basically a pernicious form of
    taxation.
- end: '54:07.000'
  start: '53:59.000'
  text: So both policy in terms of with inflation and actual technological cobalt,
    like cryptocurrency
- end: '54:11.440'
  start: '54:07.000'
  text: takes us into the 21st century in terms of the actual systems that allow you
    to do the
- end: '54:14.320'
  start: '54:11.440'
  text: transaction to store wealth, all those kinds of things.
- end: '54:18.760'
  start: '54:14.320'
  text: Like I said, just think of money as information.
- end: '54:24.160'
  start: '54:18.760'
  text: People often will think of money as having power in and of itself.
- end: '54:25.160'
  start: '54:24.160'
  text: It does not.
- end: '54:31.560'
  start: '54:25.160'
  text: Money is information and it does not have power in and of itself.
- end: '54:37.640'
  start: '54:31.560'
  text: Like applying the physics tools of thinking about things in the limit is helpful.
- end: '54:47.840'
  start: '54:37.640'
  text: If you are stranded on a tropical island and you have a trillion dollars,
    it's useless
- end: '54:50.720'
  start: '54:47.840'
  text: because there's no resource allocation.
- end: '54:54.000'
  start: '54:50.720'
  text: Money is a database for resource allocation, but there's no resource to allocate
    except
- end: '55:01.080'
  start: '54:54.000'
  text: yourself, so money is useless.
- end: '55:09.960'
  start: '55:01.080'
  text: If you're stranded on a desert island with no food, all the Bitcoin in the
    world will
- end: '55:16.160'
  start: '55:09.960'
  text: not stop you from starving.
- end: '55:26.360'
  start: '55:16.160'
  text: So just think of money as a database for resource allocation across time and
    space.
- end: '55:37.640'
  start: '55:26.360'
  text: And then what system, in what form should that database or data system, what
    would be
- end: '55:40.320'
  start: '55:37.640'
  text: most effective?
- end: '55:47.640'
  start: '55:40.320'
  text: There is a fundamental issue with, say, Bitcoin in its current form in that
    the transaction
- end: '55:58.600'
  start: '55:47.640'
  text: volume is very limited and the latency for a properly confirmed transaction
    is too long,
- end: '56:00.280'
  start: '55:58.600'
  text: much longer than you'd like.
- end: '56:09.280'
  start: '56:00.280'
  text: So it's actually not great from a transaction volume standpoint or a latency
    standpoint.
- end: '56:19.240'
  start: '56:10.280'
  text: Perhaps useful to solve an aspect of the money database problem, which is
    the store
- end: '56:29.480'
  start: '56:19.240'
  text: of wealth or an accounting of relative obligations, I suppose, but it is not
    useful as a currency,
- end: '56:30.880'
  start: '56:29.480'
  text: as a day-to-day currency.
- end: '56:35.760'
  start: '56:30.880'
  text: The people have proposed different technological solutions, lightning network
    and the layer
- end: '56:39.000'
  start: '56:35.760'
  text: of two technologies on top of that.
- end: '56:42.960'
  start: '56:39.000'
  text: It seems to be all kind of a trade-off, but the point is it's kind of brilliant
    to say
- end: '56:47.080'
  start: '56:42.960'
  text: that just think about information, think about what kind of database, what
    kind of infrastructure
- end: '56:49.080'
  start: '56:47.080'
  text: enables the exchange of information.
- end: '56:56.040'
  start: '56:49.080'
  text: Like you're operating an economy and you need to have some thing that allows
    for the
- end: '57:01.440'
  start: '56:56.040'
  text: efficient to have efficient value ratios between products and services.
- end: '57:05.920'
  start: '57:01.440'
  text: So you've got this massive number of products and services and you need to,
    you can't just
- end: '57:09.760'
  start: '57:05.920'
  text: barter, just like that would be extremely unwieldy.
- end: '57:21.120'
  start: '57:09.760'
  text: So you need something that gives you a ratio of exchange between goods and
    services and
- end: '57:28.160'
  start: '57:21.120'
  text: then something that allows you to shift obligations across time, like debt
    and equity, shift obligations
- end: '57:29.160'
  start: '57:28.160'
  text: across time.
- end: '57:31.280'
  start: '57:29.200'
  text: Then what does the best job of that?
- end: '57:38.360'
  start: '57:33.280'
  text: Part of the reason why I think there's some merits to Dogecoin, even though
    it was obviously
- end: '57:47.520'
  start: '57:38.360'
  text: created as a joke, is that it actually does have a much higher transaction
    volume capability
- end: '57:55.880'
  start: '57:47.520'
  text: than Bitcoin and the costs of doing a transaction, the Dogecoin fee is very
    low.
- end: '57:59.920'
  start: '57:56.000'
  text: Like right now, if you want to do a Bitcoin transaction, the price of doing
    that transaction
- end: '58:00.440'
  start: '57:59.920'
  text: is very high.
- end: '58:06.720'
  start: '58:00.440'
  text: So you could not use it effectively for most things and nor could it even
    scale to a high volume.
- end: '58:18.320'
  start: '58:11.840'
  text: And when Bitcoin started, I guess around 2008 or something like that, the
    internet
- end: '58:20.760'
  start: '58:18.320'
  text: connections were much worse than they are today.
- end: '58:26.880'
  start: '58:20.840'
  text: Like order of magnitude, I mean, there's the way way worse in 2008.
- end: '58:36.840'
  start: '58:26.880'
  text: So like having a small block size or whatever is and a long synchronization
    time is made
- end: '58:45.200'
  start: '58:36.840'
  text: sense in 2008, but to 2021 or fast forward 10 years, it's like comically low.
- end: '58:56.920'
  start: '58:46.040'
  text: So and I think there's some value to having a linear increase in the amount
    of currency
- end: '59:06.320'
  start: '58:56.920'
  text: that is generated because some amount of the currency, if a currency is too
    deflationary
- end: '59:13.600'
  start: '59:06.320'
  text: or should say if a currency is expected to increase in value over time, there's
    reluctance
- end: '59:18.800'
  start: '59:13.640'
  text: to spend it because you're like, oh, if I I'll just hold it and not spend
    it because
- end: '59:20.560'
  start: '59:18.800'
  text: it's scarcity is increasing with time.
- end: '59:23.360'
  start: '59:20.560'
  text: So if I spend it now, then I will regret spending it.
- end: '59:25.880'
  start: '59:23.360'
  text: So we'll just, you know, total it.
- end: '59:32.320'
  start: '59:27.880'
  text: But if there's some dilution of the currency occurring over time, that's that's
    more of
- end: '59:33.880'
  start: '59:32.320'
  text: an incentive to use it as a currency.
- end: '59:46.240'
  start: '59:34.160'
  text: So those coins somewhat randomly has a just a fixed number of sort of coins
    or hash strings
- end: '59:49.480'
  start: '59:46.280'
  text: that are generated every year.
- end: '59:52.720'
  start: '59:49.520'
  text: So there's some inflation, but it's not a percentage base.
- end: '59:55.640'
  start: '59:52.720'
  text: It's a fixed number.
- end: '59:59.840'
  start: '59:55.640'
  text: So the percentage of inflation will necessarily decline over time.
- end: '01:00:07.960'
  start: '01:00:00.840'
  text: So it just I'm not saying that it's like the ideal system for a currency,
    but I think
- end: '01:00:14.240'
  start: '01:00:07.960'
  text: it actually is just fundamentally better than anything else I've seen, just
    by accident.
- end: '01:00:23.800'
  start: '01:00:15.760'
  text: So like I said, around 2008, so you're not, you know, some people suggested
    you might be
- end: '01:00:28.040'
  start: '01:00:23.800'
  text: said to Oshinakamoto, you've previously said you're not, you're not for sure.
- end: '01:00:30.040'
  start: '01:00:28.760'
  text: Would you tell us if you were?
- end: '01:00:30.440'
  start: '01:00:30.080'
  text: Yes.
- end: '01:00:30.920'
  start: '01:00:30.560'
  text: Okay.
- end: '01:00:37.080'
  start: '01:00:33.400'
  text: Do you think it's a feature or bug that he's anonymous or she or they?
- end: '01:00:43.360'
  start: '01:00:38.960'
  text: It's an interesting kind of quirk of human history that there is a particular
    technology
- end: '01:00:49.760'
  start: '01:00:43.560'
  text: that is a completely anonymous inventor or creator.
- end: '01:01:11.760'
  start: '01:00:58.480'
  text: Well, I mean, you can you can look at the evolution of ideas before the launch
    of Bitcoin
- end: '01:01:19.320'
  start: '01:01:12.800'
  text: and see who wrote, you know, about those ideas.
- end: '01:01:26.080'
  start: '01:01:20.600'
  text: And then I like, I don't know, I don't know who created Bitcoin for practical
    purposes,
- end: '01:01:29.920'
  start: '01:01:26.080'
  text: but the evolution of ideas is pretty clear before that.
- end: '01:01:36.200'
  start: '01:01:29.920'
  text: And like it seems as though like Nick Szabo is probably more than anyone else
    responsible
- end: '01:01:37.520'
  start: '01:01:36.200'
  text: for the evolution of those ideas.
- end: '01:01:44.760'
  start: '01:01:38.000'
  text: So he claims not to be Nakamoto, but I'm not sure that's that's neither here
    nor there,
- end: '01:01:49.800'
  start: '01:01:45.320'
  text: but he seems to be the one more responsible for the ideas behind Bitcoin than
    anyone else.
- end: '01:01:55.800'
  start: '01:01:50.840'
  text: So it's not perhaps like singular figures aren't even as important as the
    figures
- end: '01:01:58.160'
  start: '01:01:55.800'
  text: involved in the evolution of ideas that led to a thing.
- end: '01:02:03.560'
  start: '01:01:58.160'
  text: So yeah, yeah, it's, you know, most perhaps it's sad to think about history,
- end: '01:02:06.480'
  start: '01:02:03.560'
  text: but maybe most names will be forgotten anyway.
- end: '01:02:07.800'
  start: '01:02:06.880'
  text: What is the name anyway?
- end: '01:02:10.520'
  start: '01:02:07.960'
  text: It's a name, a name attached to an idea.
- end: '01:02:13.200'
  start: '01:02:12.120'
  text: What does it even mean really?
- end: '01:02:17.000'
  start: '01:02:13.680'
  text: I think Shakespeare had a thing about roses and stuff, whatever he said.
- end: '01:02:18.200'
  start: '01:02:17.160'
  text: Rose by any other name.
- end: '01:02:19.320'
  start: '01:02:18.640'
  text: It smells sweet.
- end: '01:02:23.880'
  start: '01:02:22.360'
  text: I got to go on to quote Shakespeare.
- end: '01:02:26.160'
  start: '01:02:24.240'
  text: I feel, I feel like I accomplished something today.
- end: '01:02:28.320'
  start: '01:02:26.800'
  text: Shall I compare you to a summer's day?
- end: '01:02:31.680'
  start: '01:02:30.720'
  text: I'm going to clip that out.
- end: '01:02:35.000'
  start: '01:02:33.960'
  text: Not more temperate, not more fair.
- end: '01:02:39.640'
  start: '01:02:38.920'
  text: Autopilot.
- end: '01:02:41.400'
  start: '01:02:40.560'
  text: Tesla Autopilot.
- end: '01:02:49.680'
  start: '01:02:46.080'
  text: Tesla Autopilot has been through an incredible journey over the past six years,
- end: '01:02:54.960'
  start: '01:02:50.480'
  text: or perhaps even longer in the minds of, in your mind, in the minds of many
    involved.
- end: '01:03:00.080'
  start: '01:02:56.960'
  text: I think that's where we first like connected really was the autopilot stuff,
- end: '01:03:04.720'
  start: '01:03:00.360'
  text: autonomy and the whole journey was incredible to me to watch.
- end: '01:03:11.880'
  start: '01:03:05.160'
  text: I was, because I knew, well, part of it was I was at MIT and I knew the difficulty
- end: '01:03:15.720'
  start: '01:03:11.880'
  text: of computer vision and I knew the whole, I had a lot of colleagues and friends
- end: '01:03:17.960'
  start: '01:03:15.720'
  text: about the DARPA challenge and knew how difficult it is.
- end: '01:03:23.160'
  start: '01:03:18.400'
  text: And so there was a natural skepticism when I first drove a Tesla with the
    initial
- end: '01:03:26.360'
  start: '01:03:23.160'
  text: system based on mobile eye, I thought there's no way.
- end: '01:03:31.400'
  start: '01:03:27.360'
  text: So the first one I got in, I thought there's no way this car could maintain
- end: '01:03:35.680'
  start: '01:03:33.200'
  text: like staying in the lane and create a comfortable experience.
- end: '01:03:40.800'
  start: '01:03:35.880'
  text: So my intuition initially was that the lane keeping problem is way too difficult
    to
- end: '01:03:41.240'
  start: '01:03:40.800'
  text: solve.
- end: '01:03:42.360'
  start: '01:03:41.720'
  text: Oh, they're keeping.
- end: '01:03:43.440'
  start: '01:03:42.360'
  text: Yeah, that's relatively easy.
- end: '01:03:49.000'
  start: '01:03:43.880'
  text: Well, like, but not the, but solve in the way that we just, we talked about
- end: '01:03:54.360'
  start: '01:03:49.000'
  text: previous is prototype versus a thing that actually creates a pleasant experience
- end: '01:03:56.680'
  start: '01:03:54.360'
  text: over hundreds of thousands of miles of millions.
- end: '01:03:57.680'
  start: '01:03:57.280'
  text: Yeah.
- end: '01:04:01.680'
  start: '01:03:57.680'
  text: So we had to wrap a lot of code around the mobile eye thing.
- end: '01:04:03.480'
  start: '01:04:01.680'
  text: It doesn't just work by itself.
- end: '01:04:07.560'
  start: '01:04:04.320'
  text: I mean, there's part, that's part of the story of how you approach things.
- end: '01:04:09.320'
  start: '01:04:07.560'
  text: Sometimes you do things from scratch.
- end: '01:04:13.240'
  start: '01:04:09.600'
  text: Sometimes at first you kind of see what's out there and then you decide
- end: '01:04:13.960'
  start: '01:04:13.240'
  text: to do from scratch.
- end: '01:04:18.320'
  start: '01:04:14.320'
  text: That was one of the boldest decisions I've seen is both on the hardware and
    the
- end: '01:04:20.640'
  start: '01:04:18.320'
  text: software to decide to eventually go from scratch.
- end: '01:04:24.240'
  start: '01:04:20.960'
  text: I thought, again, I was skeptical of whether that's going to be able to work
- end: '01:04:26.280'
  start: '01:04:24.240'
  text: out because it's such a, such a difficult problem.
- end: '01:04:28.840'
  start: '01:04:26.840'
  text: And so it was an incredible journey.
- end: '01:04:33.160'
  start: '01:04:28.840'
  text: What I see now with everything, the hardware, the compute, the sensors,
- end: '01:04:39.040'
  start: '01:04:33.160'
  text: the things I maybe care and love about most is the, the stuff that Andre
- end: '01:04:43.080'
  start: '01:04:39.040'
  text: Carpathi is leading with the data set selection, the whole data engine process,
- end: '01:04:47.560'
  start: '01:04:43.080'
  text: the neural network architectures, the way that's in the real world, that
- end: '01:04:52.680'
  start: '01:04:47.560'
  text: network is tested, validated, all the different test sets, you know, versus
- end: '01:04:57.680'
  start: '01:04:52.680'
  text: the image net model of computer vision, like what's in academia is like real
- end: '01:04:59.560'
  start: '01:04:57.680'
  text: world artificial intelligence.
- end: '01:05:00.240'
  start: '01:04:59.840'
  text: So.
- end: '01:05:05.760'
  start: '01:05:00.760'
  text: Um, Andre is awesome and obviously plays an important role, but we have a
    lot
- end: '01:05:07.640'
  start: '01:05:05.760'
  text: of really talented people driving things.
- end: '01:05:12.560'
  start: '01:05:07.640'
  text: So, um, and Ashok is actually the head of autopilot engineering.
- end: '01:05:16.280'
  start: '01:05:12.720'
  text: Um, uh, uh, Andre is the director of AI.
- end: '01:05:16.920'
  start: '01:05:16.320'
  text: AI stuff.
- end: '01:05:17.320'
  start: '01:05:16.960'
  text: Yeah.
- end: '01:05:22.040'
  start: '01:05:17.640'
  text: So yeah, there's, I'm aware that there's an incredible team of just a lot
    going on.
- end: '01:05:22.160'
  start: '01:05:22.040'
  text: Yeah.
- end: '01:05:25.680'
  start: '01:05:22.160'
  text: Just, uh, you know, obviously people, people will give, will give me too much
- end: '01:05:27.240'
  start: '01:05:25.680'
  text: credit and they'll give Andre too much credit.
- end: '01:05:27.920'
  start: '01:05:27.520'
  text: So.
- end: '01:05:33.400'
  start: '01:05:28.640'
  text: And people should realize how much is going on under the, under the, so a
    lot of
- end: '01:05:39.960'
  start: '01:05:33.400'
  text: really talented people, um, the Tesla autopilot AI team is extremely talented.
- end: '01:05:42.280'
  start: '01:05:40.000'
  text: It's like some of the smartest people in the world.
- end: '01:05:44.680'
  start: '01:05:42.840'
  text: Um, so yeah, we're getting it done.
- end: '01:05:51.000'
  start: '01:05:45.000'
  text: What, what are some insights you've gained over those five, six years of autopilot
- end: '01:05:53.840'
  start: '01:05:51.280'
  text: about the problem of autonomous driving?
- end: '01:05:59.600'
  start: '01:05:54.240'
  text: So you leaped in having some sort of, uh, first principles, kinds of
- end: '01:06:05.400'
  start: '01:05:59.600'
  text: intuitions, but nobody knows how difficult the, the problem, like the problem.
- end: '01:06:08.680'
  start: '01:06:05.400'
  text: I thought the self-driving problem would be hard, but it was harder than I
    thought.
- end: '01:06:09.920'
  start: '01:06:08.960'
  text: It's not like I thought it'd be easy.
- end: '01:06:13.800'
  start: '01:06:09.920'
  text: I thought it'd be very hard, but it was actually way harder than, than even
    that.
- end: '01:06:18.560'
  start: '01:06:14.160'
  text: So, I mean, what it comes down to at the end of the day is to solve self-driving.
- end: '01:06:28.240'
  start: '01:06:19.160'
  text: Uh, you have to solve, uh, you basically need to recreate, um, what, what
    humans do
- end: '01:06:33.640'
  start: '01:06:28.240'
  text: to drive, which is humans drive with optical sensors, eyes, and biological
    neural nets.
- end: '01:06:38.960'
  start: '01:06:34.320'
  text: Um, and so in order to, that, that's how the entire road system is designed
    to work
- end: '01:06:45.960'
  start: '01:06:39.080'
  text: with, with, uh, basically passive optical and neural nets, um, biologically.
- end: '01:06:50.160'
  start: '01:06:46.040'
  text: Um, and now that we need to, so for actually for full self-driving to work,
    we
- end: '01:06:51.680'
  start: '01:06:50.160'
  text: have to recreate that in digital form.
- end: '01:07:00.760'
  start: '01:06:52.600'
  text: Um, so we have to, um, that, that means cameras with, uh, advanced, uh, neural
- end: '01:07:07.800'
  start: '01:07:00.760'
  text: nets in silicon form, uh, and, and then you, it will obviously solve for full
    self-driving.
- end: '01:07:08.760'
  start: '01:07:07.880'
  text: That's, that's the only way.
- end: '01:07:09.840'
  start: '01:07:08.880'
  text: I don't think there's any other way.
- end: '01:07:14.760'
  start: '01:07:10.200'
  text: But the question is what aspects of human nature do you have to encode into
    the machine?
- end: '01:07:15.440'
  start: '01:07:15.200'
  text: Right.
- end: '01:07:19.440'
  start: '01:07:15.440'
  text: So you have to solve the perception problem, like detect, uh, and then you
    first
- end: '01:07:23.880'
  start: '01:07:19.480'
  text: or while it realize what is the perception problem for driving, like all the
    kinds
- end: '01:07:27.440'
  start: '01:07:23.880'
  text: of things you have to be able to see, like what, what do we even look at when
    we drive?
- end: '01:07:33.640'
  start: '01:07:27.840'
  text: There's, uh, I just recently heard Andre talked about at MIT about like car
    doors.
- end: '01:07:36.840'
  start: '01:07:33.680'
  text: I think it was the world's greatest talk of all time about car doors.
- end: '01:07:37.200'
  start: '01:07:36.880'
  text: Yeah.
- end: '01:07:41.000'
  start: '01:07:37.440'
  text: Um, the, the, you know, the fine details of car doors.
- end: '01:07:43.880'
  start: '01:07:41.320'
  text: Like what, what is even an open car door, man?
- end: '01:07:47.920'
  start: '01:07:44.360'
  text: So like the, the ontology of that, that's the perception problem.
- end: '01:07:51.400'
  start: '01:07:47.920'
  text: We humans solve that perception problem and Tesla has to solve that problem.
- end: '01:07:54.480'
  start: '01:07:51.600'
  text: And then there's the control and the planning couple with the perception.
- end: '01:07:59.480'
  start: '01:07:54.920'
  text: You have to figure out like what's involved in driving, like, especially in
    all
- end: '01:08:00.640'
  start: '01:07:59.480'
  text: the different edge cases.
- end: '01:08:07.320'
  start: '01:08:01.280'
  text: Um, and, and then there, I mean, maybe you can comment on this, how much game
- end: '01:08:12.480'
  start: '01:08:07.320'
  text: theoretic kind of stuff needs to be involved, you know, at a four way stop
    sign.
- end: '01:08:17.640'
  start: '01:08:13.240'
  text: You know, our, as humans, when we drive our actions affect the world.
- end: '01:08:20.480'
  start: '01:08:18.040'
  text: Like it changes how others behave.
- end: '01:08:22.080'
  start: '01:08:20.760'
  text: Most of the time was driving.
- end: '01:08:29.200'
  start: '01:08:22.120'
  text: If you, you're usually just responding, um, to the scene as opposed to like
    really,
- end: '01:08:31.320'
  start: '01:08:29.240'
  text: um, asserting yourself in the scene.
- end: '01:08:35.920'
  start: '01:08:31.320'
  text: Do you think, I think these, I think, I think these, these sort of control,
- end: '01:08:39.200'
  start: '01:08:35.920'
  text: control logic conundrums are not, are not the hard part.
- end: '01:08:47.160'
  start: '01:08:39.680'
  text: Um, the, you know, let's see, um, what do you think is the hard part in this
- end: '01:08:50.520'
  start: '01:08:47.160'
  text: whole, um, beautiful, complex problem.
- end: '01:08:52.360'
  start: '01:08:50.560'
  text: So it's a lot of frigging software, man.
- end: '01:08:54.160'
  start: '01:08:52.960'
  text: A lot of smart lines of code.
- end: '01:09:03.400'
  start: '01:08:54.600'
  text: Um, uh, for sure, in order to have, um, create an accurate vector space.
- end: '01:09:08.760'
  start: '01:09:03.720'
  text: Uh, so like you're, you're, you're coming from image space, which is like
- end: '01:09:12.360'
  start: '01:09:08.760'
  text: this, this flow of, um, photons.
- end: '01:09:12.680'
  start: '01:09:12.440'
  text: Yeah.
- end: '01:09:18.840'
  start: '01:09:12.680'
  text: Going to the camera cameras and, and then, uh, so you have this massive
- end: '01:09:25.760'
  start: '01:09:18.840'
  text: bit stream, um, in, in image space, uh, and then you have to, uh, effectively
- end: '01:09:36.840'
  start: '01:09:25.760'
  text: compress, uh, the, uh, a massive bit stream, uh, corresponding to photons
- end: '01:09:42.200'
  start: '01:09:36.840'
  text: that knocked off an electron in a camera sensor, uh, and, and turn
- end: '01:09:45.120'
  start: '01:09:42.200'
  text: that bit stream into, into vector space.
- end: '01:09:53.640'
  start: '01:09:45.360'
  text: Um, uh, by, by vector space, I mean like, uh, you know, you've got cars
- end: '01:10:01.360'
  start: '01:09:53.640'
  text: and, and humans and, uh, lane lines and curves and, uh, traffic lights
- end: '01:10:02.200'
  start: '01:10:01.360'
  text: and that kind of thing.
- end: '01:10:09.000'
  start: '01:10:02.840'
  text: Um, once, once you, uh, have an accurate vector space, um, the control
- end: '01:10:12.600'
  start: '01:10:09.000'
  text: problem is similar to that of a video game, like a grand theft
- end: '01:10:16.040'
  start: '01:10:12.600'
  text: order of cyberpunk, um, if you have accurate, accurate best vector space.
- end: '01:10:19.400'
  start: '01:10:16.240'
  text: It's the control problem is, it's, it's, I wouldn't say it's, it's
- end: '01:10:24.600'
  start: '01:10:19.400'
  text: trivial, it's not trivial, but it's, um, it's, it's, it's, it's, it's, it's
- end: '01:10:27.800'
  start: '01:10:24.600'
  text: not like some insurmountable thing.
- end: '01:10:31.360'
  start: '01:10:27.800'
  text: It's, it's, it's, but, but having an accurate vector space is very
- end: '01:10:31.880'
  start: '01:10:31.360'
  text: difficult.
- end: '01:10:32.280'
  start: '01:10:32.120'
  text: Yeah.
- end: '01:10:36.200'
  start: '01:10:32.280'
  text: I think we humans, uh, don't give enough respect to how incredible
- end: '01:10:42.160'
  start: '01:10:36.200'
  text: the human perception system is to mapping the raw photons to the vector
- end: '01:10:43.840'
  start: '01:10:42.160'
  text: space representation in our heads.
- end: '01:10:49.160'
  start: '01:10:44.640'
  text: Your brain is doing an incredible amount of processing, um, and, and giving
- end: '01:10:51.360'
  start: '01:10:49.160'
  text: you an image that is a very cleaned up image.
- end: '01:10:54.600'
  start: '01:10:51.360'
  text: Like when we look around here, we seek, like you see color in the
- end: '01:10:57.760'
  start: '01:10:54.600'
  text: corners of your eyes, but actually your eyes have very few, uh,
- end: '01:11:01.800'
  start: '01:10:58.400'
  text: uh, cones, like the cone receptors in the peripheral vision.
- end: '01:11:05.640'
  start: '01:11:02.240'
  text: Your, your, your eyes are painting color in the peripheral vision.
- end: '01:11:09.040'
  start: '01:11:05.640'
  text: You don't realize it, but their eyes are actually painting color.
- end: '01:11:13.480'
  start: '01:11:09.040'
  text: And your eyes also have like this blood vessels and also to gnarly things.
- end: '01:11:15.880'
  start: '01:11:13.480'
  text: And there's a blind spot, but do you see your blind spot?
- end: '01:11:20.840'
  start: '01:11:16.360'
  text: No, your, your, your, your brain is painting in the missing, the blind spot.
- end: '01:11:24.320'
  start: '01:11:21.160'
  text: You're going to do these like, see these things online where you look,
- end: '01:11:27.360'
  start: '01:11:24.360'
  text: look here and look at this point and, and then look at this point.
- end: '01:11:31.440'
  start: '01:11:27.400'
  text: And it's, if it's in your blind spot, it, it, your brain will just
- end: '01:11:33.320'
  start: '01:11:31.440'
  text: fill in the, the missing bits.
- end: '01:11:35.040'
  start: '01:11:33.680'
  text: The peripheral vision is so cool.
- end: '01:11:35.480'
  start: '01:11:35.240'
  text: Yeah.
- end: '01:11:37.960'
  start: '01:11:35.480'
  text: It's, you realize all the illusions for vision science.
- end: '01:11:40.560'
  start: '01:11:37.960'
  text: And so it makes you realize just how incredible the brain is.
- end: '01:11:43.800'
  start: '01:11:40.640'
  text: The brain is doing crazy amount of post-processing on the vision
- end: '01:11:44.640'
  start: '01:11:43.800'
  text: signals from your eyes.
- end: '01:11:46.440'
  start: '01:11:45.240'
  text: Um, it's insane.
- end: '01:11:51.800'
  start: '01:11:47.600'
  text: So, um, and then, and then even once you get all those vision signals,
- end: '01:11:57.320'
  start: '01:11:52.080'
  text: uh, your, your brain is constantly trying to, to, to forget as much as possible.
- end: '01:12:01.320'
  start: '01:11:57.640'
  text: So human memory is perhaps the weakest thing about the brain is memory.
- end: '01:12:07.160'
  start: '01:12:01.880'
  text: So because memory is so expensive to a brain and so limited, your brain is
- end: '01:12:09.400'
  start: '01:12:07.160'
  text: trying to forget as much as possible.
- end: '01:12:15.280'
  start: '01:12:09.720'
  text: And there's still the things that you see into, uh, the smallest, smallest
- end: '01:12:16.480'
  start: '01:12:15.280'
  text: amounts of information possible.
- end: '01:12:20.520'
  start: '01:12:16.480'
  text: So your brain is trying to not just get to a vector space, but get to a vector
- end: '01:12:24.880'
  start: '01:12:20.520'
  text: space that is the smallest possible vector space of only relevant objects.
- end: '01:12:31.280'
  start: '01:12:25.800'
  text: Um, and I think like you can sort of look inside your brain, or at least I
    can,
- end: '01:12:36.080'
  start: '01:12:31.320'
  text: like when you drive down the road and, and try to think about what your brain
    is
- end: '01:12:38.160'
  start: '01:12:36.080'
  text: actually doing consciously.
- end: '01:12:44.760'
  start: '01:12:38.960'
  text: And it's, it's, it's, it's, it's, it's like, you'll see a car that's because
- end: '01:12:46.440'
  start: '01:12:44.760'
  text: you're, you're, you don't have cameras.
- end: '01:12:48.600'
  start: '01:12:46.560'
  text: You, I don't have eyes in the back of your head or the side.
- end: '01:12:53.000'
  start: '01:12:48.720'
  text: You know, so you say like, you, you, you basically, your, your head is like,
    uh,
- end: '01:12:56.680'
  start: '01:12:53.520'
  text: you know, you basically have like two cameras on a slow gimbal.
- end: '01:13:01.520'
  start: '01:12:57.240'
  text: Um, and, and what's your, and I said, it's not that great.
- end: '01:13:01.920'
  start: '01:13:01.680'
  text: Okay.
- end: '01:13:05.800'
  start: '01:13:01.920'
  text: You and I is a, you know, like, um, and people are constantly distracted and
- end: '01:13:08.720'
  start: '01:13:05.800'
  text: thinking about things and texting and doing all sorts of things they shouldn't
- end: '01:13:10.440'
  start: '01:13:08.720'
  text: do in a car, changing the radio station.
- end: '01:13:18.280'
  start: '01:13:10.920'
  text: So having arguments, you know, is like, um, so, so then like, say like,
- end: '01:13:23.800'
  start: '01:13:18.600'
  text: like, uh, like when's the last time you looked right and left and, you know,
    or
- end: '01:13:28.960'
  start: '01:13:23.800'
  text: and, and rearward, um, or even diagonally, you know, forward to actually
- end: '01:13:30.480'
  start: '01:13:28.960'
  text: refresh your vector space.
- end: '01:13:35.160'
  start: '01:13:31.160'
  text: So you're, you're glancing around and what your mind is doing is, is, is trying
- end: '01:13:41.000'
  start: '01:13:35.160'
  text: to still, um, relevant vectors, basically objects with a position and motion.
- end: '01:13:48.240'
  start: '01:13:41.440'
  text: Uh, and, and then, and then, uh, editing that down to the least amount that's
- end: '01:13:49.320'
  start: '01:13:48.240'
  text: necessary for you to drive.
- end: '01:13:54.560'
  start: '01:13:49.840'
  text: It does seem to be able to, uh, edit it down or compress it even further
- end: '01:13:55.720'
  start: '01:13:54.560'
  text: into things like concepts.
- end: '01:13:59.360'
  start: '01:13:55.720'
  text: So it's not, it's like, it goes beyond the human mind seems to go sometimes
- end: '01:14:04.840'
  start: '01:13:59.360'
  text: beyond vector space to sort of space of concepts to where you'll see a thing.
- end: '01:14:07.240'
  start: '01:14:05.000'
  text: It's no longer represented spatially somehow.
- end: '01:14:09.600'
  start: '01:14:07.440'
  text: It's almost like a concept that you should be aware of.
- end: '01:14:15.160'
  start: '01:14:10.000'
  text: Like if this is a school zone, you'll remember that as a concept, which is
- end: '01:14:19.520'
  start: '01:14:15.160'
  text: a weird thing to represent, but perhaps for driving, you don't need to fully
- end: '01:14:24.640'
  start: '01:14:19.520'
  text: represent those things, or maybe you get those kind of, um, well, you
- end: '01:14:29.600'
  start: '01:14:25.000'
  text: indirectly, you need, you need to like establish vector space and then actually
- end: '01:14:34.040'
  start: '01:14:29.600'
  text: have predictions for, uh, that those vector spaces.
- end: '01:14:40.960'
  start: '01:14:34.040'
  text: So like, um, you know, like if, uh, you know, like you drive past, say, say,
    uh,
- end: '01:14:47.800'
  start: '01:14:41.680'
  text: uh, uh, uh, a bus and the, and you see that this, this people, before you
- end: '01:14:51.120'
  start: '01:14:47.800'
  text: drove past the bus, you saw people crossing, like, or some just imagine
- end: '01:14:54.080'
  start: '01:14:51.120'
  text: there's like a large truck or something blocking site.
- end: '01:14:58.960'
  start: '01:14:54.640'
  text: Um, but you, before you came out to the truck, you saw that there were some
- end: '01:15:01.480'
  start: '01:14:58.960'
  text: kids about to cross the road in front of the truck.
- end: '01:15:05.520'
  start: '01:15:01.480'
  text: Now you can no longer see the kids, but you, you need to be able, but you
    would
- end: '01:15:09.440'
  start: '01:15:05.520'
  text: now know, okay, those kids are probably going to pass by the truck and cross
    the
- end: '01:15:11.600'
  start: '01:15:09.440'
  text: road, even though you cannot see them.
- end: '01:15:18.320'
  start: '01:15:11.960'
  text: So you have to have, um, memory, uh, that you had to need to remember that
- end: '01:15:22.240'
  start: '01:15:18.320'
  text: there were kids there and you need to have some forward prediction of what
- end: '01:15:25.600'
  start: '01:15:22.240'
  text: their, uh, position will be at the time of relevance.
- end: '01:15:29.920'
  start: '01:15:25.640'
  text: So with, with occlusions and computer vision, when you can't see an object
- end: '01:15:34.120'
  start: '01:15:29.920'
  text: anymore, even when just walks behind a tree and reappears, that's a really,
- end: '01:15:39.280'
  start: '01:15:34.120'
  text: really, I mean, at least in academic literature, it's tracking through occlusions.
- end: '01:15:40.080'
  start: '01:15:39.280'
  text: It's very difficult.
- end: '01:15:41.320'
  start: '01:15:40.600'
  text: Yeah, we're doing it.
- end: '01:15:42.680'
  start: '01:15:41.520'
  text: Um, I understand this.
- end: '01:15:46.400'
  start: '01:15:43.440'
  text: So some of it, it's like object permanence, like the same thing happens with
- end: '01:15:47.680'
  start: '01:15:46.400'
  text: the humans with neural nets.
- end: '01:15:51.800'
  start: '01:15:47.680'
  text: Like when like a toddler grows up, like there's a, there's a point in time
- end: '01:15:56.120'
  start: '01:15:51.800'
  text: where, uh, they develop, they have a sense of object permanence.
- end: '01:16:00.080'
  start: '01:15:56.200'
  text: So before a certain age, if you have a ball, uh, or a toy or whatever, and
    you
- end: '01:16:03.880'
  start: '01:16:00.080'
  text: put it behind your back and you pop it out, if they don't, before they have
- end: '01:16:05.800'
  start: '01:16:03.880'
  text: object permanence, it's like a new thing every time.
- end: '01:16:08.240'
  start: '01:16:05.880'
  text: It's like, whoa, this toy went, just spared.
- end: '01:16:09.920'
  start: '01:16:08.240'
  text: And now it's back again, and they can't believe it.
- end: '01:16:13.560'
  start: '01:16:09.960'
  text: And that they can play peekaboo all day long because the peekaboo is fresh
    every time.
- end: '01:16:19.120'
  start: '01:16:16.160'
  text: But then we figured out object permanence, then they realized, oh, no,
- end: '01:16:20.360'
  start: '01:16:19.120'
  text: the object is not gone.
- end: '01:16:21.160'
  start: '01:16:20.360'
  text: It's just behind your back.
- end: '01:16:25.920'
  start: '01:16:21.920'
  text: Um, sometimes I wish we never did figure out object permanence.
- end: '01:16:26.560'
  start: '01:16:26.320'
  text: Yeah.
- end: '01:16:30.880'
  start: '01:16:26.560'
  text: So that's, uh, that's an important problem to solve.
- end: '01:16:32.040'
  start: '01:16:31.600'
  text: Yes.
- end: '01:16:36.640'
  start: '01:16:32.040'
  text: So, so like an important evolution of the neural nets in the car is, uh,
- end: '01:16:43.280'
  start: '01:16:38.600'
  text: um, memory across, memory across both time and space.
- end: '01:16:47.720'
  start: '01:16:43.440'
  text: Um, so, uh, no, you can't remember, like you have to say, like, how long do
- end: '01:16:48.920'
  start: '01:16:47.720'
  text: you want to remember things for?
- end: '01:16:53.240'
  start: '01:16:48.920'
  text: And, and it's, there's, there's a cost to remembering things for a long time.
- end: '01:16:57.920'
  start: '01:16:53.240'
  text: So you keep, you know, like right out of memory to try to remember too much
    for too long.
- end: '01:17:02.000'
  start: '01:16:58.480'
  text: Um, and, and then you also have things that are stale if, if, if they're
- end: '01:17:03.400'
  start: '01:17:02.560'
  text: remembering for too long.
- end: '01:17:06.840'
  start: '01:17:03.720'
  text: And then you also need things that are remembered, uh, remembered over time.
- end: '01:17:11.880'
  start: '01:17:06.840'
  text: So even if you like, say, have like, for a good sake, five seconds of
- end: '01:17:15.760'
  start: '01:17:11.880'
  text: memory, uh, on a time basis, but like, let's say you, you, you're
- end: '01:17:20.680'
  start: '01:17:15.760'
  text: parked at a light and you, and you saw, you use a pedestrian example that
- end: '01:17:25.760'
  start: '01:17:20.680'
  text: people were waiting to cross the, across the road and you can't, you
- end: '01:17:27.400'
  start: '01:17:25.760'
  text: can't quite see them because of an occlusion.
- end: '01:17:32.160'
  start: '01:17:27.960'
  text: Uh, but they might wait for a minute before the light changes for them to
- end: '01:17:32.840'
  start: '01:17:32.160'
  text: cross the road.
- end: '01:17:36.280'
  start: '01:17:33.120'
  text: You still need to, to remember that they, that that's where they were.
- end: '01:17:39.680'
  start: '01:17:36.960'
  text: Um, and that they're probably going to cross the road type of thing.
- end: '01:17:44.880'
  start: '01:17:39.760'
  text: Um, so even if that exceeds your, your, your time-based memory, it should
- end: '01:17:46.840'
  start: '01:17:44.880'
  text: not exceed your space of memory.
- end: '01:17:50.480'
  start: '01:17:48.120'
  text: And I just think the data engine side of that.
- end: '01:17:55.200'
  start: '01:17:50.480'
  text: So getting the data to learn all of the concepts that you're saying now is
    an
- end: '01:17:56.160'
  start: '01:17:55.200'
  text: incredible process.
- end: '01:18:00.440'
  start: '01:17:56.160'
  text: It's this iterative process of just, it's this, this hydranetic, many
- end: '01:18:05.080'
  start: '01:18:03.440'
  text: work changing the name to something else.
- end: '01:18:05.720'
  start: '01:18:05.360'
  text: Okay.
- end: '01:18:09.520'
  start: '01:18:05.840'
  text: I'm sure it'd be, uh, equally as Rick and Morty, like,
- end: '01:18:15.080'
  start: '01:18:09.680'
  text: there's a lot of, yeah, we've re-architected the neural net, uh, neural
- end: '01:18:15.800'
  start: '01:18:15.080'
  text: nets in the cars.
- end: '01:18:17.200'
  start: '01:18:15.840'
  text: So many times it's crazy.
- end: '01:18:20.680'
  start: '01:18:17.960'
  text: Oh, so every time there's a new major version, you'll rename it to
- end: '01:18:24.520'
  start: '01:18:20.680'
  text: something more ridiculous or, or memorable and beautiful.
- end: '01:18:24.920'
  start: '01:18:24.520'
  text: Sorry.
- end: '01:18:26.160'
  start: '01:18:25.040'
  text: Not ridiculous, of course.
- end: '01:18:33.240'
  start: '01:18:28.120'
  text: If you see the full, the full like, uh, array of neural nets that, that, that
- end: '01:18:35.360'
  start: '01:18:33.240'
  text: we're operating in the car, it's kind of boggles the mind.
- end: '01:18:37.600'
  start: '01:18:35.600'
  text: There's so, there's so many layers.
- end: '01:18:38.400'
  start: '01:18:37.600'
  text: It's crazy.
- end: '01:18:41.800'
  start: '01:18:38.480'
  text: Um, so, yeah.
- end: '01:18:50.080'
  start: '01:18:42.200'
  text: Um, but, and, and we, we started off with, uh, simple neural nets that were,
    uh,
- end: '01:18:57.240'
  start: '01:18:50.720'
  text: basically, uh, image recognition on a single frame from a single camera, uh,
    and
- end: '01:19:04.560'
  start: '01:18:57.240'
  text: then, uh, trying to knit those together with it, you know, with, uh, see,
    uh, I
- end: '01:19:08.880'
  start: '01:19:04.560'
  text: should say we, we're really primarily running C here because C plus plus is
- end: '01:19:11.160'
  start: '01:19:09.480'
  text: too much overhead and we have our own C compiler.
- end: '01:19:16.120'
  start: '01:19:11.680'
  text: So to get maximum performance, we actually wrote, wrote our own C compiler
    and are
- end: '01:19:20.040'
  start: '01:19:16.120'
  text: continuing to optimize our C compiler, uh, for, uh, maximum efficiency.
- end: '01:19:24.560'
  start: '01:19:20.080'
  text: In fact, we've just recently, uh, done a new river on a, on a C compiler that
    will
- end: '01:19:26.640'
  start: '01:19:24.560'
  text: compile directly to our autopilot hardware.
- end: '01:19:30.240'
  start: '01:19:26.760'
  text: Um, you want to compile the whole thing down and with your own compiler.
- end: '01:19:30.720'
  start: '01:19:30.400'
  text: Yeah.
- end: '01:19:33.880'
  start: '01:19:30.720'
  text: Like, so efficiency here, cause there's all kinds of compute.
- end: '01:19:34.920'
  start: '01:19:33.880'
  text: There's CPU, GPU.
- end: '01:19:38.360'
  start: '01:19:34.920'
  text: There's like the ASIC types of things that's, and you have to somehow figure
- end: '01:19:40.120'
  start: '01:19:38.360'
  text: out the scheduling across all of those things.
- end: '01:19:41.800'
  start: '01:19:40.120'
  text: And so you're compiling the code down.
- end: '01:19:42.200'
  start: '01:19:42.000'
  text: Yeah.
- end: '01:19:43.120'
  start: '01:19:42.200'
  text: It does all the, okay.
- end: '01:19:46.520'
  start: '01:19:43.720'
  text: This is, so that's why there's a lot of people involved.
- end: '01:19:53.680'
  start: '01:19:47.560'
  text: There's a lot of hardcore, uh, software engineering at a very sort of bare
    metal
- end: '01:19:57.920'
  start: '01:19:53.680'
  text: level, uh, cause you, we're trying to do a lot of compute, uh, that's constrained
- end: '01:20:02.920'
  start: '01:19:57.920'
  text: to the, you know, our full self-driving computer.
- end: '01:20:10.320'
  start: '01:20:03.000'
  text: So, and we want to try to have the highest frames per second, um, possible,
    um, with,
- end: '01:20:15.080'
  start: '01:20:10.320'
  text: with, sort of very, very finite amount of compute, um, and power.
- end: '01:20:21.560'
  start: '01:20:15.120'
  text: So, um, we really put a lot of effort into the efficiency of our compute.
- end: '01:20:28.200'
  start: '01:20:22.080'
  text: Um, and, and, uh, so there's actually a lot of work done by some very talented
- end: '01:20:33.560'
  start: '01:20:28.200'
  text: software engineers at Tesla that, uh, at a very foundational level to improve
- end: '01:20:39.080'
  start: '01:20:33.560'
  text: the efficiency of compute and how we use the, the, the trip accelerators,
    uh, which
- end: '01:20:45.560'
  start: '01:20:39.080'
  text: are basically, um, dot, you know, uh, doing matrix math dot, dot products,
    uh, like
- end: '01:20:46.680'
  start: '01:20:45.560'
  text: a bazillion dot products.
- end: '01:20:49.520'
  start: '01:20:47.280'
  text: And it's like, what, what, what, what are neural nets?
- end: '01:20:53.000'
  start: '01:20:49.520'
  text: It's like computer-wise, like 99% dot products.
- end: '01:20:56.960'
  start: '01:20:54.280'
  text: So, you know, um,
- end: '01:21:00.440'
  start: '01:20:57.000'
  text: And you want to achieve as many high frame rates like a video game.
- end: '01:21:04.640'
  start: '01:21:00.520'
  text: You want full, full resolution, high frame rate,
- end: '01:21:09.880'
  start: '01:21:04.960'
  text: High frame rate, low latency, um, low jitter.
- end: '01:21:16.600'
  start: '01:21:10.280'
  text: Uh, so, um, I think one of the things for, um,
- end: '01:21:25.600'
  start: '01:21:17.040'
  text: moving towards now is no post-processing of the image through the, um, uh,
    the
- end: '01:21:26.600'
  start: '01:21:25.600'
  text: image signal processor.
- end: '01:21:33.400'
  start: '01:21:26.600'
  text: So, um, like for, for what happens for cameras is that almost all cameras
    is
- end: '01:21:39.240'
  start: '01:21:33.400'
  text: they, um, there's a lot of post-processing done in order to make pictures
    look pretty.
- end: '01:21:42.320'
  start: '01:21:40.200'
  text: Uh, and so we don't care about pictures looking pretty.
- end: '01:21:44.560'
  start: '01:21:42.440'
  text: Um, we, we just want the data.
- end: '01:21:47.920'
  start: '01:21:44.920'
  text: We, so we're, we're moving to just roll, roll photon counts.
- end: '01:21:55.440'
  start: '01:21:48.720'
  text: So the system will, like the image that, that, that the computer sees is actually
- end: '01:21:59.000'
  start: '01:21:55.440'
  text: much more than what you'd see if you represented it on a camera.
- end: '01:22:00.040'
  start: '01:21:59.040'
  text: It's got much more data.
- end: '01:22:04.360'
  start: '01:22:00.720'
  text: Uh, and even in very low light conditions, you can see that there's a small
    photon
- end: '01:22:08.920'
  start: '01:22:04.360'
  text: count difference between, you know, this spot here and that spot there, which
- end: '01:22:11.880'
  start: '01:22:08.920'
  text: means that, so it can see in the dark incredibly well.
- end: '01:22:15.960'
  start: '01:22:12.640'
  text: Um, because it can detect these tiny differences in photon counts.
- end: '01:22:19.640'
  start: '01:22:16.920'
  text: That's much better than you'd possibly imagine.
- end: '01:22:26.440'
  start: '01:22:20.360'
  text: Um, so, and then we also save, uh, 13 milliseconds on a latency.
- end: '01:22:29.000'
  start: '01:22:26.560'
  text: Uh, so, um,
- end: '01:22:31.160'
  start: '01:22:29.240'
  text: From removing the post-processing and the image.
- end: '01:22:31.560'
  start: '01:22:31.200'
  text: Yes.
- end: '01:22:31.720'
  start: '01:22:31.560'
  text: Yeah.
- end: '01:22:39.400'
  start: '01:22:31.920'
  text: It's like, um, because we've got eight cameras and then there's, uh, roughly,
- end: '01:22:40.760'
  start: '01:22:39.400'
  text: I don't know, one and a half milliseconds.
- end: '01:22:46.200'
  start: '01:22:40.760'
  text: Also maybe 1.6 milliseconds of latency, um, for each camera.
- end: '01:22:55.000'
  start: '01:22:46.200'
  text: And so it, like, um, going to just, uh, it basically bypassing the image
- end: '01:22:59.120'
  start: '01:22:55.000'
  text: processor, uh, gets us back 13 milliseconds of latency, which is important.
- end: '01:23:05.440'
  start: '01:22:59.960'
  text: Um, and we track latency all the way from, you know, photon hits the, the
    camera
- end: '01:23:09.040'
  start: '01:23:05.560'
  text: to, you know, all the steps that it's going to go through to get, you know,
- end: '01:23:13.280'
  start: '01:23:09.040'
  text: go through the, um, the various neural nets and the, the C code.
- end: '01:23:16.360'
  start: '01:23:13.280'
  text: And, uh, and there's a little bit of C plus plus there as well.
- end: '01:23:22.400'
  start: '01:23:16.880'
  text: Um, well, I can maybe a lot, but it, the core stuff is the heavy duty computers
- end: '01:23:29.080'
  start: '01:23:22.400'
  text: all in C, um, and, uh, and so, so we track that latency all the way to an
- end: '01:23:35.040'
  start: '01:23:29.080'
  text: output command to the, um, drive unit to accelerate, uh, the brakes just to
    slow
- end: '01:23:37.480'
  start: '01:23:35.040'
  text: down the steering, you know, turn left or right.
- end: '01:23:41.760'
  start: '01:23:37.640'
  text: Um, so because you got to output a command that's going to go to a controller
- end: '01:23:44.080'
  start: '01:23:41.760'
  text: and like some of these controllers have an update frequency.
- end: '01:23:47.240'
  start: '01:23:44.080'
  text: That's maybe, uh, 10 hertz or something like that, which is slow.
- end: '01:23:49.560'
  start: '01:23:47.280'
  text: That's like, now you lose a hundred milliseconds potentially.
- end: '01:23:57.960'
  start: '01:23:50.160'
  text: So, um, so then we want to update the, the drivers on the, like, say, steering
- end: '01:24:02.880'
  start: '01:23:58.000'
  text: braking control to have, um, more like, uh, 100 hoods instead of 10 hoods.
- end: '01:24:05.800'
  start: '01:24:02.880'
  text: And you got a 10 millisecond latency instead of 100 milliseconds worst case
- end: '01:24:09.480'
  start: '01:24:05.800'
  text: latency and actually jitter is more of a challenge than, than, than latency.
- end: '01:24:12.040'
  start: '01:24:09.480'
  text: Because latency is like, you can, you can, you can anticipate and predict.
- end: '01:24:15.720'
  start: '01:24:12.040'
  text: But if you're, but if you've got a stack up of things going from the camera
    to
- end: '01:24:19.920'
  start: '01:24:15.720'
  text: the, to the computer through then a series of other computers and finally
    to
- end: '01:24:26.340'
  start: '01:24:19.920'
  text: an actuator on the car, if you have a stack up of, uh, of tolerances of timing
- end: '01:24:29.740'
  start: '01:24:26.380'
  text: tolerances, then you can have quite a variable latency, which is called jitter.
- end: '01:24:35.700'
  start: '01:24:30.340'
  text: And, and that makes it a hard to, to, to anticipate exactly what, how you
- end: '01:24:37.460'
  start: '01:24:35.700'
  text: should turn the car or accelerate.
- end: '01:24:42.580'
  start: '01:24:37.460'
  text: Because, you know, if you've got maybe 150, 200 milliseconds of jitter, then
- end: '01:24:46.220'
  start: '01:24:42.580'
  text: you could be off by, you know, up to 0.2 seconds and this can make, this
- end: '01:24:47.220'
  start: '01:24:46.220'
  text: could make a big difference.
- end: '01:24:52.220'
  start: '01:24:47.500'
  text: So you have to interpolate somehow to, to, to, uh, deal with the effects of
    jitter.
- end: '01:24:56.780'
  start: '01:24:52.380'
  text: So you, they can make like robust control decisions.
- end: '01:24:58.180'
  start: '01:24:57.900'
  text: Yeah.
- end: '01:25:02.240'
  start: '01:24:58.180'
  text: Then you have to, uh, so the jitters in the sensor information or is it, the
- end: '01:25:04.740'
  start: '01:25:02.240'
  text: jitter can occur at any stage in the pipeline.
- end: '01:25:08.780'
  start: '01:25:04.940'
  text: You can, if you have just, if you have a fixed latency, you can anticipate.
- end: '01:25:15.740'
  start: '01:25:09.140'
  text: Um, and, and, uh, like say, okay, we know that, uh, our information is for
- end: '01:25:21.020'
  start: '01:25:15.740'
  text: argument's sake, 150 milliseconds stale, like, so for, for, um, hundred
- end: '01:25:28.060'
  start: '01:25:21.420'
  text: 40 milliseconds from photon second camera to, um, where you can measure, uh,
    a
- end: '01:25:30.620'
  start: '01:25:28.060'
  text: change in the acceleration of the vehicle.
- end: '01:25:38.300'
  start: '01:25:31.460'
  text: Um, so then, uh, then you're going to say, okay, well, we're going to enter,
    we,
- end: '01:25:39.380'
  start: '01:25:38.300'
  text: we know it's 150 milliseconds.
- end: '01:25:44.180'
  start: '01:25:39.380'
  text: So we're going to take that into account and, uh, and compensate for that
    latency.
- end: '01:25:47.580'
  start: '01:25:44.220'
  text: However, if you, if you've got then 150 milliseconds of latency plus
- end: '01:25:51.040'
  start: '01:25:47.580'
  text: 100 milliseconds of jitter, that's, which could be anywhere from zero to
- end: '01:25:52.220'
  start: '01:25:51.040'
  text: a hundred milliseconds on top.
- end: '01:25:55.740'
  start: '01:25:52.220'
  text: So, so then your latency could be from 150 to 250 milliseconds.
- end: '01:25:57.540'
  start: '01:25:55.740'
  text: Now you've got a hundred milliseconds that you don't know what to do with.
- end: '01:25:59.820'
  start: '01:25:58.060'
  text: And, and that's basically random.
- end: '01:26:03.300'
  start: '01:26:01.420'
  text: So getting rid of jitter is extremely important.
- end: '01:26:06.980'
  start: '01:26:04.260'
  text: And that affects your control decisions and all those kinds of things.
- end: '01:26:07.740'
  start: '01:26:07.380'
  text: Okay.
- end: '01:26:11.320'
  start: '01:26:08.740'
  text: Um, yeah, the, the cars is going to fundamentally maneuver better with
- end: '01:26:16.100'
  start: '01:26:11.320'
  text: lower jitter, um, the, the, the, the, the cause will maneuver with super
- end: '01:26:18.860'
  start: '01:26:16.100'
  text: human ability and reaction time much faster than a human.
- end: '01:26:25.620'
  start: '01:26:20.140'
  text: Um, I mean, I think over time, the autopilot, full self-driving will be
- end: '01:26:33.940'
  start: '01:26:25.620'
  text: capable of maneuvers that, um, you know, uh, you know, are far more than what
- end: '01:26:36.340'
  start: '01:26:33.940'
  text: like James Bond could do in like the best movie type of thing.
- end: '01:26:39.220'
  start: '01:26:36.420'
  text: That's exactly where I was imagining my mind as you said it.
- end: '01:26:42.820'
  start: '01:26:39.740'
  text: Um, it's like impossible maneuvers that a human couldn't do.
- end: '01:26:43.380'
  start: '01:26:42.900'
  text: You know, so.
- end: '01:26:49.380'
  start: '01:26:44.380'
  text: Well, let me ask sort of, uh, looking back the six years, looking out into
    the future,
- end: '01:26:53.700'
  start: '01:26:49.620'
  text: based on your current understanding, how, how hard do you think this, this
    full
- end: '01:26:58.100'
  start: '01:26:53.700'
  text: self-driving problem, when do you think Tesla will solve level four FSD?
- end: '01:27:02.820'
  start: '01:27:00.500'
  text: I mean, it's looking quite likely that it will be next year.
- end: '01:27:06.540'
  start: '01:27:05.020'
  text: And what does the solution look like?
- end: '01:27:09.540'
  start: '01:27:06.540'
  text: Is it the current pool of FSD beta candidates?
- end: '01:27:15.180'
  start: '01:27:10.540'
  text: Um, they start getting greater and greater as they have been degrees of autonomy,
    and
- end: '01:27:20.060'
  start: '01:27:15.180'
  text: then there's a certain level beyond which they can, they, they can do their
    own.
- end: '01:27:20.740'
  start: '01:27:20.060'
  text: They can read a book.
- end: '01:27:22.540'
  start: '01:27:22.140'
  text: Yeah.
- end: '01:27:28.420'
  start: '01:27:22.540'
  text: So, uh, I mean, you can see that anybody who's been following the full self-driving
- end: '01:27:36.180'
  start: '01:27:28.420'
  text: beta closely, um, will see that the, um, the rate of disengagement has been
    dropping rapidly.
- end: '01:27:41.300'
  start: '01:27:37.140'
  text: So like disengagement be where, where the driver intervenes to prevent the
    car from
- end: '01:27:44.100'
  start: '01:27:41.300'
  text: doing something, uh, dangerous potentially.
- end: '01:27:54.900'
  start: '01:27:44.100'
  text: So, um, so the interventions, you know, per million miles has been dropping
    dramatically
- end: '01:28:04.020'
  start: '01:27:54.900'
  text: at some point the, and that trend looks like it happens next year is that
    the probability
- end: '01:28:11.060'
  start: '01:28:04.100'
  text: of an accident on FSD, uh, is, uh, less than that of the average human and
    then, and then
- end: '01:28:12.660'
  start: '01:28:11.060'
  text: significantly less than that of the average human.
- end: '01:28:19.620'
  start: '01:28:12.980'
  text: Um, so it certainly appears like we will get there next year.
- end: '01:28:24.900'
  start: '01:28:20.340'
  text: Um, then, then of course that, that, then there's going to be a case of, okay,
    well,
- end: '01:28:28.660'
  start: '01:28:24.900'
  text: we now have to prove this to regulators and prove it to, you know, and, and
    we, we, we
- end: '01:28:33.940'
  start: '01:28:28.660'
  text: want a standard that is not just equivalent to a human, but, uh, much better
    than the average
- end: '01:28:38.900'
  start: '01:28:33.940'
  text: human. I think it's got to be at least two or three times, uh, higher safety
    than a human.
- end: '01:28:41.780'
  start: '01:28:38.900'
  text: So two or three times lower probability of injury than a human.
- end: '01:28:45.700'
  start: '01:28:42.340'
  text: Uh, before, before we would actually say like, okay, it's okay to go.
- end: '01:28:47.460'
  start: '01:28:45.700'
  text: It's not going to be a cool, it's going to be much better.
- end: '01:28:54.580'
  start: '01:28:48.180'
  text: So if you look at 10 point FSD, 10.6 just came out recently, 10.7 is on the
    way,
- end: '01:28:58.340'
  start: '01:28:55.300'
  text: maybe 11 is on the way to where in the future.
- end: '01:29:01.780'
  start: '01:28:58.340'
  text: Yeah. Um, we were hoping to get 11 out this year, but it's, uh,
- end: '01:29:09.140'
  start: '01:29:03.460'
  text: 11 actually has a whole bunch of, uh, fundamental rewrites on the neural,
    neural net architecture.
- end: '01:29:16.180'
  start: '01:29:09.780'
  text: Um, and, and some fundamental improvements, uh, in creating vector space.
- end: '01:29:23.780'
  start: '01:29:17.460'
  text: So, uh, there is a, some fundamental like leap that really deserves the 11.
- end: '01:29:25.060'
  start: '01:29:23.780'
  text: I mean, that's a pretty cool number.
- end: '01:29:32.260'
  start: '01:29:25.060'
  text: Yeah. Uh, 11 would be, uh, a single stack for all, you know, one stack to
    rule them all.
- end: '01:29:41.460'
  start: '01:29:32.260'
  text: Um, and, uh, but, but there, there's just some really fundamental, uh, neural
    net architecture
- end: '01:29:50.020'
  start: '01:29:41.460'
  text: changes that are, that will allow for, uh, much more capability, but, but,
    you know, at first
- end: '01:29:54.580'
  start: '01:29:50.020'
  text: they're going to have issues. So like we have this working on like sort of
    alpha software.
- end: '01:30:01.300'
  start: '01:29:54.580'
  text: And it's, it's good, but it's, uh, it's, it's, it's, it's basically taking
    a whole bunch of C C
- end: '01:30:05.860'
  start: '01:30:01.300'
  text: plus plus code and, and, and leading a massive amount of C plus plus code
    and replacing it with
- end: '01:30:09.940'
  start: '01:30:05.860'
  text: the neural net. And you know, Andre, um, makes this point a lot, which he's
    like neural nets,
- end: '01:30:15.140'
  start: '01:30:09.940'
  text: like kind of eating software, you know, over time there's like less and less
    conventional
- end: '01:30:18.900'
  start: '01:30:15.140'
  text: software, more and more neural net, uh, we were just still software, but it's,
    you know,
- end: '01:30:25.380'
  start: '01:30:19.620'
  text: still comes out the lines of software, but, uh, let's, it's more, more neural
    net stuff, uh, and
- end: '01:30:35.380'
  start: '01:30:25.380'
  text: less, uh, you know, heuristics basically, um, if you're more, more, more,
    uh, matrix-based
- end: '01:30:43.220'
  start: '01:30:36.260'
  text: stuff and less, uh, heuristics-based stuff. Um, and, um,
- end: '01:30:52.820'
  start: '01:30:44.020'
  text: um, you know, like, like, like one of the big changes will be, um, like right
    now the neural
- end: '01:31:04.100'
  start: '01:30:52.820'
  text: nets, uh, will, um, deliver a giant bag of points, uh, to the C plus plus
    or C and C plus plus code.
- end: '01:31:09.780'
  start: '01:31:04.100'
  text: Yeah. Um, we call it the giant bag of points. Yeah. Uh, and it's like, so
    you go to pixel and,
- end: '01:31:14.740'
  start: '01:31:09.780'
  text: and, and, and something associated with that pixel, like this pixel is probably
    car,
- end: '01:31:19.780'
  start: '01:31:14.740'
  text: the pixel is probably lane line. Um, then you've got to assemble this giant
    bag of points
- end: '01:31:28.980'
  start: '01:31:20.340'
  text: in the C code and turn it into, uh, vectors. Um, and, uh, it does a pretty
    good job of it, but it's,
- end: '01:31:36.660'
  start: '01:31:29.860'
  text: it's, uh, it's, we want to just, we need another layer of neural nets on top
    of that to take the,
- end: '01:31:44.740'
  start: '01:31:36.660'
  text: the giant bag of points and distill that down to vector space in the neural
    net part of the
- end: '01:31:51.060'
  start: '01:31:44.740'
  text: software as opposed to the heuristics part of the software. This is a big
    improvement. Um,
- end: '01:31:55.780'
  start: '01:31:51.060'
  text: neural nets all the way down is what you want. It's not even your own neural
    net, but it's, it's,
- end: '01:32:01.620'
  start: '01:31:55.780'
  text: it's, uh, this will be just a, this is a game changer to not have the bag
    of points, the giant
- end: '01:32:08.420'
  start: '01:32:01.620'
  text: bag of points that has to be assembled with, uh, many lines of C C plus plus,
    uh, and, and have the,
- end: '01:32:14.820'
  start: '01:32:09.300'
  text: and have a neural net just assemble those into vectors. So, so the, the, the
    neural net is outputting,
- end: '01:32:22.740'
  start: '01:32:15.940'
  text: um, much, much less data. It's, it's, it's outputting this, this is a lane
    line. This is a curve. This
- end: '01:32:28.740'
  start: '01:32:22.740'
  text: is drivable space. This is a car. This is, uh, you know, a pedestrian or cyclist
    or something
- end: '01:32:38.100'
  start: '01:32:28.740'
  text: like that. It's outputting, um, it's really outputting, um, proper vectors
    to the, the C C plus
- end: '01:32:49.140'
  start: '01:32:38.100'
  text: plus control, control code as opposed to the sort of constructing the, the
    vectors, uh, in, in C. Um,
- end: '01:32:55.220'
  start: '01:32:50.260'
  text: which we've done, I think quite a good job of, but it's, it's a, it's kind
    of hitting a local
- end: '01:33:01.620'
  start: '01:32:55.220'
  text: maximum on the, how well this, you can do this. Um, so this is, this is really,
    this is a really
- end: '01:33:06.580'
  start: '01:33:01.620'
  text: big deal. And, and just all of the networks in the car need, need to move
    to surround video.
- end: '01:33:13.220'
  start: '01:33:06.580'
  text: There's still some legacy networks that are not, uh, surround video. Um, and
    all of the training
- end: '01:33:17.700'
  start: '01:33:13.220'
  text: needs to move to surround video and the efficiency of the training, uh, it
    needs to get better than
- end: '01:33:26.020'
  start: '01:33:17.700'
  text: it is. Uh, and then we need to move everything to, uh, raw, uh, photon, uh,
    counts as opposed to,
- end: '01:33:32.020'
  start: '01:33:26.580'
  text: um, processed images, which is, which is quite a big reset on the training
    because the system's
- end: '01:33:39.380'
  start: '01:33:32.020'
  text: trained on post-processed images. So we need to redo all the training, uh,
    to train against
- end: '01:33:45.060'
  start: '01:33:39.380'
  text: the, the raw photon counts instead of the post-processed image. So ultimately
    it's kind
- end: '01:33:50.420'
  start: '01:33:45.140'
  text: of reducing the complexity of the whole thing. So, uh, reducing, reducing
    lines of code will
- end: '01:33:56.020'
  start: '01:33:50.420'
  text: actually go, go lower. Yeah. That's fascinating. Um, so you're doing fusion
    of all the sensors
- end: '01:34:00.100'
  start: '01:33:56.020'
  text: and reducing the complexity of having to deal with these cameras. There's
    a lot of cameras really.
- end: '01:34:07.940'
  start: '01:34:00.100'
  text: Right. Yes. Um, same with humans. Uh, well, I guess we got years too. Okay.
    Yeah. Well,
- end: '01:34:12.420'
  start: '01:34:07.940'
  text: we'll actually need to incorporate, um, sound as well. Um, cause you know,
    you need to like
- end: '01:34:18.260'
  start: '01:34:12.420'
  text: listen for ambulance sirens or fire, you know, fire trucks, you know, uh,
    if somebody like,
- end: '01:34:22.420'
  start: '01:34:19.300'
  text: you know, yelling at you or something, I don't know, just there's, there's
    a little bit of
- end: '01:34:26.500'
  start: '01:34:22.420'
  text: audio that needs to be incorporated as well. Do you need to go back to break?
    Yeah, let's
- end: '01:34:33.620'
  start: '01:34:26.500'
  text: let's take a break. Okay. Honestly, frankly, like the ideas are, are the easy
    thing and the
- end: '01:34:37.620'
  start: '01:34:33.620'
  text: implementation is the hard thing. Like the idea of going to the moon is, is
    the easy part,
- end: '01:34:42.580'
  start: '01:34:37.700'
  text: but going to the moon is the hard part. And there's a lot of like hardcore
    engineering
- end: '01:34:48.020'
  start: '01:34:42.580'
  text: that's got to get done at the hardware and software level. Uh, like sit optimizing
    the
- end: '01:34:56.340'
  start: '01:34:48.020'
  text: C compiler and just, you know, uh, cutting out latency everywhere. Like this
    is,
- end: '01:35:02.420'
  start: '01:34:57.060'
  text: if we don't do this, the system will not work properly. Um, so the work of
    the engineers doing
- end: '01:35:07.540'
  start: '01:35:02.420'
  text: this, they are like the unsung heroes to some, you know, but they are critical
    to the success
- end: '01:35:11.540'
  start: '01:35:07.540'
  text: of the situation. I think he made it clear. I mean, at least to me, it's super
    exciting.
- end: '01:35:16.260'
  start: '01:35:11.540'
  text: Everything that's going on outside of what Andre is doing, just the whole
    infrastructure,
- end: '01:35:20.820'
  start: '01:35:16.260'
  text: the software, I mean, everything is going on with data engine, uh, whatever,
    whatever it's
- end: '01:35:26.340'
  start: '01:35:20.820'
  text: called, the whole process is, it's just work of art to me. The sure scale
    of it is boggles
- end: '01:35:30.180'
  start: '01:35:26.340'
  text: the mind. Like the training, the amount of work done with the, like we've
    written all this custom
- end: '01:35:35.860'
  start: '01:35:30.180'
  text: software for training and labeling, um, and to do auto labeling, auto labeling
    is essential.
- end: '01:35:42.820'
  start: '01:35:38.260'
  text: Cause especially when you've got like surround video, it's very difficult
    to like label
- end: '01:35:50.500'
  start: '01:35:43.780'
  text: surround video from scratch is extremely difficult. Um, like take a human's
    such a long time to even
- end: '01:35:56.580'
  start: '01:35:50.500'
  text: label one video clip, like several hours, uh, or the order label it, uh, basically
    we're just
- end: '01:36:04.500'
  start: '01:35:56.660'
  text: applying like heavy duty, uh, like a lot of compute to the, to the video clips,
    um, to
- end: '01:36:08.820'
  start: '01:36:04.500'
  text: pre-assign and guess what all the things are that are going on in this round
    video.
- end: '01:36:12.820'
  start: '01:36:08.820'
  text: And then there's like correcting it. Yeah. And then all the human has to do
    is like tweet,
- end: '01:36:18.020'
  start: '01:36:12.820'
  text: like say, you know, change, adjust what is incorrect. This, this is like increase,
- end: '01:36:23.540'
  start: '01:36:18.020'
  text: increase this productivity by a hundred or more. Yeah. So you've presented
    Tesla bot as
- end: '01:36:28.260'
  start: '01:36:23.540'
  text: primarily useful in the factory. First of all, I think humanoid robots are
    incredible
- end: '01:36:33.780'
  start: '01:36:28.260'
  text: from a, a fan of robotics. I think, uh, the elegance of movement that human,
    um,
- end: '01:36:39.780'
  start: '01:36:33.780'
  text: the humanoid robots that by Peter robots show are just so cool. So it's, uh,
    really interesting
- end: '01:36:44.180'
  start: '01:36:39.780'
  text: that you're working on this and also talking about applying the same kind
    of all the ideas of
- end: '01:36:48.100'
  start: '01:36:44.180'
  text: some of what you've talked about with data engine, all the things that we're
    talking about with
- end: '01:36:53.540'
  start: '01:36:48.100'
  text: Tesla autopilot, just, uh, transferring that over to the, just yet another
    robotics problem.
- end: '01:36:59.060'
  start: '01:36:54.420'
  text: I have to ask, since I care about human robot interaction, so the human side
    of that,
- end: '01:37:04.260'
  start: '01:36:59.060'
  text: so you've talked about mostly in the factory, do you see it, uh, also, do
    you see as part of
- end: '01:37:08.340'
  start: '01:37:04.260'
  text: this problem that Tesla bot has to solve is interacting with humans and potentially
    having
- end: '01:37:14.020'
  start: '01:37:08.340'
  text: a place like in the home. So interacting, not just, not replacing labor, but
    also like,
- end: '01:37:20.180'
  start: '01:37:14.660'
  text: I don't know, being a friend or an assistant. Yeah. Yeah. I think the, the
    possibilities are,
- end: '01:37:22.180'
  start: '01:37:21.380'
  text: you know, endless.
- end: '01:37:32.260'
  start: '01:37:27.060'
  text: Yeah. I mean, it's, it's, it's obviously like a, it's not quite in, in Tesla's
    primary mission
- end: '01:37:38.100'
  start: '01:37:32.260'
  text: direction of accelerating sustainable energy, but it is a, an extremely useful
    thing that we can
- end: '01:37:43.780'
  start: '01:37:38.100'
  text: do for the world, which is to make a useful humanoid robot. Um, that is capable
    of interacting
- end: '01:37:49.940'
  start: '01:37:44.100'
  text: with the world and, um, helping in, in many different ways. Uh, so,
- end: '01:37:55.620'
  start: '01:37:51.140'
  text: so in fact reason, and really just, just, I mean, I think if you say like,
    uh,
- end: '01:38:03.300'
  start: '01:37:56.580'
  text: extrapolate to, you know, many years in the future, it's like, I think, uh,
    work will become
- end: '01:38:11.620'
  start: '01:38:03.300'
  text: optional. So like, there's a lot of jobs that if people weren't paid to do
    it, they wouldn't
- end: '01:38:16.020'
  start: '01:38:11.620'
  text: do it. Like it's not, it's not fun, you know, necessarily. Like if you're
    washing dishes all
- end: '01:38:20.260'
  start: '01:38:16.020'
  text: day, it's like, uh, you know, even if you really like washing dishes, you
    really want to do it for
- end: '01:38:27.460'
  start: '01:38:20.260'
  text: eight hours a day every day. Probably not. So, um, and then there's like dangerous
    work and
- end: '01:38:32.820'
  start: '01:38:27.460'
  text: basically if it's dangerous, boring, uh, it has like potential for repetitive
    stress injury,
- end: '01:38:39.540'
  start: '01:38:32.820'
  text: that kind of thing. Um, then that's really where humanoid robots would add
    the most value initially.
- end: '01:38:47.300'
  start: '01:38:40.500'
  text: Um, so that's what we're aiming for is, is to, um, for, for the humanoid robots
    to
- end: '01:38:53.060'
  start: '01:38:47.300'
  text: do jobs that people don't, don't voluntarily want to do. Um, and then we'll
    have to pair that
- end: '01:38:59.300'
  start: '01:38:53.060'
  text: obviously with some kind of universal basic income in the future. Uh, so I
    think, um,
- end: '01:39:04.660'
  start: '01:39:00.900'
  text: So do you see a world when there's like hundreds of millions of tesla bots
- end: '01:39:09.540'
  start: '01:39:04.980'
  text: doing different performing different tasks throughout the world?
- end: '01:39:15.460'
  start: '01:39:12.180'
  text: Yeah. I haven't really thought about it that far into the future, but I guess
    that there may be
- end: '01:39:24.580'
  start: '01:39:15.460'
  text: something like that. Um, so I guess it's a wild question. So the, the number
    of tesla cars has
- end: '01:39:30.340'
  start: '01:39:24.580'
  text: been accelerating. It's been close to 2 million produced. Many of them have
    autopilot. I think
- end: '01:39:34.660'
  start: '01:39:30.340'
  text: we're over 2 million now. Yeah. Do you think there will ever be a time when
    there'll be more tesla
- end: '01:39:44.100'
  start: '01:39:34.660'
  text: bots than tesla cars? Yeah. I, I, I, you know, actually it's funny you asked
    this question
- end: '01:39:47.620'
  start: '01:39:44.100'
  text: because normally I do try to think I've pretty far into the future, but I
    haven't really thought
- end: '01:39:55.220'
  start: '01:39:47.620'
  text: that far into the future with the, with the tesla bot or it's code named optimus.
    I call,
- end: '01:40:02.500'
  start: '01:39:55.300'
  text: I call it optimus subprime because it's not, it's not like a giant, you know,
    transformer robot.
- end: '01:40:10.660'
  start: '01:40:04.260'
  text: So, uh, but it's meant to be a general purpose helpful, helpful bot. Um,
- end: '01:40:21.300'
  start: '01:40:14.500'
  text: and, and basically like, like the things that we're basically like, like tesla,
    I think, um,
- end: '01:40:26.420'
  start: '01:40:21.300'
  text: is the, has the most advanced real world AI, uh, for interacting with the
    real world, which
- end: '01:40:32.820'
  start: '01:40:26.420'
  text: you developed as a function of to, to make self-driving work. Um, and so along
    with custom
- end: '01:40:39.380'
  start: '01:40:32.820'
  text: hardware and like a lot of, you know, uh, hardcore low-level software to have
    it run efficiently
- end: '01:40:43.540'
  start: '01:40:39.380'
  text: and be, you know, power efficient because, you know, it's one thing to do
    neural nets if you've
- end: '01:40:48.020'
  start: '01:40:43.540'
  text: got a gigantic server room with 10,000 computers, but now let's say you just,
    you have to now just
- end: '01:40:52.420'
  start: '01:40:48.020'
  text: distill that down into one computer that's running at low power in a humanoid
    robot or a car.
- end: '01:40:56.260'
  start: '01:40:52.980'
  text: Um, that's actually very difficult and a lot of hardcore software work is
    required for that.
- end: '01:41:05.620'
  start: '01:40:56.980'
  text: Um, so, so since we're kind of like solving the nav, navigate the real world
    with neural
- end: '01:41:11.140'
  start: '01:41:05.620'
  text: nets problem for cars, which are kind of like robots with four wheels, then
    it's like kind
- end: '01:41:18.420'
  start: '01:41:11.140'
  text: of a natural extension of that is to put it in a robot with arms and legs,
    uh, and actually,
- end: '01:41:29.220'
  start: '01:41:18.420'
  text: you know, actuators. Um, so, um, like, like the, the, the two, like hard things
    are like, you,
- end: '01:41:33.700'
  start: '01:41:29.220'
  text: you basically need to make the, have the row of being intelligent enough to
    interact in a
- end: '01:41:40.980'
  start: '01:41:33.700'
  text: sensible way with the environment. Um, so you see real real world AI and you
    need to be
- end: '01:41:46.580'
  start: '01:41:40.980'
  text: very good at, um, manufacturing, which is a very hard problem. Tesla is very
    good at manufacturing
- end: '01:41:54.260'
  start: '01:41:46.580'
  text: and also, uh, has the real world AI. So making the humanoid robot work is,
    uh, basically means
- end: '01:42:03.060'
  start: '01:41:54.260'
  text: developing custom, uh, motors and sensors, uh, that, that are different for
    what a car would use.
- end: '01:42:10.500'
  start: '01:42:04.020'
  text: But we, we're also, we have, um, I think we have the, the, the best expertise
    in
- end: '01:42:17.460'
  start: '01:42:11.300'
  text: developing advanced electric motors and power electronics. So it just has
    to be for
- end: '01:42:19.860'
  start: '01:42:18.260'
  text: a humanoid robot application on a car.
- end: '01:42:28.580'
  start: '01:42:22.100'
  text: Still, you do talk about love sometimes. So let me ask, this isn't like for
    like sex robots or
- end: '01:42:36.340'
  start: '01:42:28.580'
  text: something like that. I love the answer. Yes. Uh, there is something compelling
    to us, not compelling,
- end: '01:42:42.100'
  start: '01:42:36.340'
  text: but we connect with, um, humanoid robots or even legged robots, like with
    the dog and shapes of
- end: '01:42:47.540'
  start: '01:42:42.100'
  text: dogs. It just, it seems like, you know, there's a huge amount of loneliness
    in this world.
- end: '01:42:52.500'
  start: '01:42:48.100'
  text: All of us seek companionship and with other humans, friendship and all those
    kinds of things.
- end: '01:42:57.780'
  start: '01:42:52.500'
  text: We have a lot of here in Austin, a lot of people have dogs. Sure. Um, there
    seems to be a huge
- end: '01:43:06.100'
  start: '01:42:57.780'
  text: opportunity to also have robots that decrease the, uh, the, the amount of
    loneliness in the world
- end: '01:43:11.220'
  start: '01:43:06.100'
  text: or help us humans connect with each with each other. So in the way that dogs
    can,
- end: '01:43:16.980'
  start: '01:43:12.020'
  text: um, do you think about that? We test about it all, or is it really focused
    on the problem of,
- end: '01:43:20.820'
  start: '01:43:17.620'
  text: of performing specific tasks, not connecting with humans?
- end: '01:43:27.140'
  start: '01:43:21.780'
  text: Um, I mean, to be, to be honest, I have not actually thought about it from
    the companionship
- end: '01:43:31.940'
  start: '01:43:27.140'
  text: standpoint, but I think it actually would end up being, it could be actually
    a very good companion.
- end: '01:43:43.940'
  start: '01:43:32.820'
  text: Um, and it could develop like a personality, uh, over time that is, that is
    like unique.
- end: '01:43:48.260'
  start: '01:43:43.940'
  text: Like, uh, you know, it's not like they're just all the robots are the same
    and that personality
- end: '01:43:56.340'
  start: '01:43:48.260'
  text: could evolve to be, you know, uh, match, match the, the, the owner or the,
    you know,
- end: '01:44:03.620'
  start: '01:43:57.140'
  text: yes, the owner. Uh, well, uh, whatever you want to call it. Uh, the other
    companion. The other half,
- end: '01:44:09.460'
  start: '01:44:03.620'
  text: right? Uh, in the same way that friends do. See, I think that's a huge opportunity.
    I think.
- end: '01:44:17.380'
  start: '01:44:09.460'
  text: Yeah. No, that's interesting. Like, um, the, because, you know, like there's
    a Japanese phrase,
- end: '01:44:22.900'
  start: '01:44:17.380'
  text: I like the, uh, why we savvy, you know, uh, the subtle imperfections are what
    makes something
- end: '01:44:28.820'
  start: '01:44:22.900'
  text: special. And the subtle imperfections of the personality of the robot mapped
    to the subtle
- end: '01:44:36.420'
  start: '01:44:28.820'
  text: imperfections of the robot's human friend. I don't know. Owners sounds like
    maybe the wrong word,
- end: '01:44:41.780'
  start: '01:44:36.420'
  text: but, um, could actually make an incredible buddy, basically.
- end: '01:44:46.340'
  start: '01:44:42.500'
  text: In that way, the imperfections like R2D2 or like a C3PO sort of thing, you
    know.
- end: '01:44:53.860'
  start: '01:44:46.340'
  text: So from a machine learning perspective, I think the flaws being a feature
    is really nice.
- end: '01:44:58.820'
  start: '01:44:53.860'
  text: You could be quite terrible at being a robot for quite a while in the general
    home environment
- end: '01:45:04.580'
  start: '01:44:58.820'
  text: or all in general world. And that's kind of adorable. And that's like, those
    are your flaws
- end: '01:45:09.300'
  start: '01:45:04.580'
  text: and you fall in love with those flaws. So it's, it's a, it's very different
    than autonomous
- end: '01:45:14.740'
  start: '01:45:09.300'
  text: driving where it's a very high stakes environment. You cannot mess up. And
    so it's, yeah, it's more
- end: '01:45:21.300'
  start: '01:45:14.820'
  text: fun to be a robot in the home. Yeah. In fact, if you think of like a C3PO
    and R2D2,
- end: '01:45:25.140'
  start: '01:45:21.300'
  text: yeah, like they actually had a lot of like flaws and imperfections and silly
    things.
- end: '01:45:29.300'
  start: '01:45:25.140'
  text: And they would argue with each other. And, um,
- end: '01:45:32.980'
  start: '01:45:29.300'
  text: were they actually good at doing anything? I'm not exactly sure.
- end: '01:45:40.660'
  start: '01:45:33.780'
  text: I definitely added a lot to the story. But, but, but there's, there's sort
    of quirky elements and
- end: '01:45:47.060'
  start: '01:45:41.620'
  text: you know, that they would like make mistakes and do things. Like it was like,
    it made them
- end: '01:45:56.500'
  start: '01:45:48.420'
  text: relatable. I don't know. Enduring. So, so yeah, I think that that could be
    something that probably
- end: '01:46:06.420'
  start: '01:45:56.500'
  text: would happen. But our initial focus is just to make it useful. So, so I'm
    confident we'll get it
- end: '01:46:11.540'
  start: '01:46:06.420'
  text: done. I'm not sure what the exact timeframe is, but like we'll probably have,
    I don't know, a decent
- end: '01:46:17.140'
  start: '01:46:11.540'
  text: prototype towards the end of next year or something like that. And it's cool
    that it's connected to
- end: '01:46:24.180'
  start: '01:46:17.140'
  text: Tesla, the car. So, so yeah, it's, it's, it's using a lot of, you know, it
    would use the autopilot
- end: '01:46:30.420'
  start: '01:46:24.180'
  text: inference computer and a lot of the training that we've done for the four
    cars in terms of recognizing
- end: '01:46:38.740'
  start: '01:46:31.220'
  text: real world things could be applied directly to the, to the robot. So it, but,
    but there's,
- end: '01:46:41.460'
  start: '01:46:38.740'
  text: there's a lot of custom actuators and sensors that need to be developed.
- end: '01:46:46.100'
  start: '01:46:42.420'
  text: And an extra module on top of the vector space for love.
- end: '01:46:47.940'
  start: '01:46:47.220'
  text: Yeah. That's me saying.
- end: '01:46:57.460'
  start: '01:46:50.500'
  text: Okay. We can add that to the car too. That's true. That could be useful in
    all environments. Like
- end: '01:47:00.500'
  start: '01:46:57.460'
  text: you said, a lot of people argue in the car. So maybe we can help them out.
- end: '01:47:05.940'
  start: '01:47:01.940'
  text: You're a student of history, fan of Dan Carlin's hardcore history podcast.
- end: '01:47:07.860'
  start: '01:47:05.940'
  text: Yeah, that's great. Greatest podcast ever.
- end: '01:47:09.940'
  start: '01:47:08.420'
  text: Yeah, I think it is actually.
- end: '01:47:16.340'
  start: '01:47:11.940'
  text: It almost doesn't really count as a podcast. It's more like a audiobook.
- end: '01:47:19.940'
  start: '01:47:16.340'
  text: Yeah. So you were on the podcast with Dan, just had a chat with him about
    it.
- end: '01:47:23.460'
  start: '01:47:20.980'
  text: He said you guys want military and all that kind of stuff.
- end: '01:47:33.860'
  start: '01:47:23.460'
  text: Yeah, it was basically, it should be titled engineer wars. Essentially, like,
    when there's
- end: '01:47:40.660'
  start: '01:47:33.860'
  text: a rapid change in the rate of technology, then engineering plays a pivotal
    role in victory
- end: '01:47:46.340'
  start: '01:47:40.660'
  text: and battle. How far back in history did you go? Did you go world war two?
- end: '01:47:52.260'
  start: '01:47:47.060'
  text: It was mostly, well, it was supposed to be a deep dive on fighters and bomber
- end: '01:47:57.220'
  start: '01:47:53.380'
  text: technology in world war two, but that ended up being more wide-ranging than
    that.
- end: '01:48:03.700'
  start: '01:47:58.420'
  text: Because I just went down the total rathole of studying all of the fighters
    and bombers of
- end: '01:48:10.820'
  start: '01:48:03.700'
  text: world war two and the constant rock-paper-scissors game that one country would
    make this plane,
- end: '01:48:13.700'
  start: '01:48:10.820'
  text: then it'd make a plane to beat that, and that's what I'm trying to make a
    plane to beat that,
- end: '01:48:17.460'
  start: '01:48:14.180'
  text: and really what matters is the pace of innovation
- end: '01:48:27.540'
  start: '01:48:18.420'
  text: and also access to high-quality fuel and raw materials. Germany had amazing
    designs,
- end: '01:48:30.740'
  start: '01:48:27.540'
  text: but they couldn't make them because they couldn't get the raw materials,
- end: '01:48:38.660'
  start: '01:48:31.460'
  text: and they had a real problem with the oil and fuel, basically. The fuel quality
    was extremely
- end: '01:48:45.700'
  start: '01:48:39.220'
  text: variable. So the design wasn't the bottleneck? Yeah, the US had kick-ass fuel
    that was very
- end: '01:48:49.460'
  start: '01:48:46.260'
  text: consistent. The problem is if you make a very high-performance aircraft engine,
- end: '01:48:58.260'
  start: '01:48:50.340'
  text: in order to make high-performance, you have to, the fuel, the aviation gas,
- end: '01:49:08.260'
  start: '01:48:59.220'
  text: has to be a consistent mixture, and it has to have a high octane. High octane
    is the most
- end: '01:49:13.060'
  start: '01:49:08.260'
  text: important thing, but it also can't have impurities and stuff because you'll
    foul up the engine,
- end: '01:49:18.020'
  start: '01:49:13.940'
  text: and Germany just never had good access to oil. They tried to get it by invading
    the Caucasus,
- end: '01:49:22.740'
  start: '01:49:18.900'
  text: but that didn't work too well. It never works well.
- end: '01:49:23.940'
  start: '01:49:22.740'
  text: You can work out for them.
- end: '01:49:35.700'
  start: '01:49:27.540'
  text: So Germany was always struggling with basically shitty oil, and they couldn't
    count on high-quality
- end: '01:49:39.700'
  start: '01:49:35.700'
  text: fuel for their aircraft, so then they had to have all these additives and
    stuff.
- end: '01:49:47.060'
  start: '01:49:43.460'
  text: Whereas the US had awesome fuel, and that provided that to Britain as well.
- end: '01:49:54.420'
  start: '01:49:48.180'
  text: So that allowed the British and the Americans to design aircraft engines that
    were super high
- end: '01:49:59.780'
  start: '01:49:54.420'
  text: performance better than anything else in the world. Germany could design the
    engines,
- end: '01:50:05.300'
  start: '01:49:59.780'
  text: they just didn't have the fuel, and then also the quality of the aluminum
- end: '01:50:07.060'
  start: '01:50:05.300'
  text: allies that they were getting was also not that great.
- end: '01:50:11.460'
  start: '01:50:09.220'
  text: Is this like you talked about all this with Dan?
- end: '01:50:11.940'
  start: '01:50:11.460'
  text: Yeah.
- end: '01:50:18.500'
  start: '01:50:11.940'
  text: Awesome. Broadly looking at history, when you look at Jenkins Kahn, when you
    look at Stalin,
- end: '01:50:24.100'
  start: '01:50:18.500'
  text: Hitler, the darkest moments of human history, what do you take away from those
    moments? Does it
- end: '01:50:29.300'
  start: '01:50:24.100'
  text: help you gain insight about human nature, about human behavior today, whether
    it's the wars,
- end: '01:50:33.300'
  start: '01:50:29.300'
  text: or the individuals, or just the behavior of people, any aspects of history?
- end: '01:50:42.660'
  start: '01:50:40.980'
  text: Yeah, I find history fascinating.
- end: '01:50:52.500'
  start: '01:50:49.460'
  text: I mean, there's a lot of incredible things that have been done, good and bad,
- end: '01:51:04.260'
  start: '01:50:52.820'
  text: that they just help you understand the nature of civilization and individuals.
- end: '01:51:10.260'
  start: '01:51:06.020'
  text: Does it make you sad that humans do these kinds of things to each other? You
    look at the 20th
- end: '01:51:19.060'
  start: '01:51:10.260'
  text: century, World War II, the cruelty, the abuse of power, talk about communism,
    Marxism, and Stalin.
- end: '01:51:24.260'
  start: '01:51:19.780'
  text: I mean, some of these things do, I mean, if you, like there's a lot of human
    history,
- end: '01:51:29.700'
  start: '01:51:25.220'
  text: most of it is actually people just getting on with their lives. And it's not
    like
- end: '01:51:37.380'
  start: '01:51:30.580'
  text: human history is just a nonstop war and disaster. Those are actually just,
- end: '01:51:42.900'
  start: '01:51:37.380'
  text: those are intermittent and rare. And if they weren't, then humans would soon
    cease to exist.
- end: '01:51:50.980'
  start: '01:51:43.860'
  text: But it's just that wars tend to be written about a lot. And whereas, like,
- end: '01:51:57.140'
  start: '01:51:53.380'
  text: something being like, well, a normal year where nothing major happened was,
- end: '01:52:02.340'
  start: '01:51:57.140'
  text: doesn't get written about much. But that's, you know, most people just like
    farming and kind of
- end: '01:52:10.020'
  start: '01:52:02.340'
  text: like living their life, you know, being a villager somewhere. And every now
    and again,
- end: '01:52:21.540'
  start: '01:52:10.020'
  text: there's a war and so. And I would say like, there aren't very many books that
    I,
- end: '01:52:28.500'
  start: '01:52:21.540'
  text: where I just had to start reading because it was just too dark. But the book
    about Stalin,
- end: '01:52:36.100'
  start: '01:52:28.500'
  text: the Court of the Red Tsar, I had to start reading. It was just too dark, rough.
- end: '01:52:46.500'
  start: '01:52:36.100'
  text: Yeah. The thirties, there's a lot of lessons there to me, in particular that
    it feels like
- end: '01:52:51.220'
  start: '01:52:47.540'
  text: humans, like all of us have that as the old Solzhenitsyn line,
- end: '01:52:57.300'
  start: '01:52:53.220'
  text: that the line between good and evil runs to the heart of every man, that all
    of us are capable
- end: '01:53:01.300'
  start: '01:52:57.300'
  text: of evil, all of us are capable of good. It's almost like this kind of responsibility
    that
- end: '01:53:09.700'
  start: '01:53:02.100'
  text: all of us have to tend towards the good. And so like, to me, looking at history
    is almost
- end: '01:53:17.140'
  start: '01:53:09.700'
  text: like an example of, look, you have some charismatic leader that convinces
    you of things is too easy
- end: '01:53:23.860'
  start: '01:53:18.260'
  text: based on that story to do evil onto each other, onto your family, onto others.
    And so it's like,
- end: '01:53:30.260'
  start: '01:53:23.860'
  text: our responsibility to do good. It's not like now is somehow different from
    history. That can happen
- end: '01:53:35.860'
  start: '01:53:30.260'
  text: again. All of it can happen again. And yes, most of the time, you're right.
    I mean, the optimistic
- end: '01:53:42.660'
  start: '01:53:35.860'
  text: view here is mostly people are just living life. And as you've often memed
    about, the quality of
- end: '01:53:47.620'
  start: '01:53:42.660'
  text: life was way worse back in the day and keeps improving over time through innovation
    through
- end: '01:53:54.260'
  start: '01:53:47.620'
  text: technology. But still, it's somehow notable that these blimps of atrocities
    happen.
- end: '01:54:02.420'
  start: '01:53:54.260'
  text: Sure. Yeah, I mean, life was really tough for most of history. I mean,
- end: '01:54:09.060'
  start: '01:54:02.420'
  text: probably for most of human history, a good year would be one where not that
    many people
- end: '01:54:14.820'
  start: '01:54:09.060'
  text: in your village died of the plague, starvation, freezing to death, or being
    killed by a neighboring
- end: '01:54:19.220'
  start: '01:54:14.820'
  text: village. It's like, well, it wasn't that bad, you know, it was only like,
    you know, we lost
- end: '01:54:26.420'
  start: '01:54:19.220'
  text: 5% this year. That was a good year. That would be part of the course. Just
    not starving to death
- end: '01:54:32.100'
  start: '01:54:26.420'
  text: would have been like the primary goal of most people throughout history, is
    making sure we'll
- end: '01:54:35.940'
  start: '01:54:32.100'
  text: have no foods last through the winter and not get in a freeze or whatever.
    So
- end: '01:54:43.140'
  start: '01:54:39.860'
  text: now food is plentiful. I have an obesity problem.
- end: '01:54:51.140'
  start: '01:54:43.700'
  text: Well, yeah, the lesson there is to be grateful for the way things are now
    for some of us.
- end: '01:54:58.020'
  start: '01:54:52.820'
  text: We've spoken about this offline. I'd love to get your thought about it here.
- end: '01:55:05.140'
  start: '01:54:59.780'
  text: If I sat down for a long-form in-person conversation with the President of
    Russia,
- end: '01:55:11.380'
  start: '01:55:05.140'
  text: Vladimir Putin, would you potentially want to call in for a few minutes to
    join in on a
- end: '01:55:16.980'
  start: '01:55:11.380'
  text: conversation with him, moderated and translated by me? Sure. Yeah, sure. I'd
    be happy to do that.
- end: '01:55:23.940'
  start: '01:55:19.460'
  text: You've shown interest in the Russian language. Is this grounded in your interest
    in history of
- end: '01:55:28.500'
  start: '01:55:23.940'
  text: linguistics, culture, general curiosity? I think it sounds cool.
- end: '01:55:36.820'
  start: '01:55:29.620'
  text: Sounds cool, not looks cool. Well, it's, you know, it's a, it's a, it takes
    a moment to read
- end: '01:55:44.900'
  start: '01:55:36.820'
  text: Cyrillic. Once you know what the Cyrillic characters stand for, actually,
    then reading
- end: '01:55:49.220'
  start: '01:55:44.900'
  text: Russian becomes a lot easier because there are a lot of words that are actually
    the same,
- end: '01:55:58.580'
  start: '01:55:49.220'
  text: like bank is bank. So find the words that are exactly the same and now you
    start to understand
- end: '01:56:05.220'
  start: '01:55:58.580'
  text: Cyrillic. Yeah. If you can, if you can sound it out, then it's much, there's
    at least some
- end: '01:56:12.180'
  start: '01:56:05.220'
  text: commonality of words. What about the culture? You love great engineering,
    physics. There's
- end: '01:56:16.980'
  start: '01:56:12.180'
  text: a tradition of the sciences there. Sure. You look at the 20th century from
    rocketry. So,
- end: '01:56:21.540'
  start: '01:56:17.860'
  text: you know, some of the greatest rockets of the space exploration has been done
- end: '01:56:25.620'
  start: '01:56:21.540'
  text: in the Soviet and the former Soviet Union. Yeah. So do you draw inspiration
    from
- end: '01:56:31.780'
  start: '01:56:26.340'
  text: that history? Just how this culture that in many ways, I mean, one of the
    sad things is because
- end: '01:56:37.460'
  start: '01:56:31.860'
  text: of the language, a lot of it is lost to history because it's not translated
    to all those kinds of,
- end: '01:56:43.060'
  start: '01:56:37.460'
  text: because it, it is in some ways an isolated culture. It flourishes within its,
    within its borders.
- end: '01:56:50.500'
  start: '01:56:44.420'
  text: Yeah. So do you draw inspiration from those folks from, from the history of
    science engineering
- end: '01:57:01.140'
  start: '01:56:50.500'
  text: there? I mean, the Soviet Union, Russia and Ukraine as well, and have a really
    strong history in
- end: '01:57:05.300'
  start: '01:57:01.220'
  text: spaceflight. Like some of the most advanced and impressive things in history
    were done,
- end: '01:57:11.380'
  start: '01:57:07.700'
  text: you know, by the Soviet Union. So,
- end: '01:57:19.460'
  start: '01:57:14.820'
  text: one can, cannot help but admire the impressive rocket technology that was
    developed.
- end: '01:57:28.260'
  start: '01:57:22.100'
  text: You know, after the sort of full Soviet Union, there's, there's, there's much
    less that, that
- end: '01:57:38.020'
  start: '01:57:28.260'
  text: then happened. But still things are happening, but it's not, not quite at
    the frenetic pace that
- end: '01:57:45.540'
  start: '01:57:38.020'
  text: was happening before the Soviet Union kind of dissolved into separate republics.
- end: '01:57:54.980'
  start: '01:57:46.900'
  text: Yeah. I mean, I, you know, there's Roscoe's most the Russian agency. I look
    forward to a time when
- end: '01:57:59.860'
  start: '01:57:54.980'
  text: those countries with China are working together, the United States are all
    working together.
- end: '01:58:02.980'
  start: '01:57:59.860'
  text: Maybe a little bit of friendly competition, but. I think friendly competition
    is good.
- end: '01:58:08.260'
  start: '01:58:04.740'
  text: You know, government's so slow and the only thing slower than one government
    is a collection of
- end: '01:58:15.780'
  start: '01:58:08.260'
  text: governments. So, the Olympics would be boring if everyone just crossed the
    finishing line at the
- end: '01:58:22.260'
  start: '01:58:15.780'
  text: same time. Yeah. Nobody would watch. Yeah. And, and people wouldn't try hard
    to run fast and stuff.
- end: '01:58:24.500'
  start: '01:58:22.340'
  text: So, I think friendly competition is a good thing.
- end: '01:58:30.740'
  start: '01:58:26.500'
  text: This is also a good place to give a shout out to a video titled the entire
    Soviet rocket engine
- end: '01:58:36.260'
  start: '01:58:30.740'
  text: family tree by Tim Dodd, aka Everyday Astronaut. It's like an hour and a half.
    It gives a full
- end: '01:58:41.380'
  start: '01:58:36.260'
  text: history of Soviet rockets and people should definitely go check out and support
    Tim in general.
- end: '01:58:46.500'
  start: '01:58:41.380'
  text: That guy's super excited about the future, super excited about a space fight.
    Every time I see
- end: '01:58:50.500'
  start: '01:58:46.500'
  text: anything by him, I just have a stupid smile on my face because he's so excited
    about stuff.
- end: '01:58:55.300'
  start: '01:58:51.140'
  text: Yeah. Tim Dodd is really, really great. If you're interested in anything to
    do with space,
- end: '01:59:02.580'
  start: '01:58:56.180'
  text: he's, in terms of explaining rocket technology to your average person, he's
    awesome. The best,
- end: '01:59:10.660'
  start: '01:59:02.580'
  text: I'd say. And I should say like the part of the reason like I switched us from,
- end: '01:59:13.860'
  start: '01:59:11.860'
  text: like Raptor at one point was going to be a hydrogen engine.
- end: '01:59:19.620'
  start: '01:59:15.700'
  text: But hydrogen has a lot of challenges. It's very low density. It's a deep cryogen,
- end: '01:59:24.580'
  start: '01:59:19.700'
  text: so it's only liquid at a very close to absolute zero. It requires a lot of
    installation.
- end: '01:59:34.340'
  start: '01:59:26.580'
  text: So there's a lot of challenges there. And I was actually reading a bit about
    Russian
- end: '01:59:41.780'
  start: '01:59:34.340'
  text: rocket engine development. And at least the impression I had was that Soviet
    Union, Russia,
- end: '01:59:49.540'
  start: '01:59:41.780'
  text: and Ukraine primarily were actually in the process of switching to methalox.
- end: '01:59:57.860'
  start: '01:59:50.740'
  text: And there was some interesting test and data for ISP, like they were able
    to get like up to like
- end: '02:00:04.580'
  start: '01:59:57.860'
  text: a 380 second ISP with a methalox engine. And I was like, well, okay, that's
    actually really
- end: '02:00:15.620'
  start: '02:00:04.580'
  text: impressive. So I think you could actually get a much lower cost, like optimizing
    cost per ton to
- end: '02:00:26.340'
  start: '02:00:15.620'
  text: orbit cost per ton to Mars. I think methane oxygen is the way to go. And I
    was partly inspired by
- end: '02:00:31.220'
  start: '02:00:26.340'
  text: the Russian work on the test stands with methalox engines.
- end: '02:00:37.620'
  start: '02:00:31.460'
  text: And now for something completely different. Do you mind doing a bit of a meme
    review in the spirit
- end: '02:00:43.380'
  start: '02:00:37.620'
  text: of the great, the powerful PewDiePie? Let's say one to 11, just go over a
    few documents, print it out.
- end: '02:00:51.060'
  start: '02:00:43.380'
  text: We can try. Let's try this. I present to you document number Uno.
- end: '02:00:57.860'
  start: '02:00:51.460'
  text: I don't know. Okay.
- end: '02:01:01.940'
  start: '02:00:58.660'
  text: Vlad the Impaler discovers marshmallows.
- end: '02:01:04.500'
  start: '02:01:03.860'
  text: Yeah, that's not bad.
- end: '02:01:13.460'
  start: '02:01:07.060'
  text: So you get it because he's like, he's like, I don't know, three, whatever.
- end: '02:01:15.380'
  start: '02:01:14.180'
  text: Oh, that's not very good.
- end: '02:01:23.140'
  start: '02:01:19.060'
  text: This is grounded in some engineering, some history.
- end: '02:01:29.940'
  start: '02:01:28.580'
  text: Yeah, give us an eight out of 10.
- end: '02:01:32.500'
  start: '02:01:31.060'
  text: What do you think about nuclear power?
- end: '02:01:40.820'
  start: '02:01:33.140'
  text: I'm in favor of nuclear power. I think it's in a place that is not subject
    to extreme natural
- end: '02:01:46.180'
  start: '02:01:40.820'
  text: disasters. I think it's a nuclear power is a great way to generate electricity.
- end: '02:01:50.420'
  start: '02:01:47.860'
  text: I don't think we should be shutting down nuclear power stations.
- end: '02:01:52.900'
  start: '02:01:51.700'
  text: Yeah, but what about Chernobyl?
- end: '02:02:02.260'
  start: '02:01:54.100'
  text: Exactly. So I think people, there's like a lot of fear of radiation and stuff.
- end: '02:02:10.020'
  start: '02:02:02.980'
  text: It's probably like a lot of people just don't understand, they didn't study
- end: '02:02:15.300'
  start: '02:02:11.140'
  text: engineering or physics. It's just the word radiation just sounds scary.
- end: '02:02:18.820'
  start: '02:02:16.980'
  text: They can't calibrate what radiation means.
- end: '02:02:24.740'
  start: '02:02:20.820'
  text: But radiation is much less dangerous than you think.
- end: '02:02:39.460'
  start: '02:02:25.620'
  text: So, for example, Fukushima, when the Fukushima problem happened due to the
    tsunami,
- end: '02:02:44.820'
  start: '02:02:41.300'
  text: I got people in California asking me if they should worry about radiation
- end: '02:02:52.100'
  start: '02:02:45.540'
  text: from Fukushima. I'm like, definitely not. Not even slightly, not at all. That
    is crazy.
- end: '02:03:06.180'
  start: '02:02:52.900'
  text: And just to show, this is how the danger is so much overplayed compared to
    what it really is,
- end: '02:03:14.820'
  start: '02:03:06.180'
  text: that I actually flew to Fukushima and I donated a solar power system for water
    treatment plant.
- end: '02:03:25.700'
  start: '02:03:15.140'
  text: And I made a point of eating locally grown vegetables on TV in Fukushima.
- end: '02:03:30.660'
  start: '02:03:28.580'
  text: Like, I'm still alive. Okay.
- end: '02:03:35.940'
  start: '02:03:31.300'
  text: So it's not even at the risk of these events as low, but the impact of them
    is-
- end: '02:03:38.580'
  start: '02:03:35.940'
  text: Impact is greatly exaggerated. It's just-
- end: '02:03:39.300'
  start: '02:03:38.580'
  text: It's human nature.
- end: '02:03:42.820'
  start: '02:03:39.940'
  text: It's people who don't know what radiation is. I've had people ask me like,
- end: '02:03:46.740'
  start: '02:03:42.820'
  text: what about radiation from cell phones causing brain cancer? I'm like,
- end: '02:03:51.380'
  start: '02:03:46.740'
  text: when you say radiation, do you mean photons or particles that I don't know
    what you mean
- end: '02:03:59.220'
  start: '02:03:51.380'
  text: photons, particles? So do you mean, let's say photons, what frequency, wavelength?
- end: '02:04:03.700'
  start: '02:03:59.220'
  text: And they're like, I have no idea. Do you know that everything's radiating
    all the time?
- end: '02:04:07.460'
  start: '02:04:04.660'
  text: Like, what do you mean? Like, yeah, everything's radiating all the time.
- end: '02:04:12.340'
  start: '02:04:08.580'
  text: Photons are being emitted by all objects all the time, basically.
- end: '02:04:20.820'
  start: '02:04:12.340'
  text: So, and if you want to know what it means to stand in front of nuclear fire,
    go outside.
- end: '02:04:27.780'
  start: '02:04:21.620'
  text: The sun is a gigantic, you know, thermonuclear reactor that you're staring
    right at it.
- end: '02:04:30.500'
  start: '02:04:28.660'
  text: Are you still alive? Yes. Okay. Amazing.
- end: '02:04:38.580'
  start: '02:04:32.420'
  text: Yeah. I guess radiation is one of the words that could be used as a tool to
    fear monger
- end: '02:04:40.260'
  start: '02:04:38.580'
  text: by certain people. That's it.
- end: '02:04:44.180'
  start: '02:04:40.260'
  text: I think people just don't understand. I mean, that's the way to fight that
    fear,
- end: '02:04:48.100'
  start: '02:04:44.180'
  text: I suppose, is to understand, is to learn. Yeah, just say like, okay, how many
    people
- end: '02:04:51.700'
  start: '02:04:48.100'
  text: have actually died from nuclear accidents? It's like practically nothing.
    And
- end: '02:04:58.340'
  start: '02:04:52.900'
  text: say how many people have died from, you know, coal plants, and it's a very
    big number.
- end: '02:05:05.140'
  start: '02:04:59.300'
  text: So, like, obviously, we should not be starting up coal plants and shutting
    down nuclear plants.
- end: '02:05:10.820'
  start: '02:05:05.140'
  text: Just doesn't make any sense at all. Coal plants like, I don't know, 100 to
    1,000 times worse
- end: '02:05:17.460'
  start: '02:05:11.860'
  text: for health than nuclear power plants. You want to go to the next one? This
    is really bad.
- end: '02:05:27.300'
  start: '02:05:20.100'
  text: So, that 90, 180, and 360 degrees, everybody loves the math, nobody gives
    a shit about 270.
- end: '02:05:31.540'
  start: '02:05:27.860'
  text: It's not super funny. I don't like 203. Yeah.
- end: '02:05:37.700'
  start: '02:05:32.420'
  text: This is not a, you know, LOL situation. Yeah.
- end: '02:05:46.740'
  start: '02:05:43.220'
  text: That's pretty good. The United States oscillating between establishing and
- end: '02:05:53.540'
  start: '02:05:46.740'
  text: destroying dictatorships. It's like, is that a metronome? Yeah, it's a 7 out
    of 10. It's kind of
- end: '02:06:01.460'
  start: '02:05:53.540'
  text: true. Oh, yeah. This is kind of personal for me. Next one. Oh, man, this is
    Leica? Yeah. Well, no,
- end: '02:06:08.420'
  start: '02:06:01.460'
  text: this is... Or it's like referring to Leica or something? As Leica is like
    a husband. Hello,
- end: '02:06:14.100'
  start: '02:06:08.420'
  text: yes, this is dog. Your wife was launched into space. And then the last one
    is him with his eyes
- end: '02:06:20.420'
  start: '02:06:14.100'
  text: closed in a bottle of vodka. Yeah, Leica didn't come back. No. They don't
    tell you the full story
- end: '02:06:26.740'
  start: '02:06:20.420'
  text: of, you know, what the impact they had on the loved ones. True. That one gets
    an 11 for me.
- end: '02:06:35.460'
  start: '02:06:26.740'
  text: Sure, let's go. Yeah, this keeps going on the Russian theme. First man in
    space, nobody cares,
- end: '02:06:38.580'
  start: '02:06:35.460'
  text: first man on the moon. Well, I think people do care. No, I know, but...
- end: '02:06:46.740'
  start: '02:06:41.060'
  text: Yuri Gagarin's names will be forever in history, I think. There is something
    special about
- end: '02:06:54.980'
  start: '02:06:47.220'
  text: placing like stepping foot onto another totally foreign land. It's not the
    journey like people
- end: '02:07:00.020'
  start: '02:06:54.980'
  text: that explore the oceans. It's not as important to explore the oceans as to
    land on a whole
- end: '02:07:07.940'
  start: '02:07:00.020'
  text: new continent. Yeah. Well, this is about you. Oh, yeah, I'd love to get your
    comment on this.
- end: '02:07:14.820'
  start: '02:07:07.940'
  text: You know, Musk, after sending $6.6 billion to the UN to end world hunger,
    you have three hours.
- end: '02:07:20.340'
  start: '02:07:17.700'
  text: Yeah, well, I mean, obviously, $6 billion is not going to end world hunger.
- end: '02:07:27.620'
  start: '02:07:24.020'
  text: So, I mean, the reality is at this point, the world is producing
- end: '02:07:33.620'
  start: '02:07:29.300'
  text: far more food than it can really consume it. Like, we don't have a caloric
- end: '02:07:39.060'
  start: '02:07:34.820'
  text: constraint to this point. So, where there is hunger, it is almost always due
    to
- end: '02:07:46.980'
  start: '02:07:39.940'
  text: like civil war or strife or some like... It's not a thing that is
- end: '02:07:55.460'
  start: '02:07:48.980'
  text: extremely rare for it to be just a matter of lack of money. It's like, you
    know, it's like some
- end: '02:07:59.540'
  start: '02:07:56.020'
  text: the civil war in some country and like one part of the country is literally
    trying to
- end: '02:08:05.060'
  start: '02:07:59.540'
  text: starve the other part of the country. So, it's much more complex than something
    that money
- end: '02:08:11.220'
  start: '02:08:05.060'
  text: could solve. It's geopolitics. It's a lot of things. It's human nature. It's
    governments.
- end: '02:08:17.380'
  start: '02:08:11.220'
  text: It's money, monetary systems, all that kind of stuff. Yeah, food is extremely
    cheap these days.
- end: '02:08:26.820'
  start: '02:08:20.740'
  text: I mean, the US at this point, you know, among low income families, obesity
    is the
- end: '02:08:33.940'
  start: '02:08:27.220'
  text: other problem. It's not... Like, obviously, it's not hunger. It's like too
    many calories.
- end: '02:08:42.420'
  start: '02:08:34.420'
  text: So, it's not that nobody's hungry anywhere. It's just this is not a simple
    matter of
- end: '02:08:47.380'
  start: '02:08:42.420'
  text: adding money and solving it. What do you think that one gets?
- end: '02:08:50.740'
  start: '02:08:48.340'
  text: It's getting... Two.
- end: '02:08:58.340'
  start: '02:08:53.780'
  text: Just going after empires. World, where did you get those artifacts? The British
    Museum
- end: '02:09:02.100'
  start: '02:08:59.060'
  text: has a shout out to Monty Python. We found them.
- end: '02:09:05.940'
  start: '02:09:02.820'
  text: Yeah, the British Museum. It's pretty great. I mean,
- end: '02:09:10.340'
  start: '02:09:06.900'
  text: immediately Britain did take these historical artifacts from all around the
    world and put
- end: '02:09:17.700'
  start: '02:09:10.340'
  text: them in London. But, you know, it's not like people can't go see them. So,
    it is a convenient
- end: '02:09:24.100'
  start: '02:09:17.700'
  text: place to see these ancient artifacts is London for, you know, for a large
    segment of the world.
- end: '02:09:29.460'
  start: '02:09:24.820'
  text: So, I think, you know, on balance, the British Museum is a net good, although
    I'm sure
- end: '02:09:34.740'
  start: '02:09:29.460'
  text: that a lot of countries argue about that. Yeah. It's like you want to make
    these historical artifacts
- end: '02:09:39.780'
  start: '02:09:34.740'
  text: accessible to as many people as possible. And the British Museum, I think,
    does a good job of that.
- end: '02:09:45.700'
  start: '02:09:41.140'
  text: Even if there's a darker aspect to like the history of empire in general,
    whatever the empire is,
- end: '02:09:53.380'
  start: '02:09:46.420'
  text: however things were done, it is the history that happened. You can't sort
    of erase that history,
- end: '02:09:56.980'
  start: '02:09:53.380'
  text: unfortunately. You could just become better in the future. That's the point.
- end: '02:10:04.020'
  start: '02:09:58.420'
  text: Yeah. I mean, it's like, well, how are we going to pass from all judgment
    on these things? Like,
- end: '02:10:11.220'
  start: '02:10:04.020'
  text: it's like, you know, if one is going to judge, say, the British Empire, you're
    going to judge,
- end: '02:10:15.780'
  start: '02:10:11.220'
  text: you know, what everyone was doing at the time and how were the British relative
    to everyone.
- end: '02:10:21.780'
  start: '02:10:17.940'
  text: And I think the British would actually get like a relatively good grade,
- end: '02:10:27.300'
  start: '02:10:21.780'
  text: relatively good grade, not in absolute terms, but compared to what everyone
    else was doing,
- end: '02:10:33.620'
  start: '02:10:29.700'
  text: they were not the worst. Like I said, you got to look at these things in the
    context of the
- end: '02:10:38.420'
  start: '02:10:33.620'
  text: history at the time and say, what were the alternatives and what are you comparing
    it against?
- end: '02:10:47.460'
  start: '02:10:38.420'
  text: Yes. And I do not think it would be the case that Britain would get a bad
    grade when looking at
- end: '02:10:55.220'
  start: '02:10:47.460'
  text: history at the time. Now, if you judge history from, you know, from what is
    morally acceptable
- end: '02:11:00.100'
  start: '02:10:55.220'
  text: today, you're basically going to give everyone a failing grade. I'm not clear.
    I don't think
- end: '02:11:06.260'
  start: '02:11:00.100'
  text: anyone would get a passing grade in their morality of like, you go back 300
    years ago,
- end: '02:11:09.300'
  start: '02:11:06.260'
  text: like who is getting a passing grade? Basically, no one.
- end: '02:11:15.380'
  start: '02:11:10.500'
  text: And we might not get a passing grade from generations that come after us.
- end: '02:11:18.100'
  start: '02:11:17.060'
  text: What does that one get?
- end: '02:11:22.260'
  start: '02:11:20.100'
  text: Sure, six, seven, seven.
- end: '02:11:23.860'
  start: '02:11:22.260'
  text: For the Monty Python, maybe.
- end: '02:11:25.460'
  start: '02:11:23.860'
  text: I always want Monty Python. They're great.
- end: '02:11:29.300'
  start: '02:11:26.420'
  text: The life of Brian and the Quist of the Holy Grail are incredible.
- end: '02:11:30.100'
  start: '02:11:29.300'
  text: Yeah. Yeah.
- end: '02:11:31.220'
  start: '02:11:30.100'
  text: Damn, those serious eyebrows.
- end: '02:11:37.220'
  start: '02:11:32.420'
  text: Bresna. How important do you think is facial hair to great leadership?
- end: '02:11:42.580'
  start: '02:11:38.180'
  text: Well, you got a new haircut. How does that affect your leadership?
- end: '02:11:46.100'
  start: '02:11:43.780'
  text: I don't know. Hopefully not. It doesn't.
- end: '02:11:47.620'
  start: '02:11:46.100'
  text: Is that the second no one?
- end: '02:11:49.380'
  start: '02:11:48.260'
  text: Yeah, the second is no one.
- end: '02:11:52.740'
  start: '02:11:51.220'
  text: There is no one competing with Bresna.
- end: '02:11:53.540'
  start: '02:11:52.740'
  text: No one, too.
- end: '02:11:54.820'
  start: '02:11:53.540'
  text: Those are like epic eyebrows.
- end: '02:12:00.180'
  start: '02:11:59.780'
  text: That's ridiculous.
- end: '02:12:02.020'
  start: '02:12:00.180'
  text: Give it a six or seven, I don't know.
- end: '02:12:04.740'
  start: '02:12:02.020'
  text: I like this, like Shakespeare analysis of memes.
- end: '02:12:08.100'
  start: '02:12:05.460'
  text: Bresna, he had a flair for drama as well.
- end: '02:12:11.300'
  start: '02:12:09.220'
  text: Like, you know, showmanship.
- end: '02:12:14.020'
  start: '02:12:11.300'
  text: Yeah. Yeah. It must come from the eyebrows.
- end: '02:12:17.940'
  start: '02:12:14.020'
  text: All right. Invention, great engineering.
- end: '02:12:19.540'
  start: '02:12:17.940'
  text: Look what I invented.
- end: '02:12:21.940'
  start: '02:12:19.540'
  text: That's the best thing since ripped up bread.
- end: '02:12:22.500'
  start: '02:12:21.940'
  text: Yeah.
- end: '02:12:25.700'
  start: '02:12:22.500'
  text: Because they invented sliced bread.
- end: '02:12:27.540'
  start: '02:12:25.700'
  text: Am I just explaining memes at this point?
- end: '02:12:31.060'
  start: '02:12:29.700'
  text: This is what my life has become.
- end: '02:12:35.140'
  start: '02:12:33.460'
  text: He's a meme, or do you mean explainer?
- end: '02:12:35.860'
  start: '02:12:35.140'
  text: Yeah, explainer.
- end: '02:12:36.980'
  start: '02:12:35.860'
  text: I'm a meme.
- end: '02:12:43.460'
  start: '02:12:38.260'
  text: You know, like a scribe that like runs around with the kings and just like
    writes down memes.
- end: '02:12:46.020'
  start: '02:12:44.180'
  text: I mean, when was the cheeseburger invention?
- end: '02:12:47.300'
  start: '02:12:46.020'
  text: That's like an epic invention.
- end: '02:12:47.620'
  start: '02:12:47.300'
  text: Yeah.
- end: '02:12:49.380'
  start: '02:12:47.620'
  text: Like, wow.
- end: '02:12:53.140'
  start: '02:12:50.100'
  text: You know, versus just like a burger?
- end: '02:12:53.860'
  start: '02:12:53.140'
  text: Or burger.
- end: '02:12:56.100'
  start: '02:12:53.860'
  text: I guess a burger in general is like, you know.
- end: '02:12:58.660'
  start: '02:12:57.220'
  text: Then there's like, what is a burger?
- end: '02:12:59.700'
  start: '02:12:58.660'
  text: What's the sandwich?
- end: '02:13:02.740'
  start: '02:12:59.700'
  text: And then you start getting the pizza sandwich and what is the original?
- end: '02:13:05.780'
  start: '02:13:03.300'
  text: It gets into an ontology argument.
- end: '02:13:08.980'
  start: '02:13:05.780'
  text: Yeah. But everybody knows like if you order like a burger or cheeseburger
    or whatever and you like,
- end: '02:13:12.580'
  start: '02:13:08.980'
  text: you got like, you know, tomato and some lettuce and onions and whatever and,
    you know,
- end: '02:13:15.140'
  start: '02:13:13.780'
  text: mayo and ketchup and mustard.
- end: '02:13:16.340'
  start: '02:13:15.140'
  text: It's like epic.
- end: '02:13:18.900'
  start: '02:13:16.340'
  text: Yeah. But I'm sure they've had bread and meat separately
- end: '02:13:22.100'
  start: '02:13:18.900'
  text: for a long time and it was kind of a burger on the same plate,
- end: '02:13:24.820'
  start: '02:13:22.100'
  text: but somebody who actually combined them into the same thing.
- end: '02:13:25.940'
  start: '02:13:25.620'
  text: Yeah.
- end: '02:13:28.740'
  start: '02:13:25.940'
  text: The bite it and hold it makes it convenient.
- end: '02:13:30.100'
  start: '02:13:28.740'
  text: It's a materials problem.
- end: '02:13:33.220'
  start: '02:13:30.100'
  text: Like your hands don't get dirty and whatever.
- end: '02:13:33.860'
  start: '02:13:33.220'
  text: Yeah, it's brilliant.
- end: '02:13:35.140'
  start: '02:13:33.860'
  text: That's definitely the way to talk it.
- end: '02:13:37.140'
  start: '02:13:35.140'
  text: And it's between 18 and 19 hundred.
- end: '02:13:38.820'
  start: '02:13:38.260'
  text: Well.
- end: '02:13:40.180'
  start: '02:13:38.820'
  text: That is not what I would have guessed.
- end: '02:13:44.180'
  start: '02:13:40.980'
  text: But everyone knows like you, if you order a cheeseburger, you know what you're
    getting,
- end: '02:13:48.020'
  start: '02:13:44.180'
  text: you know, it's not like some obtuse, like I wonder what I'll get, you know.
- end: '02:13:53.220'
  start: '02:13:49.860'
  text: You know, fries are, I mean, great.
- end: '02:13:55.140'
  start: '02:13:53.220'
  text: I mean, they're the devil, but fries are awesome.
- end: '02:13:59.780'
  start: '02:13:55.940'
  text: And yeah, pizza is incredible.
- end: '02:14:02.660'
  start: '02:14:01.060'
  text: Food innovation doesn't get enough love.
- end: '02:14:03.620'
  start: '02:14:03.380'
  text: Yeah.
- end: '02:14:04.740'
  start: '02:14:03.620'
  text: I guess is what we're getting at.
- end: '02:14:05.940'
  start: '02:14:05.540'
  text: It's great.
- end: '02:14:11.140'
  start: '02:14:08.180'
  text: What about the Matthew McGonaghey Austinite here?
- end: '02:14:15.060'
  start: '02:14:11.860'
  text: President Kennedy, do you know how to put men on the moon yet?
- end: '02:14:15.860'
  start: '02:14:15.060'
  text: NASA, no.
- end: '02:14:18.420'
  start: '02:14:15.860'
  text: President Kennedy, be a lot cooler if you did.
- end: '02:14:21.140'
  start: '02:14:19.860'
  text: Pretty much.
- end: '02:14:21.620'
  start: '02:14:21.140'
  text: Sure.
- end: '02:14:22.740'
  start: '02:14:21.620'
  text: Six, six or seven of those.
- end: '02:14:22.980'
  start: '02:14:22.740'
  text: All right.
- end: '02:14:27.060'
  start: '02:14:26.020'
  text: And this is the last one.
- end: '02:14:29.060'
  start: '02:14:28.580'
  text: That's funny.
- end: '02:14:35.380'
  start: '02:14:30.420'
  text: Someone drew a bunch of dicks all over the walls, Sistine Chapel boys' bathroom.
- end: '02:14:35.620'
  start: '02:14:35.380'
  text: Sure.
- end: '02:14:36.180'
  start: '02:14:35.620'
  text: I'll give it nine.
- end: '02:14:38.020'
  start: '02:14:36.820'
  text: It's super, it's really true.
- end: '02:14:39.460'
  start: '02:14:39.300'
  text: All right.
- end: '02:14:41.620'
  start: '02:14:39.460'
  text: This is our highest ranking meme for today.
- end: '02:14:42.660'
  start: '02:14:42.180'
  text: I mean, it's true.
- end: '02:14:43.620'
  start: '02:14:42.660'
  text: Like, how do they get away with that?
- end: '02:14:45.380'
  start: '02:14:44.500'
  text: Lots of nakedness.
- end: '02:14:48.980'
  start: '02:14:46.340'
  text: Dick pics are, I mean, just something throughout history.
- end: '02:14:52.740'
  start: '02:14:50.420'
  text: As long as people can draw things, there's been a dick pic.
- end: '02:14:54.900'
  start: '02:14:52.740'
  text: It's a staple of human history.
- end: '02:14:58.340'
  start: '02:14:54.900'
  text: It's a staple, consistent throughout human history.
- end: '02:15:00.500'
  start: '02:14:58.340'
  text: You tweeted that you aspire to comedy.
- end: '02:15:05.940'
  start: '02:15:00.500'
  text: Your friends with Joe Rogan, might you do a short stand-up comedy set at some
    point in the future?
- end: '02:15:09.380'
  start: '02:15:06.500'
  text: Maybe open for Joe, something like that.
- end: '02:15:11.140'
  start: '02:15:09.380'
  text: Is that really stand-up?
- end: '02:15:12.500'
  start: '02:15:11.140'
  text: Actual, just full-on stand-up?
- end: '02:15:13.300'
  start: '02:15:12.500'
  text: Full-on stand-up.
- end: '02:15:14.820'
  start: '02:15:13.300'
  text: Is that in there or is that all right?
- end: '02:15:15.700'
  start: '02:15:14.820'
  text: I've never thought about that.
- end: '02:15:22.900'
  start: '02:15:17.380'
  text: It's extremely difficult if, at least that's what Joe says in the comedians
    say.
- end: '02:15:24.980'
  start: '02:15:24.500'
  text: Huh.
- end: '02:15:25.860'
  start: '02:15:24.980'
  text: I wonder if I could.
- end: '02:15:28.500'
  start: '02:15:27.140'
  text: Only one way to find out.
- end: '02:15:34.420'
  start: '02:15:29.380'
  text: You know, I have done stand-up for friends, just impromptu,
- end: '02:15:41.220'
  start: '02:15:35.620'
  text: you know, I'll get on like a roof and they do laugh, but they're our friends
    too.
- end: '02:15:44.980'
  start: '02:15:41.220'
  text: So, I don't know if you've got to call, you know, like a room of strangers.
- end: '02:15:46.820'
  start: '02:15:44.980'
  text: Are they going to actually also find it funny?
- end: '02:15:50.420'
  start: '02:15:46.820'
  text: But I could try, see what happens.
- end: '02:15:53.060'
  start: '02:15:51.220'
  text: I think you'd learn something either way.
- end: '02:15:54.260'
  start: '02:15:53.860'
  text: Yeah.
- end: '02:16:00.420'
  start: '02:15:54.260'
  text: I kind of love both the, when you bomb and when you do great, just watching
    people,
- end: '02:16:01.380'
  start: '02:16:00.420'
  text: how they deal with it.
- end: '02:16:03.060'
  start: '02:16:02.020'
  text: It's so difficult.
- end: '02:16:06.660'
  start: '02:16:03.060'
  text: It's so, you're so fragile up there.
- end: '02:16:07.380'
  start: '02:16:06.660'
  text: It's just you.
- end: '02:16:11.540'
  start: '02:16:08.100'
  text: And you think you're going to be funny and when it completely falls flat,
    it's just,
- end: '02:16:15.060'
  start: '02:16:11.540'
  text: it's beautiful to see people deal with like that.
- end: '02:16:16.820'
  start: '02:16:15.060'
  text: Yeah, I might have enough material to do stand-up.
- end: '02:16:20.980'
  start: '02:16:18.340'
  text: I've never thought about it, but I might have enough material.
- end: '02:16:25.460'
  start: '02:16:23.380'
  text: I don't know, like 15 minutes or something.
- end: '02:16:26.020'
  start: '02:16:25.460'
  text: Oh yeah?
- end: '02:16:26.420'
  start: '02:16:26.020'
  text: Yeah.
- end: '02:16:27.780'
  start: '02:16:26.420'
  text: Do a Netflix special.
- end: '02:16:29.780'
  start: '02:16:28.580'
  text: A Netflix special, sure.
- end: '02:16:33.780'
  start: '02:16:31.860'
  text: What's your favorite Rick and Morty concept?
- end: '02:16:36.100'
  start: '02:16:34.980'
  text: Just to spring that on you.
- end: '02:16:39.700'
  start: '02:16:36.580'
  text: There's a lot of sort of scientific engineering ideas explored there.
- end: '02:16:42.580'
  start: '02:16:39.700'
  text: There's the, there's the Butter Robot.
- end: '02:16:43.140'
  start: '02:16:42.580'
  text: It's great.
- end: '02:16:44.100'
  start: '02:16:43.140'
  text: It's a great show.
- end: '02:16:46.340'
  start: '02:16:45.220'
  text: Yeah, Rick and Morty is awesome.
- end: '02:16:50.340'
  start: '02:16:47.060'
  text: Somebody that's exactly like you from an alternate dimension showed up there,
- end: '02:16:51.140'
  start: '02:16:50.340'
  text: Elon Tusk.
- end: '02:16:52.500'
  start: '02:16:51.940'
  text: Yeah, that's right.
- end: '02:16:53.540'
  start: '02:16:52.500'
  text: That you voiced.
- end: '02:16:54.100'
  start: '02:16:53.540'
  text: Yeah.
- end: '02:16:56.820'
  start: '02:16:54.100'
  text: Rick and Morty certainly explores a lot of interesting concepts.
- end: '02:17:00.100'
  start: '02:16:58.180'
  text: I'm sure like what's the favorite one.
- end: '02:17:00.740'
  start: '02:17:00.100'
  text: I don't know.
- end: '02:17:04.900'
  start: '02:17:00.740'
  text: The Butter Robot certainly is, you know, it's like, it's certainly possible
    to have
- end: '02:17:06.500'
  start: '02:17:04.900'
  text: too much sentence in a device.
- end: '02:17:11.860'
  start: '02:17:07.700'
  text: Like you don't want to have your toast to be like a super genius toaster.
- end: '02:17:15.060'
  start: '02:17:11.860'
  text: It's going to hate life because all it could just make is toast.
- end: '02:17:18.100'
  start: '02:17:15.060'
  text: But if, you know, it's like, you don't want to have like super intelligence
    stuck in a
- end: '02:17:20.260'
  start: '02:17:19.140'
  text: very limited device.
- end: '02:17:24.900'
  start: '02:17:21.060'
  text: Do you think it's too easy from a, if we're talking about from the engineering
    perspective
- end: '02:17:27.540'
  start: '02:17:24.900'
  text: of super intelligence, like with Marvin, the robot?
- end: '02:17:33.380'
  start: '02:17:28.260'
  text: Like is it, it seems like it might be very easy to engineer just a depressed
    robot.
- end: '02:17:37.700'
  start: '02:17:33.940'
  text: Like it, it's not obvious to engineer a robot that's going to
- end: '02:17:40.420'
  start: '02:17:38.420'
  text: find a fulfilling existence.
- end: '02:17:41.700'
  start: '02:17:40.420'
  text: Same as humans, I suppose.
- end: '02:17:45.940'
  start: '02:17:42.660'
  text: But I wonder if that's like the default.
- end: '02:17:50.660'
  start: '02:17:46.580'
  text: If you don't do a good job on building a robot, it's going to be sad a lot.
- end: '02:17:56.260'
  start: '02:17:52.500'
  text: Well, we can reprogram robots easier than we can reprogram humans.
- end: '02:18:04.180'
  start: '02:17:56.820'
  text: So, I guess if you let it evolve without tinkering, then it might get sad.
- end: '02:18:09.940'
  start: '02:18:04.180'
  text: But you can change the optimization function and have it be a cheery robot.
- end: '02:18:16.980'
  start: '02:18:12.820'
  text: You, like I mentioned with, with SpaceX, you give a lot of people hope.
- end: '02:18:19.460'
  start: '02:18:16.980'
  text: And a lot of people look up to you, millions of people look up to you.
- end: '02:18:24.180'
  start: '02:18:20.180'
  text: If we think about young people in high school, maybe in college,
- end: '02:18:31.460'
  start: '02:18:25.140'
  text: what advice would you give to them about, if they want to try to do something
    big in this world,
- end: '02:18:33.380'
  start: '02:18:31.460'
  text: they want to really have a big positive impact.
- end: '02:18:37.300'
  start: '02:18:33.380'
  text: What advice would you give them about their career, maybe about life in general?
- end: '02:18:40.100'
  start: '02:18:39.140'
  text: Try to be useful.
- end: '02:18:45.620'
  start: '02:18:41.780'
  text: You do things that are useful to your fellow human beings to the world.
- end: '02:18:47.460'
  start: '02:18:46.180'
  text: It's very hard to be useful.
- end: '02:18:51.460'
  start: '02:18:50.980'
  text: Very hard.
- end: '02:18:57.700'
  start: '02:18:52.260'
  text: You know, are you contributing more than you consume, you know, like,
- end: '02:19:05.300'
  start: '02:18:59.300'
  text: like, can you try to have a positive net contribution to society?
- end: '02:19:11.860'
  start: '02:19:07.460'
  text: I think that's the thing to aim for, you know, not to try to be sort of a
    leader for,
- end: '02:19:14.420'
  start: '02:19:12.980'
  text: for the sake of being a leader or whatever.
- end: '02:19:21.940'
  start: '02:19:14.580'
  text: A lot of the time, people who, a lot of the time, the people you want as leaders
    are the people
- end: '02:19:34.260'
  start: '02:19:21.940'
  text: who don't want to be leaders. So, if you can live a useful life, that is a
    good life, a life with
- end: '02:19:41.860'
  start: '02:19:35.300'
  text: having lived, you know, and like I said, I would encourage people to
- end: '02:19:49.140'
  start: '02:19:42.740'
  text: use the mental tools of physics and apply them broadly in life. There are
    the best tools.
- end: '02:19:53.140'
  start: '02:19:49.140'
  text: When you think about education and self-education, what do you recommend?
- end: '02:20:02.420'
  start: '02:19:53.780'
  text: So, there's the university, there's self-study, there is a hands-on sort of
    finding a company
- end: '02:20:06.340'
  start: '02:20:02.420'
  text: or a place or a set of people that do the thing you're passionate about and
    joining them as early
- end: '02:20:13.220'
  start: '02:20:06.340'
  text: as possible. There's taking a road trip across Europe for a few years and
    writing some poetry,
- end: '02:20:22.420'
  start: '02:20:13.220'
  text: which trajectory do you suggest? In terms of learning about how you can become
    useful,
- end: '02:20:24.980'
  start: '02:20:22.420'
  text: as you mentioned, how you can have the most positive impact.
- end: '02:20:40.580'
  start: '02:20:24.980'
  text: I encourage people to read a lot of books. Basically, try to ingest as much
    information as you can
- end: '02:20:50.420'
  start: '02:20:43.220'
  text: and try to also just develop a good general knowledge. So, you at least have
    like a rough
- end: '02:20:56.740'
  start: '02:20:50.500'
  text: lay of the land of the knowledge landscape. Like try to learn a little bit
    about a lot of things.
- end: '02:21:00.340'
  start: '02:20:58.180'
  text: Because you might not know what you're really interested in, how would you
    know what you're
- end: '02:21:05.940'
  start: '02:21:00.340'
  text: really interested in if you at least aren't like doing it peripheral exploration
    or broadly of
- end: '02:21:15.300'
  start: '02:21:07.860'
  text: the knowledge landscape. And you talk to people from different walks of life
    and different
- end: '02:21:24.500'
  start: '02:21:15.620'
  text: industries and professions and skills and occupations. Just try to learn as
    much as possible.
- end: '02:21:28.260'
  start: '02:21:27.220'
  text: Man's search for meaning.
- end: '02:21:32.420'
  start: '02:21:30.740'
  text: Isn't the whole thing a search for meaning?
- end: '02:21:38.820'
  start: '02:21:34.660'
  text: Yeah, what's the meaning of life and all? But just generally, like I said,
    I would encourage
- end: '02:21:47.460'
  start: '02:21:38.900'
  text: people to read broadly in many different subject areas. And then try to find
    something where there's
- end: '02:21:53.460'
  start: '02:21:47.460'
  text: an overlap of your talents and what you're interested in. So, people may be
    good at something,
- end: '02:21:57.380'
  start: '02:21:53.460'
  text: but they may have skill at a particular thing, but they don't like doing it.
- end: '02:22:06.660'
  start: '02:21:59.300'
  text: So, you want to try to find this thing where that's a good combination of
    the things that
- end: '02:22:14.980'
  start: '02:22:06.660'
  text: you're inherently good at, but you also like doing. And reading is a super
    fast shortcut
- end: '02:22:21.620'
  start: '02:22:14.980'
  text: to figure out which, where are you? You're both good at it, you like doing
    it, and it will actually
- end: '02:22:28.100'
  start: '02:22:21.620'
  text: have positive impact. Well, you got to learn about things somehow. So, reading
    a broad range,
- end: '02:22:35.460'
  start: '02:22:28.100'
  text: it's just really read it. One important one is that kid I read through the
    encyclopedia.
- end: '02:22:42.820'
  start: '02:22:37.220'
  text: That was pretty helpful. And there are also things that I didn't even know
    existed,
- end: '02:22:47.380'
  start: '02:22:42.820'
  text: or lots, obviously. It's like as broad as it gets. Encyclopheles were digestible,
- end: '02:22:57.060'
  start: '02:22:47.380'
  text: I think, you know, whatever, 40 years ago. So, you know, maybe read through
    the condensed
- end: '02:23:02.420'
  start: '02:22:57.060'
  text: version of the encyclopedia Britannica. I'd recommend that. You can always
    like skip subjects,
- end: '02:23:06.500'
  start: '02:23:02.420'
  text: so you read a few paragraphs, and no, you're not interested, just jump to
    the next one.
- end: '02:23:11.140'
  start: '02:23:07.460'
  text: So, read the encyclopedia or skip through it.
- end: '02:23:20.580'
  start: '02:23:14.900'
  text: And, you know, put a lot of stock and certainly have a lot of respect for
- end: '02:23:28.660'
  start: '02:23:20.580'
  text: someone who puts in an honest day's work to do useful things. And just generally
    to have like
- end: '02:23:36.100'
  start: '02:23:28.660'
  text: not a zero sum mindset, or like have more of a grow the pie mindset, like
    the,
- end: '02:23:43.700'
  start: '02:23:37.940'
  text: if you sort of say like when we see people like perhaps, including some very
    smart people,
- end: '02:23:50.100'
  start: '02:23:45.140'
  text: kind of taking an attitude of like doing things that seem like morally questionable,
- end: '02:23:56.260'
  start: '02:23:50.820'
  text: it's often because they have at a base sort of axiomatic level, a zero sum
    mindset.
- end: '02:24:02.740'
  start: '02:23:56.500'
  text: And they, without realizing it, they don't realize they have a zero sum mindset,
- end: '02:24:07.460'
  start: '02:24:02.740'
  text: or at least they don't realize it consciously. And so, if you have a zero
    sum mindset,
- end: '02:24:14.980'
  start: '02:24:07.460'
  text: then the only way to get ahead is by taking things from others. If the pie
    is fixed,
- end: '02:24:20.660'
  start: '02:24:14.980'
  text: then the only way to have more pie is to take someone else's pie. But this
    is false, like
- end: '02:24:26.980'
  start: '02:24:20.660'
  text: obviously the pie has grown dramatically over time, the economic pie. So,
    in reality, you can have
- end: '02:24:40.260'
  start: '02:24:30.100'
  text: over-useless analogy, you can have a lot of pie. Pie pie is not fixed. So,
    you really want to make
- end: '02:24:46.900'
  start: '02:24:40.260'
  text: sure you're not operating without realizing it from a zero sum mindset, where
    the only way to
- end: '02:24:49.860'
  start: '02:24:46.900'
  text: get ahead is to take things from others, then that's going to result in you
    trying to take
- end: '02:24:56.100'
  start: '02:24:49.860'
  text: things from others, which is not good. It's much better to work on adding
    to the economic pie.
- end: '02:25:09.220'
  start: '02:25:02.020'
  text: Like I said, creating more than you consume, doing more than you, yeah. So,
    that's a big deal.
- end: '02:25:16.500'
  start: '02:25:09.220'
  text: I think there's like a fair number of people in finance that do have a bit
    of a zero sum mindset.
- end: '02:25:21.300'
  start: '02:25:17.140'
  text: I mean, it's all walks of life. I've seen that. One of the reasons
- end: '02:25:29.140'
  start: '02:25:23.060'
  text: Rogan inspires me is he celebrates others a lot. This is not creating a constant
    competition.
- end: '02:25:34.100'
  start: '02:25:29.140'
  text: Like there's a scarcity of resources. What happens when you celebrate others
    and you promote others,
- end: '02:25:43.940'
  start: '02:25:34.820'
  text: the ideas of others, it actually grows that pie. I mean, the resources become
    less scarce.
- end: '02:25:48.420'
  start: '02:25:44.740'
  text: That applies in a lot of kinds of domains. It applies in academia, where a
    lot of people
- end: '02:25:54.820'
  start: '02:25:48.420'
  text: are very, see some funding for academic research is zero sum. It is not. If
    you celebrate each
- end: '02:26:00.180'
  start: '02:25:54.820'
  text: other, if you make, if you get everybody to be excited about AI, about physics,
    about mathematics,
- end: '02:26:04.820'
  start: '02:26:00.180'
  text: I think there'll be more and more funding and I think everybody wins. Yeah,
    that applies, I think,
- end: '02:26:11.300'
  start: '02:26:04.820'
  text: broadly. Yeah, yeah, exactly. So, last question about love and meaning.
- end: '02:26:18.580'
  start: '02:26:13.940'
  text: What is the role of love in the human condition broadly and more specific
    to you?
- end: '02:26:23.780'
  start: '02:26:18.580'
  text: How has love, romantic love or otherwise made you a better person, a better
    human being?
- end: '02:26:27.860'
  start: '02:26:27.060'
  text: Better engineer?
- end: '02:26:37.620'
  start: '02:26:29.140'
  text: Now you're asking really perplexing questions. It's hard to give up. I mean,
    there are many
- end: '02:26:43.700'
  start: '02:26:38.420'
  text: books, poems and songs written about what is love and what exactly,
- end: '02:26:49.220'
  start: '02:26:48.020'
  text: what is love, maybe you don't hurt me.
- end: '02:26:57.460'
  start: '02:26:52.340'
  text: That's one of the great ones, yes. You have earlier quoted Shakespeare, but
    that's really up there.
- end: '02:27:01.140'
  start: '02:27:00.020'
  text: Love is a many splendid thing.
- end: '02:27:07.940'
  start: '02:27:01.220'
  text: I mean, there's, because we've talked about so many inspiring things like
    be useful in
- end: '02:27:14.020'
  start: '02:27:07.940'
  text: the world, sort of like solve problems, alleviate suffering, but it seems
    like connection between
- end: '02:27:21.300'
  start: '02:27:14.020'
  text: humans is a source, you know, it's a source of joy, is a source of meaning
    and that's what love is,
- end: '02:27:27.140'
  start: '02:27:21.300'
  text: friendship, love. I just wonder if you think about that kind of thing when
    you talk about
- end: '02:27:34.020'
  start: '02:27:28.100'
  text: preserving the light of human consciousness and us becoming a multi-planetary
    species.
- end: '02:27:43.700'
  start: '02:27:35.140'
  text: I mean, to me at least, that means like if we're just alone and conscious
    and intelligent,
- end: '02:27:49.860'
  start: '02:27:44.260'
  text: it doesn't mean nearly as much as if we're with others, right? And there's
    some magic
- end: '02:27:56.660'
  start: '02:27:49.860'
  text: created when we're together. The French of it, and I think the highest form
    of it is love,
- end: '02:28:01.860'
  start: '02:27:56.660'
  text: which I think broadly is much bigger than just sort of romantic, but also
    yes,
- end: '02:28:06.020'
  start: '02:28:01.860'
  text: romantic love and family and those kinds of things.
- end: '02:28:10.420'
  start: '02:28:06.020'
  text: Well, I mean, the reason I guess I care about us becoming a multi-planet species
    in a space
- end: '02:28:20.580'
  start: '02:28:10.420'
  text: frank civilization is foundationally, I love humanity. And so I wish to see
    it prosper and
- end: '02:28:28.500'
  start: '02:28:20.820'
  text: do great things and be happy. And if I did not love humanity, I would not
    care about these things.
- end: '02:28:34.900'
  start: '02:28:31.140'
  text: So when you look at the whole of it, the human history, all the people who's
    ever lived,
- end: '02:28:43.140'
  start: '02:28:34.900'
  text: all the people alive now, it's pretty, we're okay. On the whole, we're a pretty
    interesting
- end: '02:28:50.980'
  start: '02:28:44.100'
  text: bunch. Yeah, all things considered. And I've read a lot of history, including
    the darkest
- end: '02:28:57.860'
  start: '02:28:50.980'
  text: worst parts of it. And despite all that, I think on balance, I still love
    humanity.
- end: '02:29:03.860'
  start: '02:28:59.300'
  text: You joked about it with the 42. What do you think is the meaning of this whole
    thing?
- end: '02:29:10.180'
  start: '02:29:06.180'
  text: Is there a non-humirical representation? Yeah, really,
- end: '02:29:13.540'
  start: '02:29:10.180'
  text: I think what Dr. Saddam was saying in the Hitchhiker's Guide to the Galaxy
    is that
- end: '02:29:23.460'
  start: '02:29:15.700'
  text: the universe is the answer. And what we really need to figure out are what
    questions to ask
- end: '02:29:28.740'
  start: '02:29:23.460'
  text: about the answer that is the universe. And that the question is really the
    hard part. And if you
- end: '02:29:36.260'
  start: '02:29:28.740'
  text: can properly frame the question, then the answer relatively speaking is easy.
    So therefore, if
- end: '02:29:41.300'
  start: '02:29:36.260'
  text: you want to understand what questions to ask about the universe, you want
    to understand the
- end: '02:29:46.820'
  start: '02:29:41.300'
  text: meaning of life, we need to expand the scope and scale of consciousness so
    that we're better able
- end: '02:29:53.460'
  start: '02:29:46.820'
  text: to understand the nature of the universe and understand the meaning of life.
    And ultimately,
- end: '02:29:57.860'
  start: '02:29:53.460'
  text: the most important part would be to ask the right question. Yes.
- end: '02:30:01.460'
  start: '02:29:58.020'
  text: Yes. Thereby elevating the role of the interviewer.
- end: '02:30:05.620'
  start: '02:30:02.820'
  text: Yes, exactly. As the most important human in the room.
- end: '02:30:13.540'
  start: '02:30:07.620'
  text: Good questions are, it's hard to come up with good questions. Absolutely.
- end: '02:30:21.540'
  start: '02:30:15.060'
  text: But yeah, it's like that is the foundation of my philosophy is that I am curious
    about the
- end: '02:30:30.260'
  start: '02:30:21.540'
  text: nature of the universe. And obviously, I will die. I don't know when I'll
    die, but I won't live
- end: '02:30:36.580'
  start: '02:30:30.260'
  text: forever. But I would like to know that we're on a path to understanding the
    nature of the universe
- end: '02:30:40.420'
  start: '02:30:36.580'
  text: and the meaning of life and what questions to ask about the answer that is
    the universe.
- end: '02:30:46.340'
  start: '02:30:41.460'
  text: And so if we expand the scope and scale of humanity and consciousness in general,
- end: '02:30:52.900'
  start: '02:30:46.340'
  text: which includes Silicon Consciousness, then that seems like a fundamentally
    good thing.
- end: '02:31:01.060'
  start: '02:30:55.060'
  text: Elon, like I said, I'm deeply grateful that you have spent your extremely
    valuable time with me
- end: '02:31:07.860'
  start: '02:31:01.060'
  text: today and also that you have given millions of people hope in this difficult
    time, this divisive
- end: '02:31:14.500'
  start: '02:31:07.860'
  text: time in this cynical time. So I hope you do continue doing what you're doing.
    Thank you so much for
- end: '02:31:19.620'
  start: '02:31:14.500'
  text: talking today. Oh, you're welcome. Thanks for excellent questions. Thanks
    for listening to this
- end: '02:31:24.020'
  start: '02:31:19.620'
  text: conversation with Elon Musk. To support this podcast, please check out our
    sponsors in the
- end: '02:31:30.020'
  start: '02:31:24.020'
  text: description. And now let me leave you with some words from Elon Musk himself.
    When something is
- end: '02:31:36.900'
  start: '02:31:30.020'
  text: important enough, you do it even if the odds are not in your favor. Thank
    you for listening and hope
- end: '02:31:38.100'
  start: '02:31:36.900'
  text: to see you next time.
